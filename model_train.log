I0628 16:42:38.759730 17458 caffe.cpp:217] Using GPUs 0
I0628 16:42:38.780285 17458 caffe.cpp:222] GPU 0: GeForce GTX 950M
I0628 16:42:38.988052 17458 solver.cpp:63] Initializing solver from parameters: 
train_net: "example/MobileNetSSD_train.prototxt"
test_net: "example/MobileNetSSD_test.prototxt"
test_iter: 673
test_interval: 1000
base_lr: 0.0005
display: 10
max_iter: 15000
lr_policy: "multistep"
gamma: 0.5
weight_decay: 5e-05
snapshot: 1000
snapshot_prefix: "snapshot/mobilenet"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 3000
stepvalue: 6000
stepvalue: 9000
stepvalue: 12000
iter_size: 1
type: "RMSProp"
eval_type: "detection"
ap_version: "11point"
I0628 16:42:38.988261 17458 solver.cpp:96] Creating training net from train_net file: example/MobileNetSSD_train.prototxt
I0628 16:42:38.989500 17458 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: example/MobileNetSSD_train.prototxt
I0628 16:42:38.989512 17458 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 16:42:38.990502 17458 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.007843
    mirror: true
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "trainval_lmdb/"
    batch_size: 4
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    ord
I0628 16:42:38.991596 17458 layer_factory.hpp:77] Creating layer data
I0628 16:42:38.991827 17458 net.cpp:100] Creating Layer data
I0628 16:42:38.991843 17458 net.cpp:408] data -> data
I0628 16:42:38.991879 17458 net.cpp:408] data -> label
I0628 16:42:38.992779 17471 db_lmdb.cpp:35] Opened lmdb trainval_lmdb/
I0628 16:42:39.008742 17458 annotated_data_layer.cpp:62] output data size: 4,3,300,300
I0628 16:42:39.014540 17458 net.cpp:150] Setting up data
I0628 16:42:39.014616 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.014636 17458 net.cpp:157] Top shape: 1 1 2 8 (16)
I0628 16:42:39.014639 17458 net.cpp:165] Memory required for data: 4320064
I0628 16:42:39.014652 17458 layer_factory.hpp:77] Creating layer data_data_0_split
I0628 16:42:39.014668 17458 net.cpp:100] Creating Layer data_data_0_split
I0628 16:42:39.014690 17458 net.cpp:434] data_data_0_split <- data
I0628 16:42:39.014711 17458 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0628 16:42:39.014722 17458 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0628 16:42:39.014730 17458 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0628 16:42:39.014736 17458 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0628 16:42:39.014741 17458 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0628 16:42:39.014746 17458 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0628 16:42:39.014751 17458 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0628 16:42:39.014897 17458 net.cpp:150] Setting up data_data_0_split
I0628 16:42:39.014905 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.014928 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.014967 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.014974 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.014981 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.014987 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.015007 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.015012 17458 net.cpp:165] Memory required for data: 34560064
I0628 16:42:39.015017 17458 layer_factory.hpp:77] Creating layer conv0
I0628 16:42:39.015038 17458 net.cpp:100] Creating Layer conv0
I0628 16:42:39.015043 17458 net.cpp:434] conv0 <- data_data_0_split_0
I0628 16:42:39.015050 17458 net.cpp:408] conv0 -> conv0
I0628 16:42:39.568060 17458 net.cpp:150] Setting up conv0
I0628 16:42:39.568084 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.568106 17458 net.cpp:165] Memory required for data: 46080064
I0628 16:42:39.568120 17458 layer_factory.hpp:77] Creating layer conv0/bn
I0628 16:42:39.568130 17458 net.cpp:100] Creating Layer conv0/bn
I0628 16:42:39.568133 17458 net.cpp:434] conv0/bn <- conv0
I0628 16:42:39.568158 17458 net.cpp:395] conv0/bn -> conv0 (in-place)
I0628 16:42:39.568825 17458 net.cpp:150] Setting up conv0/bn
I0628 16:42:39.568836 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.568840 17458 net.cpp:165] Memory required for data: 57600064
I0628 16:42:39.568866 17458 layer_factory.hpp:77] Creating layer conv0/scale
I0628 16:42:39.568876 17458 net.cpp:100] Creating Layer conv0/scale
I0628 16:42:39.568881 17458 net.cpp:434] conv0/scale <- conv0
I0628 16:42:39.568886 17458 net.cpp:395] conv0/scale -> conv0 (in-place)
I0628 16:42:39.569008 17458 layer_factory.hpp:77] Creating layer conv0/scale
I0628 16:42:39.569259 17458 net.cpp:150] Setting up conv0/scale
I0628 16:42:39.569265 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.569268 17458 net.cpp:165] Memory required for data: 69120064
I0628 16:42:39.569293 17458 layer_factory.hpp:77] Creating layer conv0/relu
I0628 16:42:39.569298 17458 net.cpp:100] Creating Layer conv0/relu
I0628 16:42:39.569301 17458 net.cpp:434] conv0/relu <- conv0
I0628 16:42:39.569305 17458 net.cpp:395] conv0/relu -> conv0 (in-place)
I0628 16:42:39.569965 17458 net.cpp:150] Setting up conv0/relu
I0628 16:42:39.569974 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.569978 17458 net.cpp:165] Memory required for data: 80640064
I0628 16:42:39.569981 17458 layer_factory.hpp:77] Creating layer conv1/dw
I0628 16:42:39.570009 17458 net.cpp:100] Creating Layer conv1/dw
I0628 16:42:39.570026 17458 net.cpp:434] conv1/dw <- conv0
I0628 16:42:39.570031 17458 net.cpp:408] conv1/dw -> conv1/dw
I0628 16:42:39.570335 17458 net.cpp:150] Setting up conv1/dw
I0628 16:42:39.570358 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.570361 17458 net.cpp:165] Memory required for data: 92160064
I0628 16:42:39.570366 17458 layer_factory.hpp:77] Creating layer conv1/dw/bn
I0628 16:42:39.570391 17458 net.cpp:100] Creating Layer conv1/dw/bn
I0628 16:42:39.570395 17458 net.cpp:434] conv1/dw/bn <- conv1/dw
I0628 16:42:39.570399 17458 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I0628 16:42:39.570693 17458 net.cpp:150] Setting up conv1/dw/bn
I0628 16:42:39.570701 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.570704 17458 net.cpp:165] Memory required for data: 103680064
I0628 16:42:39.570730 17458 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0628 16:42:39.570751 17458 net.cpp:100] Creating Layer conv1/dw/scale
I0628 16:42:39.570755 17458 net.cpp:434] conv1/dw/scale <- conv1/dw
I0628 16:42:39.570760 17458 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I0628 16:42:39.570849 17458 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0628 16:42:39.571084 17458 net.cpp:150] Setting up conv1/dw/scale
I0628 16:42:39.571090 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.571094 17458 net.cpp:165] Memory required for data: 115200064
I0628 16:42:39.571099 17458 layer_factory.hpp:77] Creating layer conv1/dw/relu
I0628 16:42:39.571120 17458 net.cpp:100] Creating Layer conv1/dw/relu
I0628 16:42:39.571125 17458 net.cpp:434] conv1/dw/relu <- conv1/dw
I0628 16:42:39.571141 17458 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I0628 16:42:39.571949 17458 net.cpp:150] Setting up conv1/dw/relu
I0628 16:42:39.571959 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.571961 17458 net.cpp:165] Memory required for data: 126720064
I0628 16:42:39.571965 17458 layer_factory.hpp:77] Creating layer conv1
I0628 16:42:39.571992 17458 net.cpp:100] Creating Layer conv1
I0628 16:42:39.571997 17458 net.cpp:434] conv1 <- conv1/dw
I0628 16:42:39.572002 17458 net.cpp:408] conv1 -> conv1
I0628 16:42:39.574730 17458 net.cpp:150] Setting up conv1
I0628 16:42:39.574741 17458 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0628 16:42:39.574745 17458 net.cpp:165] Memory required for data: 149760064
I0628 16:42:39.574769 17458 layer_factory.hpp:77] Creating layer conv1/bn
I0628 16:42:39.574776 17458 net.cpp:100] Creating Layer conv1/bn
I0628 16:42:39.574780 17458 net.cpp:434] conv1/bn <- conv1
I0628 16:42:39.574785 17458 net.cpp:395] conv1/bn -> conv1 (in-place)
I0628 16:42:39.575068 17458 net.cpp:150] Setting up conv1/bn
I0628 16:42:39.575076 17458 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0628 16:42:39.575079 17458 net.cpp:165] Memory required for data: 172800064
I0628 16:42:39.575084 17458 layer_factory.hpp:77] Creating layer conv1/scale
I0628 16:42:39.575109 17458 net.cpp:100] Creating Layer conv1/scale
I0628 16:42:39.575112 17458 net.cpp:434] conv1/scale <- conv1
I0628 16:42:39.575116 17458 net.cpp:395] conv1/scale -> conv1 (in-place)
I0628 16:42:39.575206 17458 layer_factory.hpp:77] Creating layer conv1/scale
I0628 16:42:39.575390 17458 net.cpp:150] Setting up conv1/scale
I0628 16:42:39.575397 17458 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0628 16:42:39.575400 17458 net.cpp:165] Memory required for data: 195840064
I0628 16:42:39.575407 17458 layer_factory.hpp:77] Creating layer conv1/relu
I0628 16:42:39.575413 17458 net.cpp:100] Creating Layer conv1/relu
I0628 16:42:39.575417 17458 net.cpp:434] conv1/relu <- conv1
I0628 16:42:39.575421 17458 net.cpp:395] conv1/relu -> conv1 (in-place)
I0628 16:42:39.576205 17458 net.cpp:150] Setting up conv1/relu
I0628 16:42:39.576213 17458 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0628 16:42:39.576217 17458 net.cpp:165] Memory required for data: 218880064
I0628 16:42:39.576220 17458 layer_factory.hpp:77] Creating layer conv2/dw
I0628 16:42:39.576247 17458 net.cpp:100] Creating Layer conv2/dw
I0628 16:42:39.576251 17458 net.cpp:434] conv2/dw <- conv1
I0628 16:42:39.576258 17458 net.cpp:408] conv2/dw -> conv2/dw
I0628 16:42:39.576537 17458 net.cpp:150] Setting up conv2/dw
I0628 16:42:39.576545 17458 net.cpp:157] Top shape: 4 64 75 75 (1440000)
I0628 16:42:39.576547 17458 net.cpp:165] Memory required for data: 224640064
I0628 16:42:39.576551 17458 layer_factory.hpp:77] Creating layer conv2/dw/bn
I0628 16:42:39.576575 17458 net.cpp:100] Creating Layer conv2/dw/bn
I0628 16:42:39.576578 17458 net.cpp:434] conv2/dw/bn <- conv2/dw
I0628 16:42:39.576583 17458 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I0628 16:42:39.577201 17458 net.cpp:150] Setting up conv2/dw/bn
I0628 16:42:39.577211 17458 net.cpp:157] Top shape: 4 64 75 75 (1440000)
I0628 16:42:39.577214 17458 net.cpp:165] Memory required for data: 230400064
I0628 16:42:39.577239 17458 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0628 16:42:39.577246 17458 net.cpp:100] Creating Layer conv2/dw/scale
I0628 16:42:39.577250 17458 net.cpp:434] conv2/dw/scale <- conv2/dw
I0628 16:42:39.577255 17458 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I0628 16:42:39.577370 17458 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0628 16:42:39.577566 17458 net.cpp:150] Setting up conv2/dw/scale
I0628 16:42:39.577574 17458 net.cpp:157] Top shape: 4 64 75 75 (1440000)
I0628 16:42:39.577576 17458 net.cpp:165] Memory required for data: 236160064
I0628 16:42:39.577581 17458 layer_factory.hpp:77] Creating layer conv2/dw/relu
I0628 16:42:39.577601 17458 net.cpp:100] Creating Layer conv2/dw/relu
I0628 16:42:39.577623 17458 net.cpp:434] conv2/dw/relu <- conv2/dw
I0628 16:42:39.577628 17458 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I0628 16:42:39.578246 17458 net.cpp:150] Setting up conv2/dw/relu
I0628 16:42:39.578254 17458 net.cpp:157] Top shape: 4 64 75 75 (1440000)
I0628 16:42:39.578258 17458 net.cpp:165] Memory required for data: 241920064
I0628 16:42:39.578261 17458 layer_factory.hpp:77] Creating layer conv2
I0628 16:42:39.578287 17458 net.cpp:100] Creating Layer conv2
I0628 16:42:39.578291 17458 net.cpp:434] conv2 <- conv2/dw
I0628 16:42:39.578296 17458 net.cpp:408] conv2 -> conv2
I0628 16:42:39.582077 17458 net.cpp:150] Setting up conv2
I0628 16:42:39.582095 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.582099 17458 net.cpp:165] Memory required for data: 253440064
I0628 16:42:39.582123 17458 layer_factory.hpp:77] Creating layer conv2/bn
I0628 16:42:39.582149 17458 net.cpp:100] Creating Layer conv2/bn
I0628 16:42:39.582154 17458 net.cpp:434] conv2/bn <- conv2
I0628 16:42:39.582172 17458 net.cpp:395] conv2/bn -> conv2 (in-place)
I0628 16:42:39.582451 17458 net.cpp:150] Setting up conv2/bn
I0628 16:42:39.582458 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.582460 17458 net.cpp:165] Memory required for data: 264960064
I0628 16:42:39.582466 17458 layer_factory.hpp:77] Creating layer conv2/scale
I0628 16:42:39.582492 17458 net.cpp:100] Creating Layer conv2/scale
I0628 16:42:39.582496 17458 net.cpp:434] conv2/scale <- conv2
I0628 16:42:39.582500 17458 net.cpp:395] conv2/scale -> conv2 (in-place)
I0628 16:42:39.582592 17458 layer_factory.hpp:77] Creating layer conv2/scale
I0628 16:42:39.582808 17458 net.cpp:150] Setting up conv2/scale
I0628 16:42:39.582814 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.582818 17458 net.cpp:165] Memory required for data: 276480064
I0628 16:42:39.582823 17458 layer_factory.hpp:77] Creating layer conv2/relu
I0628 16:42:39.582828 17458 net.cpp:100] Creating Layer conv2/relu
I0628 16:42:39.582830 17458 net.cpp:434] conv2/relu <- conv2
I0628 16:42:39.582836 17458 net.cpp:395] conv2/relu -> conv2 (in-place)
I0628 16:42:39.583613 17458 net.cpp:150] Setting up conv2/relu
I0628 16:42:39.583623 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.583626 17458 net.cpp:165] Memory required for data: 288000064
I0628 16:42:39.583648 17458 layer_factory.hpp:77] Creating layer conv3/dw
I0628 16:42:39.583658 17458 net.cpp:100] Creating Layer conv3/dw
I0628 16:42:39.583662 17458 net.cpp:434] conv3/dw <- conv2
I0628 16:42:39.583667 17458 net.cpp:408] conv3/dw -> conv3/dw
I0628 16:42:39.583937 17458 net.cpp:150] Setting up conv3/dw
I0628 16:42:39.583945 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.583947 17458 net.cpp:165] Memory required for data: 299520064
I0628 16:42:39.583971 17458 layer_factory.hpp:77] Creating layer conv3/dw/bn
I0628 16:42:39.583976 17458 net.cpp:100] Creating Layer conv3/dw/bn
I0628 16:42:39.583981 17458 net.cpp:434] conv3/dw/bn <- conv3/dw
I0628 16:42:39.583984 17458 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I0628 16:42:39.584237 17458 net.cpp:150] Setting up conv3/dw/bn
I0628 16:42:39.584244 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.584246 17458 net.cpp:165] Memory required for data: 311040064
I0628 16:42:39.584275 17458 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0628 16:42:39.584280 17458 net.cpp:100] Creating Layer conv3/dw/scale
I0628 16:42:39.584282 17458 net.cpp:434] conv3/dw/scale <- conv3/dw
I0628 16:42:39.584287 17458 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I0628 16:42:39.584372 17458 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0628 16:42:39.584583 17458 net.cpp:150] Setting up conv3/dw/scale
I0628 16:42:39.584602 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.584605 17458 net.cpp:165] Memory required for data: 322560064
I0628 16:42:39.584609 17458 layer_factory.hpp:77] Creating layer conv3/dw/relu
I0628 16:42:39.584650 17458 net.cpp:100] Creating Layer conv3/dw/relu
I0628 16:42:39.584671 17458 net.cpp:434] conv3/dw/relu <- conv3/dw
I0628 16:42:39.584676 17458 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I0628 16:42:39.585490 17458 net.cpp:150] Setting up conv3/dw/relu
I0628 16:42:39.585500 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.585503 17458 net.cpp:165] Memory required for data: 334080064
I0628 16:42:39.585525 17458 layer_factory.hpp:77] Creating layer conv3
I0628 16:42:39.585534 17458 net.cpp:100] Creating Layer conv3
I0628 16:42:39.585537 17458 net.cpp:434] conv3 <- conv3/dw
I0628 16:42:39.585543 17458 net.cpp:408] conv3 -> conv3
I0628 16:42:39.587980 17458 net.cpp:150] Setting up conv3
I0628 16:42:39.587993 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.587996 17458 net.cpp:165] Memory required for data: 345600064
I0628 16:42:39.588001 17458 layer_factory.hpp:77] Creating layer conv3/bn
I0628 16:42:39.588007 17458 net.cpp:100] Creating Layer conv3/bn
I0628 16:42:39.588011 17458 net.cpp:434] conv3/bn <- conv3
I0628 16:42:39.588016 17458 net.cpp:395] conv3/bn -> conv3 (in-place)
I0628 16:42:39.588263 17458 net.cpp:150] Setting up conv3/bn
I0628 16:42:39.588270 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.588274 17458 net.cpp:165] Memory required for data: 357120064
I0628 16:42:39.588279 17458 layer_factory.hpp:77] Creating layer conv3/scale
I0628 16:42:39.588284 17458 net.cpp:100] Creating Layer conv3/scale
I0628 16:42:39.588287 17458 net.cpp:434] conv3/scale <- conv3
I0628 16:42:39.588292 17458 net.cpp:395] conv3/scale -> conv3 (in-place)
I0628 16:42:39.588349 17458 layer_factory.hpp:77] Creating layer conv3/scale
I0628 16:42:39.588587 17458 net.cpp:150] Setting up conv3/scale
I0628 16:42:39.588593 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.588595 17458 net.cpp:165] Memory required for data: 368640064
I0628 16:42:39.588599 17458 layer_factory.hpp:77] Creating layer conv3/relu
I0628 16:42:39.588606 17458 net.cpp:100] Creating Layer conv3/relu
I0628 16:42:39.588609 17458 net.cpp:434] conv3/relu <- conv3
I0628 16:42:39.588614 17458 net.cpp:395] conv3/relu -> conv3 (in-place)
I0628 16:42:39.589390 17458 net.cpp:150] Setting up conv3/relu
I0628 16:42:39.589399 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.589403 17458 net.cpp:165] Memory required for data: 380160064
I0628 16:42:39.589406 17458 layer_factory.hpp:77] Creating layer conv4/dw
I0628 16:42:39.589416 17458 net.cpp:100] Creating Layer conv4/dw
I0628 16:42:39.589419 17458 net.cpp:434] conv4/dw <- conv3
I0628 16:42:39.589424 17458 net.cpp:408] conv4/dw -> conv4/dw
I0628 16:42:39.589694 17458 net.cpp:150] Setting up conv4/dw
I0628 16:42:39.589702 17458 net.cpp:157] Top shape: 4 128 38 38 (739328)
I0628 16:42:39.589705 17458 net.cpp:165] Memory required for data: 383117376
I0628 16:42:39.589710 17458 layer_factory.hpp:77] Creating layer conv4/dw/bn
I0628 16:42:39.589715 17458 net.cpp:100] Creating Layer conv4/dw/bn
I0628 16:42:39.589717 17458 net.cpp:434] conv4/dw/bn <- conv4/dw
I0628 16:42:39.589721 17458 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I0628 16:42:39.589960 17458 net.cpp:150] Setting up conv4/dw/bn
I0628 16:42:39.589967 17458 net.cpp:157] Top shape: 4 128 38 38 (739328)
I0628 16:42:39.589970 17458 net.cpp:165] Memory required for data: 386074688
I0628 16:42:39.589975 17458 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0628 16:42:39.589982 17458 net.cpp:100] Creating Layer conv4/dw/scale
I0628 16:42:39.589987 17458 net.cpp:434] conv4/dw/scale <- conv4/dw
I0628 16:42:39.589990 17458 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I0628 16:42:39.590047 17458 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0628 16:42:39.590276 17458 net.cpp:150] Setting up conv4/dw/scale
I0628 16:42:39.590282 17458 net.cpp:157] Top shape: 4 128 38 38 (739328)
I0628 16:42:39.590286 17458 net.cpp:165] Memory required for data: 389032000
I0628 16:42:39.590289 17458 layer_factory.hpp:77] Creating layer conv4/dw/relu
I0628 16:42:39.590294 17458 net.cpp:100] Creating Layer conv4/dw/relu
I0628 16:42:39.590308 17458 net.cpp:434] conv4/dw/relu <- conv4/dw
I0628 16:42:39.590312 17458 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I0628 16:42:39.591116 17458 net.cpp:150] Setting up conv4/dw/relu
I0628 16:42:39.591126 17458 net.cpp:157] Top shape: 4 128 38 38 (739328)
I0628 16:42:39.591130 17458 net.cpp:165] Memory required for data: 391989312
I0628 16:42:39.591133 17458 layer_factory.hpp:77] Creating layer conv4
I0628 16:42:39.591141 17458 net.cpp:100] Creating Layer conv4
I0628 16:42:39.591145 17458 net.cpp:434] conv4 <- conv4/dw
I0628 16:42:39.591152 17458 net.cpp:408] conv4 -> conv4
I0628 16:42:39.593875 17458 net.cpp:150] Setting up conv4
I0628 16:42:39.593888 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.593890 17458 net.cpp:165] Memory required for data: 397903936
I0628 16:42:39.593895 17458 layer_factory.hpp:77] Creating layer conv4/bn
I0628 16:42:39.593901 17458 net.cpp:100] Creating Layer conv4/bn
I0628 16:42:39.593904 17458 net.cpp:434] conv4/bn <- conv4
I0628 16:42:39.593911 17458 net.cpp:395] conv4/bn -> conv4 (in-place)
I0628 16:42:39.594167 17458 net.cpp:150] Setting up conv4/bn
I0628 16:42:39.594174 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.594177 17458 net.cpp:165] Memory required for data: 403818560
I0628 16:42:39.594182 17458 layer_factory.hpp:77] Creating layer conv4/scale
I0628 16:42:39.594208 17458 net.cpp:100] Creating Layer conv4/scale
I0628 16:42:39.594211 17458 net.cpp:434] conv4/scale <- conv4
I0628 16:42:39.594218 17458 net.cpp:395] conv4/scale -> conv4 (in-place)
I0628 16:42:39.594305 17458 layer_factory.hpp:77] Creating layer conv4/scale
I0628 16:42:39.594450 17458 net.cpp:150] Setting up conv4/scale
I0628 16:42:39.594456 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.594460 17458 net.cpp:165] Memory required for data: 409733184
I0628 16:42:39.594465 17458 layer_factory.hpp:77] Creating layer conv4/relu
I0628 16:42:39.594487 17458 net.cpp:100] Creating Layer conv4/relu
I0628 16:42:39.594491 17458 net.cpp:434] conv4/relu <- conv4
I0628 16:42:39.594494 17458 net.cpp:395] conv4/relu -> conv4 (in-place)
I0628 16:42:39.595271 17458 net.cpp:150] Setting up conv4/relu
I0628 16:42:39.595281 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.595284 17458 net.cpp:165] Memory required for data: 415647808
I0628 16:42:39.595306 17458 layer_factory.hpp:77] Creating layer conv5/dw
I0628 16:42:39.595317 17458 net.cpp:100] Creating Layer conv5/dw
I0628 16:42:39.595321 17458 net.cpp:434] conv5/dw <- conv4
I0628 16:42:39.595326 17458 net.cpp:408] conv5/dw -> conv5/dw
I0628 16:42:39.595588 17458 net.cpp:150] Setting up conv5/dw
I0628 16:42:39.595595 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.595598 17458 net.cpp:165] Memory required for data: 421562432
I0628 16:42:39.595603 17458 layer_factory.hpp:77] Creating layer conv5/dw/bn
I0628 16:42:39.595628 17458 net.cpp:100] Creating Layer conv5/dw/bn
I0628 16:42:39.595631 17458 net.cpp:434] conv5/dw/bn <- conv5/dw
I0628 16:42:39.595650 17458 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I0628 16:42:39.595886 17458 net.cpp:150] Setting up conv5/dw/bn
I0628 16:42:39.595892 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.595896 17458 net.cpp:165] Memory required for data: 427477056
I0628 16:42:39.595919 17458 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0628 16:42:39.595926 17458 net.cpp:100] Creating Layer conv5/dw/scale
I0628 16:42:39.595928 17458 net.cpp:434] conv5/dw/scale <- conv5/dw
I0628 16:42:39.595934 17458 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I0628 16:42:39.596022 17458 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0628 16:42:39.596231 17458 net.cpp:150] Setting up conv5/dw/scale
I0628 16:42:39.596237 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.596240 17458 net.cpp:165] Memory required for data: 433391680
I0628 16:42:39.596246 17458 layer_factory.hpp:77] Creating layer conv5/dw/relu
I0628 16:42:39.596268 17458 net.cpp:100] Creating Layer conv5/dw/relu
I0628 16:42:39.596284 17458 net.cpp:434] conv5/dw/relu <- conv5/dw
I0628 16:42:39.596309 17458 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I0628 16:42:39.597172 17458 net.cpp:150] Setting up conv5/dw/relu
I0628 16:42:39.597182 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.597187 17458 net.cpp:165] Memory required for data: 439306304
I0628 16:42:39.597208 17458 layer_factory.hpp:77] Creating layer conv5
I0628 16:42:39.597218 17458 net.cpp:100] Creating Layer conv5
I0628 16:42:39.597223 17458 net.cpp:434] conv5 <- conv5/dw
I0628 16:42:39.597229 17458 net.cpp:408] conv5 -> conv5
I0628 16:42:39.601624 17458 net.cpp:150] Setting up conv5
I0628 16:42:39.601649 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.601658 17458 net.cpp:165] Memory required for data: 445220928
I0628 16:42:39.601670 17458 layer_factory.hpp:77] Creating layer conv5/bn
I0628 16:42:39.601683 17458 net.cpp:100] Creating Layer conv5/bn
I0628 16:42:39.601692 17458 net.cpp:434] conv5/bn <- conv5
I0628 16:42:39.601739 17458 net.cpp:395] conv5/bn -> conv5 (in-place)
I0628 16:42:39.602185 17458 net.cpp:150] Setting up conv5/bn
I0628 16:42:39.602200 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.602223 17458 net.cpp:165] Memory required for data: 451135552
I0628 16:42:39.602236 17458 layer_factory.hpp:77] Creating layer conv5/scale
I0628 16:42:39.602246 17458 net.cpp:100] Creating Layer conv5/scale
I0628 16:42:39.602269 17458 net.cpp:434] conv5/scale <- conv5
I0628 16:42:39.602296 17458 net.cpp:395] conv5/scale -> conv5 (in-place)
I0628 16:42:39.602401 17458 layer_factory.hpp:77] Creating layer conv5/scale
I0628 16:42:39.602697 17458 net.cpp:150] Setting up conv5/scale
I0628 16:42:39.602707 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.602710 17458 net.cpp:165] Memory required for data: 457050176
I0628 16:42:39.602722 17458 layer_factory.hpp:77] Creating layer conv5/relu
I0628 16:42:39.602728 17458 net.cpp:100] Creating Layer conv5/relu
I0628 16:42:39.602732 17458 net.cpp:434] conv5/relu <- conv5
I0628 16:42:39.602738 17458 net.cpp:395] conv5/relu -> conv5 (in-place)
I0628 16:42:39.603507 17458 net.cpp:150] Setting up conv5/relu
I0628 16:42:39.603516 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.603520 17458 net.cpp:165] Memory required for data: 462964800
I0628 16:42:39.603523 17458 layer_factory.hpp:77] Creating layer conv6/dw
I0628 16:42:39.603534 17458 net.cpp:100] Creating Layer conv6/dw
I0628 16:42:39.603538 17458 net.cpp:434] conv6/dw <- conv5
I0628 16:42:39.603545 17458 net.cpp:408] conv6/dw -> conv6/dw
I0628 16:42:39.603849 17458 net.cpp:150] Setting up conv6/dw
I0628 16:42:39.603857 17458 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0628 16:42:39.603859 17458 net.cpp:165] Memory required for data: 464443456
I0628 16:42:39.603864 17458 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0628 16:42:39.603869 17458 net.cpp:100] Creating Layer conv6/dw/bn
I0628 16:42:39.603873 17458 net.cpp:434] conv6/dw/bn <- conv6/dw
I0628 16:42:39.603878 17458 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I0628 16:42:39.604126 17458 net.cpp:150] Setting up conv6/dw/bn
I0628 16:42:39.604133 17458 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0628 16:42:39.604136 17458 net.cpp:165] Memory required for data: 465922112
I0628 16:42:39.604141 17458 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0628 16:42:39.604146 17458 net.cpp:100] Creating Layer conv6/dw/scale
I0628 16:42:39.604151 17458 net.cpp:434] conv6/dw/scale <- conv6/dw
I0628 16:42:39.604156 17458 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I0628 16:42:39.604212 17458 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0628 16:42:39.604444 17458 net.cpp:150] Setting up conv6/dw/scale
I0628 16:42:39.604450 17458 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0628 16:42:39.604454 17458 net.cpp:165] Memory required for data: 467400768
I0628 16:42:39.604458 17458 layer_factory.hpp:77] Creating layer conv6/dw/relu
I0628 16:42:39.604462 17458 net.cpp:100] Creating Layer conv6/dw/relu
I0628 16:42:39.604480 17458 net.cpp:434] conv6/dw/relu <- conv6/dw
I0628 16:42:39.604486 17458 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I0628 16:42:39.605294 17458 net.cpp:150] Setting up conv6/dw/relu
I0628 16:42:39.605304 17458 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0628 16:42:39.605314 17458 net.cpp:165] Memory required for data: 468879424
I0628 16:42:39.605317 17458 layer_factory.hpp:77] Creating layer conv6
I0628 16:42:39.605325 17458 net.cpp:100] Creating Layer conv6
I0628 16:42:39.605329 17458 net.cpp:434] conv6 <- conv6/dw
I0628 16:42:39.605360 17458 net.cpp:408] conv6 -> conv6
I0628 16:42:39.609411 17458 net.cpp:150] Setting up conv6
I0628 16:42:39.609423 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.609427 17458 net.cpp:165] Memory required for data: 471836736
I0628 16:42:39.609433 17458 layer_factory.hpp:77] Creating layer conv6/bn
I0628 16:42:39.609441 17458 net.cpp:100] Creating Layer conv6/bn
I0628 16:42:39.609444 17458 net.cpp:434] conv6/bn <- conv6
I0628 16:42:39.609449 17458 net.cpp:395] conv6/bn -> conv6 (in-place)
I0628 16:42:39.609725 17458 net.cpp:150] Setting up conv6/bn
I0628 16:42:39.609733 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.609736 17458 net.cpp:165] Memory required for data: 474794048
I0628 16:42:39.609742 17458 layer_factory.hpp:77] Creating layer conv6/scale
I0628 16:42:39.609750 17458 net.cpp:100] Creating Layer conv6/scale
I0628 16:42:39.609753 17458 net.cpp:434] conv6/scale <- conv6
I0628 16:42:39.609758 17458 net.cpp:395] conv6/scale -> conv6 (in-place)
I0628 16:42:39.609836 17458 layer_factory.hpp:77] Creating layer conv6/scale
I0628 16:42:39.610054 17458 net.cpp:150] Setting up conv6/scale
I0628 16:42:39.610060 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.610064 17458 net.cpp:165] Memory required for data: 477751360
I0628 16:42:39.610069 17458 layer_factory.hpp:77] Creating layer conv6/relu
I0628 16:42:39.610074 17458 net.cpp:100] Creating Layer conv6/relu
I0628 16:42:39.610077 17458 net.cpp:434] conv6/relu <- conv6
I0628 16:42:39.610081 17458 net.cpp:395] conv6/relu -> conv6 (in-place)
I0628 16:42:39.610857 17458 net.cpp:150] Setting up conv6/relu
I0628 16:42:39.610867 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.610870 17458 net.cpp:165] Memory required for data: 480708672
I0628 16:42:39.610893 17458 layer_factory.hpp:77] Creating layer conv7/dw
I0628 16:42:39.610918 17458 net.cpp:100] Creating Layer conv7/dw
I0628 16:42:39.610921 17458 net.cpp:434] conv7/dw <- conv6
I0628 16:42:39.610926 17458 net.cpp:408] conv7/dw -> conv7/dw
I0628 16:42:39.611238 17458 net.cpp:150] Setting up conv7/dw
I0628 16:42:39.611244 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.611248 17458 net.cpp:165] Memory required for data: 483665984
I0628 16:42:39.611253 17458 layer_factory.hpp:77] Creating layer conv7/dw/bn
I0628 16:42:39.611258 17458 net.cpp:100] Creating Layer conv7/dw/bn
I0628 16:42:39.611261 17458 net.cpp:434] conv7/dw/bn <- conv7/dw
I0628 16:42:39.611265 17458 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I0628 16:42:39.611523 17458 net.cpp:150] Setting up conv7/dw/bn
I0628 16:42:39.611531 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.611533 17458 net.cpp:165] Memory required for data: 486623296
I0628 16:42:39.611538 17458 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0628 16:42:39.611546 17458 net.cpp:100] Creating Layer conv7/dw/scale
I0628 16:42:39.611548 17458 net.cpp:434] conv7/dw/scale <- conv7/dw
I0628 16:42:39.611553 17458 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I0628 16:42:39.611613 17458 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0628 16:42:39.611843 17458 net.cpp:150] Setting up conv7/dw/scale
I0628 16:42:39.611850 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.611852 17458 net.cpp:165] Memory required for data: 489580608
I0628 16:42:39.611857 17458 layer_factory.hpp:77] Creating layer conv7/dw/relu
I0628 16:42:39.611863 17458 net.cpp:100] Creating Layer conv7/dw/relu
I0628 16:42:39.611866 17458 net.cpp:434] conv7/dw/relu <- conv7/dw
I0628 16:42:39.611883 17458 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I0628 16:42:39.612514 17458 net.cpp:150] Setting up conv7/dw/relu
I0628 16:42:39.612524 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.612526 17458 net.cpp:165] Memory required for data: 492537920
I0628 16:42:39.612529 17458 layer_factory.hpp:77] Creating layer conv7
I0628 16:42:39.612540 17458 net.cpp:100] Creating Layer conv7
I0628 16:42:39.612543 17458 net.cpp:434] conv7 <- conv7/dw
I0628 16:42:39.612548 17458 net.cpp:408] conv7 -> conv7
I0628 16:42:39.618024 17458 net.cpp:150] Setting up conv7
I0628 16:42:39.618041 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.618046 17458 net.cpp:165] Memory required for data: 495495232
I0628 16:42:39.618052 17458 layer_factory.hpp:77] Creating layer conv7/bn
I0628 16:42:39.618059 17458 net.cpp:100] Creating Layer conv7/bn
I0628 16:42:39.618063 17458 net.cpp:434] conv7/bn <- conv7
I0628 16:42:39.618068 17458 net.cpp:395] conv7/bn -> conv7 (in-place)
I0628 16:42:39.618342 17458 net.cpp:150] Setting up conv7/bn
I0628 16:42:39.618350 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.618352 17458 net.cpp:165] Memory required for data: 498452544
I0628 16:42:39.618358 17458 layer_factory.hpp:77] Creating layer conv7/scale
I0628 16:42:39.618364 17458 net.cpp:100] Creating Layer conv7/scale
I0628 16:42:39.618367 17458 net.cpp:434] conv7/scale <- conv7
I0628 16:42:39.618373 17458 net.cpp:395] conv7/scale -> conv7 (in-place)
I0628 16:42:39.618468 17458 layer_factory.hpp:77] Creating layer conv7/scale
I0628 16:42:39.618687 17458 net.cpp:150] Setting up conv7/scale
I0628 16:42:39.618693 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.618696 17458 net.cpp:165] Memory required for data: 501409856
I0628 16:42:39.618701 17458 layer_factory.hpp:77] Creating layer conv7/relu
I0628 16:42:39.618707 17458 net.cpp:100] Creating Layer conv7/relu
I0628 16:42:39.618710 17458 net.cpp:434] conv7/relu <- conv7
I0628 16:42:39.618714 17458 net.cpp:395] conv7/relu -> conv7 (in-place)
I0628 16:42:39.619477 17458 net.cpp:150] Setting up conv7/relu
I0628 16:42:39.619488 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.619490 17458 net.cpp:165] Memory required for data: 504367168
I0628 16:42:39.619496 17458 layer_factory.hpp:77] Creating layer conv8/dw
I0628 16:42:39.619514 17458 net.cpp:100] Creating Layer conv8/dw
I0628 16:42:39.619518 17458 net.cpp:434] conv8/dw <- conv7
I0628 16:42:39.619524 17458 net.cpp:408] conv8/dw -> conv8/dw
I0628 16:42:39.619827 17458 net.cpp:150] Setting up conv8/dw
I0628 16:42:39.619833 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.619837 17458 net.cpp:165] Memory required for data: 507324480
I0628 16:42:39.619840 17458 layer_factory.hpp:77] Creating layer conv8/dw/bn
I0628 16:42:39.619846 17458 net.cpp:100] Creating Layer conv8/dw/bn
I0628 16:42:39.619849 17458 net.cpp:434] conv8/dw/bn <- conv8/dw
I0628 16:42:39.619854 17458 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I0628 16:42:39.620102 17458 net.cpp:150] Setting up conv8/dw/bn
I0628 16:42:39.620108 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.620111 17458 net.cpp:165] Memory required for data: 510281792
I0628 16:42:39.620116 17458 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0628 16:42:39.620126 17458 net.cpp:100] Creating Layer conv8/dw/scale
I0628 16:42:39.620129 17458 net.cpp:434] conv8/dw/scale <- conv8/dw
I0628 16:42:39.620134 17458 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I0628 16:42:39.620213 17458 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0628 16:42:39.620419 17458 net.cpp:150] Setting up conv8/dw/scale
I0628 16:42:39.620425 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.620441 17458 net.cpp:165] Memory required for data: 513239104
I0628 16:42:39.620446 17458 layer_factory.hpp:77] Creating layer conv8/dw/relu
I0628 16:42:39.620452 17458 net.cpp:100] Creating Layer conv8/dw/relu
I0628 16:42:39.620455 17458 net.cpp:434] conv8/dw/relu <- conv8/dw
I0628 16:42:39.620508 17458 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I0628 16:42:39.621377 17458 net.cpp:150] Setting up conv8/dw/relu
I0628 16:42:39.621402 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.621405 17458 net.cpp:165] Memory required for data: 516196416
I0628 16:42:39.621409 17458 layer_factory.hpp:77] Creating layer conv8
I0628 16:42:39.621418 17458 net.cpp:100] Creating Layer conv8
I0628 16:42:39.621421 17458 net.cpp:434] conv8 <- conv8/dw
I0628 16:42:39.621428 17458 net.cpp:408] conv8 -> conv8
I0628 16:42:39.626319 17458 net.cpp:150] Setting up conv8
I0628 16:42:39.626334 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.626338 17458 net.cpp:165] Memory required for data: 519153728
I0628 16:42:39.626363 17458 layer_factory.hpp:77] Creating layer conv8/bn
I0628 16:42:39.626370 17458 net.cpp:100] Creating Layer conv8/bn
I0628 16:42:39.626375 17458 net.cpp:434] conv8/bn <- conv8
I0628 16:42:39.626380 17458 net.cpp:395] conv8/bn -> conv8 (in-place)
I0628 16:42:39.626652 17458 net.cpp:150] Setting up conv8/bn
I0628 16:42:39.626662 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.626664 17458 net.cpp:165] Memory required for data: 522111040
I0628 16:42:39.626689 17458 layer_factory.hpp:77] Creating layer conv8/scale
I0628 16:42:39.626696 17458 net.cpp:100] Creating Layer conv8/scale
I0628 16:42:39.626713 17458 net.cpp:434] conv8/scale <- conv8
I0628 16:42:39.626718 17458 net.cpp:395] conv8/scale -> conv8 (in-place)
I0628 16:42:39.626811 17458 layer_factory.hpp:77] Creating layer conv8/scale
I0628 16:42:39.627002 17458 net.cpp:150] Setting up conv8/scale
I0628 16:42:39.627008 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.627012 17458 net.cpp:165] Memory required for data: 525068352
I0628 16:42:39.627017 17458 layer_factory.hpp:77] Creating layer conv8/relu
I0628 16:42:39.627041 17458 net.cpp:100] Creating Layer conv8/relu
I0628 16:42:39.627045 17458 net.cpp:434] conv8/relu <- conv8
I0628 16:42:39.627049 17458 net.cpp:395] conv8/relu -> conv8 (in-place)
I0628 16:42:39.628052 17458 net.cpp:150] Setting up conv8/relu
I0628 16:42:39.628067 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.628072 17458 net.cpp:165] Memory required for data: 528025664
I0628 16:42:39.628077 17458 layer_factory.hpp:77] Creating layer conv9/dw
I0628 16:42:39.628088 17458 net.cpp:100] Creating Layer conv9/dw
I0628 16:42:39.628093 17458 net.cpp:434] conv9/dw <- conv8
I0628 16:42:39.628101 17458 net.cpp:408] conv9/dw -> conv9/dw
I0628 16:42:39.628536 17458 net.cpp:150] Setting up conv9/dw
I0628 16:42:39.628548 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.628553 17458 net.cpp:165] Memory required for data: 530982976
I0628 16:42:39.628579 17458 layer_factory.hpp:77] Creating layer conv9/dw/bn
I0628 16:42:39.628585 17458 net.cpp:100] Creating Layer conv9/dw/bn
I0628 16:42:39.628588 17458 net.cpp:434] conv9/dw/bn <- conv9/dw
I0628 16:42:39.628593 17458 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I0628 16:42:39.628885 17458 net.cpp:150] Setting up conv9/dw/bn
I0628 16:42:39.628892 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.628895 17458 net.cpp:165] Memory required for data: 533940288
I0628 16:42:39.628901 17458 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0628 16:42:39.628906 17458 net.cpp:100] Creating Layer conv9/dw/scale
I0628 16:42:39.628909 17458 net.cpp:434] conv9/dw/scale <- conv9/dw
I0628 16:42:39.628914 17458 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I0628 16:42:39.629009 17458 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0628 16:42:39.629220 17458 net.cpp:150] Setting up conv9/dw/scale
I0628 16:42:39.629226 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.629230 17458 net.cpp:165] Memory required for data: 536897600
I0628 16:42:39.629233 17458 layer_factory.hpp:77] Creating layer conv9/dw/relu
I0628 16:42:39.629253 17458 net.cpp:100] Creating Layer conv9/dw/relu
I0628 16:42:39.629256 17458 net.cpp:434] conv9/dw/relu <- conv9/dw
I0628 16:42:39.629293 17458 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I0628 16:42:39.630080 17458 net.cpp:150] Setting up conv9/dw/relu
I0628 16:42:39.630091 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.630095 17458 net.cpp:165] Memory required for data: 539854912
I0628 16:42:39.630098 17458 layer_factory.hpp:77] Creating layer conv9
I0628 16:42:39.630106 17458 net.cpp:100] Creating Layer conv9
I0628 16:42:39.630110 17458 net.cpp:434] conv9 <- conv9/dw
I0628 16:42:39.630115 17458 net.cpp:408] conv9 -> conv9
I0628 16:42:39.635095 17458 net.cpp:150] Setting up conv9
I0628 16:42:39.635109 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.635113 17458 net.cpp:165] Memory required for data: 542812224
I0628 16:42:39.635118 17458 layer_factory.hpp:77] Creating layer conv9/bn
I0628 16:42:39.635125 17458 net.cpp:100] Creating Layer conv9/bn
I0628 16:42:39.635129 17458 net.cpp:434] conv9/bn <- conv9
I0628 16:42:39.635134 17458 net.cpp:395] conv9/bn -> conv9 (in-place)
I0628 16:42:39.635435 17458 net.cpp:150] Setting up conv9/bn
I0628 16:42:39.635442 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.635445 17458 net.cpp:165] Memory required for data: 545769536
I0628 16:42:39.635450 17458 layer_factory.hpp:77] Creating layer conv9/scale
I0628 16:42:39.635457 17458 net.cpp:100] Creating Layer conv9/scale
I0628 16:42:39.635460 17458 net.cpp:434] conv9/scale <- conv9
I0628 16:42:39.635466 17458 net.cpp:395] conv9/scale -> conv9 (in-place)
I0628 16:42:39.635546 17458 layer_factory.hpp:77] Creating layer conv9/scale
I0628 16:42:39.635774 17458 net.cpp:150] Setting up conv9/scale
I0628 16:42:39.635780 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.635784 17458 net.cpp:165] Memory required for data: 548726848
I0628 16:42:39.635788 17458 layer_factory.hpp:77] Creating layer conv9/relu
I0628 16:42:39.635794 17458 net.cpp:100] Creating Layer conv9/relu
I0628 16:42:39.635798 17458 net.cpp:434] conv9/relu <- conv9
I0628 16:42:39.635802 17458 net.cpp:395] conv9/relu -> conv9 (in-place)
I0628 16:42:39.636581 17458 net.cpp:150] Setting up conv9/relu
I0628 16:42:39.636591 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.636595 17458 net.cpp:165] Memory required for data: 551684160
I0628 16:42:39.636598 17458 layer_factory.hpp:77] Creating layer conv10/dw
I0628 16:42:39.636608 17458 net.cpp:100] Creating Layer conv10/dw
I0628 16:42:39.636611 17458 net.cpp:434] conv10/dw <- conv9
I0628 16:42:39.636617 17458 net.cpp:408] conv10/dw -> conv10/dw
I0628 16:42:39.636926 17458 net.cpp:150] Setting up conv10/dw
I0628 16:42:39.636934 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.636936 17458 net.cpp:165] Memory required for data: 554641472
I0628 16:42:39.636940 17458 layer_factory.hpp:77] Creating layer conv10/dw/bn
I0628 16:42:39.636946 17458 net.cpp:100] Creating Layer conv10/dw/bn
I0628 16:42:39.636950 17458 net.cpp:434] conv10/dw/bn <- conv10/dw
I0628 16:42:39.636955 17458 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I0628 16:42:39.637231 17458 net.cpp:150] Setting up conv10/dw/bn
I0628 16:42:39.637238 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.637241 17458 net.cpp:165] Memory required for data: 557598784
I0628 16:42:39.637246 17458 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0628 16:42:39.637251 17458 net.cpp:100] Creating Layer conv10/dw/scale
I0628 16:42:39.637254 17458 net.cpp:434] conv10/dw/scale <- conv10/dw
I0628 16:42:39.637261 17458 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I0628 16:42:39.637357 17458 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0628 16:42:39.637604 17458 net.cpp:150] Setting up conv10/dw/scale
I0628 16:42:39.637610 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.637614 17458 net.cpp:165] Memory required for data: 560556096
I0628 16:42:39.637619 17458 layer_factory.hpp:77] Creating layer conv10/dw/relu
I0628 16:42:39.637624 17458 net.cpp:100] Creating Layer conv10/dw/relu
I0628 16:42:39.637627 17458 net.cpp:434] conv10/dw/relu <- conv10/dw
I0628 16:42:39.637645 17458 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I0628 16:42:39.638478 17458 net.cpp:150] Setting up conv10/dw/relu
I0628 16:42:39.638490 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.638494 17458 net.cpp:165] Memory required for data: 563513408
I0628 16:42:39.638515 17458 layer_factory.hpp:77] Creating layer conv10
I0628 16:42:39.638525 17458 net.cpp:100] Creating Layer conv10
I0628 16:42:39.638543 17458 net.cpp:434] conv10 <- conv10/dw
I0628 16:42:39.638548 17458 net.cpp:408] conv10 -> conv10
I0628 16:42:39.643712 17458 net.cpp:150] Setting up conv10
I0628 16:42:39.643728 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.643731 17458 net.cpp:165] Memory required for data: 566470720
I0628 16:42:39.643738 17458 layer_factory.hpp:77] Creating layer conv10/bn
I0628 16:42:39.643745 17458 net.cpp:100] Creating Layer conv10/bn
I0628 16:42:39.643749 17458 net.cpp:434] conv10/bn <- conv10
I0628 16:42:39.643754 17458 net.cpp:395] conv10/bn -> conv10 (in-place)
I0628 16:42:39.644045 17458 net.cpp:150] Setting up conv10/bn
I0628 16:42:39.644052 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.644055 17458 net.cpp:165] Memory required for data: 569428032
I0628 16:42:39.644060 17458 layer_factory.hpp:77] Creating layer conv10/scale
I0628 16:42:39.644068 17458 net.cpp:100] Creating Layer conv10/scale
I0628 16:42:39.644073 17458 net.cpp:434] conv10/scale <- conv10
I0628 16:42:39.644076 17458 net.cpp:395] conv10/scale -> conv10 (in-place)
I0628 16:42:39.644157 17458 layer_factory.hpp:77] Creating layer conv10/scale
I0628 16:42:39.644381 17458 net.cpp:150] Setting up conv10/scale
I0628 16:42:39.644387 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.644390 17458 net.cpp:165] Memory required for data: 572385344
I0628 16:42:39.644394 17458 layer_factory.hpp:77] Creating layer conv10/relu
I0628 16:42:39.644400 17458 net.cpp:100] Creating Layer conv10/relu
I0628 16:42:39.644404 17458 net.cpp:434] conv10/relu <- conv10
I0628 16:42:39.644408 17458 net.cpp:395] conv10/relu -> conv10 (in-place)
I0628 16:42:39.645047 17458 net.cpp:150] Setting up conv10/relu
I0628 16:42:39.645056 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.645059 17458 net.cpp:165] Memory required for data: 575342656
I0628 16:42:39.645062 17458 layer_factory.hpp:77] Creating layer conv11/dw
I0628 16:42:39.645071 17458 net.cpp:100] Creating Layer conv11/dw
I0628 16:42:39.645074 17458 net.cpp:434] conv11/dw <- conv10
I0628 16:42:39.645081 17458 net.cpp:408] conv11/dw -> conv11/dw
I0628 16:42:39.645447 17458 net.cpp:150] Setting up conv11/dw
I0628 16:42:39.645455 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.645458 17458 net.cpp:165] Memory required for data: 578299968
I0628 16:42:39.645462 17458 layer_factory.hpp:77] Creating layer conv11/dw/bn
I0628 16:42:39.645467 17458 net.cpp:100] Creating Layer conv11/dw/bn
I0628 16:42:39.645471 17458 net.cpp:434] conv11/dw/bn <- conv11/dw
I0628 16:42:39.645475 17458 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I0628 16:42:39.645700 17458 net.cpp:150] Setting up conv11/dw/bn
I0628 16:42:39.645706 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.645709 17458 net.cpp:165] Memory required for data: 581257280
I0628 16:42:39.645723 17458 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0628 16:42:39.645730 17458 net.cpp:100] Creating Layer conv11/dw/scale
I0628 16:42:39.645732 17458 net.cpp:434] conv11/dw/scale <- conv11/dw
I0628 16:42:39.645737 17458 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I0628 16:42:39.645783 17458 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0628 16:42:39.645948 17458 net.cpp:150] Setting up conv11/dw/scale
I0628 16:42:39.645954 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.645957 17458 net.cpp:165] Memory required for data: 584214592
I0628 16:42:39.645962 17458 layer_factory.hpp:77] Creating layer conv11/dw/relu
I0628 16:42:39.645968 17458 net.cpp:100] Creating Layer conv11/dw/relu
I0628 16:42:39.645972 17458 net.cpp:434] conv11/dw/relu <- conv11/dw
I0628 16:42:39.645990 17458 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I0628 16:42:39.646745 17458 net.cpp:150] Setting up conv11/dw/relu
I0628 16:42:39.646755 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.646759 17458 net.cpp:165] Memory required for data: 587171904
I0628 16:42:39.646762 17458 layer_factory.hpp:77] Creating layer conv11
I0628 16:42:39.646771 17458 net.cpp:100] Creating Layer conv11
I0628 16:42:39.646775 17458 net.cpp:434] conv11 <- conv11/dw
I0628 16:42:39.646781 17458 net.cpp:408] conv11 -> conv11
I0628 16:42:39.651937 17458 net.cpp:150] Setting up conv11
I0628 16:42:39.651952 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.651954 17458 net.cpp:165] Memory required for data: 590129216
I0628 16:42:39.651960 17458 layer_factory.hpp:77] Creating layer conv11/bn
I0628 16:42:39.651983 17458 net.cpp:100] Creating Layer conv11/bn
I0628 16:42:39.651986 17458 net.cpp:434] conv11/bn <- conv11
I0628 16:42:39.651991 17458 net.cpp:395] conv11/bn -> conv11 (in-place)
I0628 16:42:39.652279 17458 net.cpp:150] Setting up conv11/bn
I0628 16:42:39.652287 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.652289 17458 net.cpp:165] Memory required for data: 593086528
I0628 16:42:39.652295 17458 layer_factory.hpp:77] Creating layer conv11/scale
I0628 16:42:39.652302 17458 net.cpp:100] Creating Layer conv11/scale
I0628 16:42:39.652307 17458 net.cpp:434] conv11/scale <- conv11
I0628 16:42:39.652310 17458 net.cpp:395] conv11/scale -> conv11 (in-place)
I0628 16:42:39.652392 17458 layer_factory.hpp:77] Creating layer conv11/scale
I0628 16:42:39.652611 17458 net.cpp:150] Setting up conv11/scale
I0628 16:42:39.652616 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.652619 17458 net.cpp:165] Memory required for data: 596043840
I0628 16:42:39.652624 17458 layer_factory.hpp:77] Creating layer conv11/relu
I0628 16:42:39.652631 17458 net.cpp:100] Creating Layer conv11/relu
I0628 16:42:39.652633 17458 net.cpp:434] conv11/relu <- conv11
I0628 16:42:39.652637 17458 net.cpp:395] conv11/relu -> conv11 (in-place)
I0628 16:42:39.653465 17458 net.cpp:150] Setting up conv11/relu
I0628 16:42:39.653475 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.653478 17458 net.cpp:165] Memory required for data: 599001152
I0628 16:42:39.653481 17458 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I0628 16:42:39.653488 17458 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I0628 16:42:39.653492 17458 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I0628 16:42:39.653498 17458 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I0628 16:42:39.653507 17458 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I0628 16:42:39.653513 17458 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I0628 16:42:39.653538 17458 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I0628 16:42:39.653651 17458 net.cpp:150] Setting up conv11_conv11/relu_0_split
I0628 16:42:39.653658 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.653662 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.653666 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.653669 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.653672 17458 net.cpp:165] Memory required for data: 610830400
I0628 16:42:39.653676 17458 layer_factory.hpp:77] Creating layer conv12/dw
I0628 16:42:39.653687 17458 net.cpp:100] Creating Layer conv12/dw
I0628 16:42:39.653690 17458 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I0628 16:42:39.653698 17458 net.cpp:408] conv12/dw -> conv12/dw
I0628 16:42:39.654023 17458 net.cpp:150] Setting up conv12/dw
I0628 16:42:39.654031 17458 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0628 16:42:39.654033 17458 net.cpp:165] Memory required for data: 611649600
I0628 16:42:39.654037 17458 layer_factory.hpp:77] Creating layer conv12/dw/bn
I0628 16:42:39.654043 17458 net.cpp:100] Creating Layer conv12/dw/bn
I0628 16:42:39.654060 17458 net.cpp:434] conv12/dw/bn <- conv12/dw
I0628 16:42:39.654065 17458 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I0628 16:42:39.654331 17458 net.cpp:150] Setting up conv12/dw/bn
I0628 16:42:39.654337 17458 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0628 16:42:39.654340 17458 net.cpp:165] Memory required for data: 612468800
I0628 16:42:39.654346 17458 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0628 16:42:39.654352 17458 net.cpp:100] Creating Layer conv12/dw/scale
I0628 16:42:39.654356 17458 net.cpp:434] conv12/dw/scale <- conv12/dw
I0628 16:42:39.654361 17458 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I0628 16:42:39.654435 17458 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0628 16:42:39.654672 17458 net.cpp:150] Setting up conv12/dw/scale
I0628 16:42:39.654678 17458 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0628 16:42:39.654682 17458 net.cpp:165] Memory required for data: 613288000
I0628 16:42:39.654686 17458 layer_factory.hpp:77] Creating layer conv12/dw/relu
I0628 16:42:39.654690 17458 net.cpp:100] Creating Layer conv12/dw/relu
I0628 16:42:39.654695 17458 net.cpp:434] conv12/dw/relu <- conv12/dw
I0628 16:42:39.654700 17458 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I0628 16:42:39.655351 17458 net.cpp:150] Setting up conv12/dw/relu
I0628 16:42:39.655359 17458 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0628 16:42:39.655364 17458 net.cpp:165] Memory required for data: 614107200
I0628 16:42:39.655366 17458 layer_factory.hpp:77] Creating layer conv12
I0628 16:42:39.655395 17458 net.cpp:100] Creating Layer conv12
I0628 16:42:39.655398 17458 net.cpp:434] conv12 <- conv12/dw
I0628 16:42:39.655403 17458 net.cpp:408] conv12 -> conv12
I0628 16:42:39.663199 17458 net.cpp:150] Setting up conv12
I0628 16:42:39.663220 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.663223 17458 net.cpp:165] Memory required for data: 615745600
I0628 16:42:39.663230 17458 layer_factory.hpp:77] Creating layer conv12/bn
I0628 16:42:39.663239 17458 net.cpp:100] Creating Layer conv12/bn
I0628 16:42:39.663244 17458 net.cpp:434] conv12/bn <- conv12
I0628 16:42:39.663250 17458 net.cpp:395] conv12/bn -> conv12 (in-place)
I0628 16:42:39.663523 17458 net.cpp:150] Setting up conv12/bn
I0628 16:42:39.663530 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.663533 17458 net.cpp:165] Memory required for data: 617384000
I0628 16:42:39.663539 17458 layer_factory.hpp:77] Creating layer conv12/scale
I0628 16:42:39.663547 17458 net.cpp:100] Creating Layer conv12/scale
I0628 16:42:39.663550 17458 net.cpp:434] conv12/scale <- conv12
I0628 16:42:39.663555 17458 net.cpp:395] conv12/scale -> conv12 (in-place)
I0628 16:42:39.663659 17458 layer_factory.hpp:77] Creating layer conv12/scale
I0628 16:42:39.663866 17458 net.cpp:150] Setting up conv12/scale
I0628 16:42:39.663873 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.663877 17458 net.cpp:165] Memory required for data: 619022400
I0628 16:42:39.663883 17458 layer_factory.hpp:77] Creating layer conv12/relu
I0628 16:42:39.663888 17458 net.cpp:100] Creating Layer conv12/relu
I0628 16:42:39.663892 17458 net.cpp:434] conv12/relu <- conv12
I0628 16:42:39.663897 17458 net.cpp:395] conv12/relu -> conv12 (in-place)
I0628 16:42:39.664672 17458 net.cpp:150] Setting up conv12/relu
I0628 16:42:39.664682 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.664686 17458 net.cpp:165] Memory required for data: 620660800
I0628 16:42:39.664690 17458 layer_factory.hpp:77] Creating layer conv13/dw
I0628 16:42:39.664700 17458 net.cpp:100] Creating Layer conv13/dw
I0628 16:42:39.664702 17458 net.cpp:434] conv13/dw <- conv12
I0628 16:42:39.664710 17458 net.cpp:408] conv13/dw -> conv13/dw
I0628 16:42:39.665091 17458 net.cpp:150] Setting up conv13/dw
I0628 16:42:39.665097 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.665100 17458 net.cpp:165] Memory required for data: 622299200
I0628 16:42:39.665105 17458 layer_factory.hpp:77] Creating layer conv13/dw/bn
I0628 16:42:39.665110 17458 net.cpp:100] Creating Layer conv13/dw/bn
I0628 16:42:39.665128 17458 net.cpp:434] conv13/dw/bn <- conv13/dw
I0628 16:42:39.665134 17458 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I0628 16:42:39.665473 17458 net.cpp:150] Setting up conv13/dw/bn
I0628 16:42:39.665482 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.665484 17458 net.cpp:165] Memory required for data: 623937600
I0628 16:42:39.665489 17458 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0628 16:42:39.665495 17458 net.cpp:100] Creating Layer conv13/dw/scale
I0628 16:42:39.665499 17458 net.cpp:434] conv13/dw/scale <- conv13/dw
I0628 16:42:39.665503 17458 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I0628 16:42:39.665562 17458 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0628 16:42:39.665781 17458 net.cpp:150] Setting up conv13/dw/scale
I0628 16:42:39.665787 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.665791 17458 net.cpp:165] Memory required for data: 625576000
I0628 16:42:39.665796 17458 layer_factory.hpp:77] Creating layer conv13/dw/relu
I0628 16:42:39.665799 17458 net.cpp:100] Creating Layer conv13/dw/relu
I0628 16:42:39.665803 17458 net.cpp:434] conv13/dw/relu <- conv13/dw
I0628 16:42:39.665807 17458 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I0628 16:42:39.666615 17458 net.cpp:150] Setting up conv13/dw/relu
I0628 16:42:39.666625 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.666628 17458 net.cpp:165] Memory required for data: 627214400
I0628 16:42:39.666631 17458 layer_factory.hpp:77] Creating layer conv13
I0628 16:42:39.666640 17458 net.cpp:100] Creating Layer conv13
I0628 16:42:39.666643 17458 net.cpp:434] conv13 <- conv13/dw
I0628 16:42:39.666651 17458 net.cpp:408] conv13 -> conv13
I0628 16:42:39.679230 17458 net.cpp:150] Setting up conv13
I0628 16:42:39.679250 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.679255 17458 net.cpp:165] Memory required for data: 628852800
I0628 16:42:39.679280 17458 layer_factory.hpp:77] Creating layer conv13/bn
I0628 16:42:39.679289 17458 net.cpp:100] Creating Layer conv13/bn
I0628 16:42:39.679294 17458 net.cpp:434] conv13/bn <- conv13
I0628 16:42:39.679301 17458 net.cpp:395] conv13/bn -> conv13 (in-place)
I0628 16:42:39.679616 17458 net.cpp:150] Setting up conv13/bn
I0628 16:42:39.679623 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.679626 17458 net.cpp:165] Memory required for data: 630491200
I0628 16:42:39.679651 17458 layer_factory.hpp:77] Creating layer conv13/scale
I0628 16:42:39.679658 17458 net.cpp:100] Creating Layer conv13/scale
I0628 16:42:39.679662 17458 net.cpp:434] conv13/scale <- conv13
I0628 16:42:39.679667 17458 net.cpp:395] conv13/scale -> conv13 (in-place)
I0628 16:42:39.679761 17458 layer_factory.hpp:77] Creating layer conv13/scale
I0628 16:42:39.680013 17458 net.cpp:150] Setting up conv13/scale
I0628 16:42:39.680020 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.680023 17458 net.cpp:165] Memory required for data: 632129600
I0628 16:42:39.680028 17458 layer_factory.hpp:77] Creating layer conv13/relu
I0628 16:42:39.680033 17458 net.cpp:100] Creating Layer conv13/relu
I0628 16:42:39.680037 17458 net.cpp:434] conv13/relu <- conv13
I0628 16:42:39.680040 17458 net.cpp:395] conv13/relu -> conv13 (in-place)
I0628 16:42:39.680944 17458 net.cpp:150] Setting up conv13/relu
I0628 16:42:39.680954 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.680958 17458 net.cpp:165] Memory required for data: 633768000
I0628 16:42:39.680979 17458 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I0628 16:42:39.680986 17458 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I0628 16:42:39.680990 17458 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I0628 16:42:39.680996 17458 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I0628 16:42:39.681005 17458 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I0628 16:42:39.681030 17458 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I0628 16:42:39.681084 17458 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I0628 16:42:39.681241 17458 net.cpp:150] Setting up conv13_conv13/relu_0_split
I0628 16:42:39.681248 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.681252 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.681257 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.681259 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.681262 17458 net.cpp:165] Memory required for data: 640321600
I0628 16:42:39.681267 17458 layer_factory.hpp:77] Creating layer conv14_1
I0628 16:42:39.681275 17458 net.cpp:100] Creating Layer conv14_1
I0628 16:42:39.681280 17458 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I0628 16:42:39.681286 17458 net.cpp:408] conv14_1 -> conv14_1
I0628 16:42:39.686802 17458 net.cpp:150] Setting up conv14_1
I0628 16:42:39.686818 17458 net.cpp:157] Top shape: 4 256 10 10 (102400)
I0628 16:42:39.686822 17458 net.cpp:165] Memory required for data: 640731200
I0628 16:42:39.686846 17458 layer_factory.hpp:77] Creating layer conv14_1/bn
I0628 16:42:39.686854 17458 net.cpp:100] Creating Layer conv14_1/bn
I0628 16:42:39.686858 17458 net.cpp:434] conv14_1/bn <- conv14_1
I0628 16:42:39.686864 17458 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I0628 16:42:39.687115 17458 net.cpp:150] Setting up conv14_1/bn
I0628 16:42:39.687122 17458 net.cpp:157] Top shape: 4 256 10 10 (102400)
I0628 16:42:39.687125 17458 net.cpp:165] Memory required for data: 641140800
I0628 16:42:39.687150 17458 layer_factory.hpp:77] Creating layer conv14_1/scale
I0628 16:42:39.687155 17458 net.cpp:100] Creating Layer conv14_1/scale
I0628 16:42:39.687173 17458 net.cpp:434] conv14_1/scale <- conv14_1
I0628 16:42:39.687180 17458 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I0628 16:42:39.687273 17458 layer_factory.hpp:77] Creating layer conv14_1/scale
I0628 16:42:39.687484 17458 net.cpp:150] Setting up conv14_1/scale
I0628 16:42:39.687491 17458 net.cpp:157] Top shape: 4 256 10 10 (102400)
I0628 16:42:39.687494 17458 net.cpp:165] Memory required for data: 641550400
I0628 16:42:39.687499 17458 layer_factory.hpp:77] Creating layer conv14_1/relu
I0628 16:42:39.687522 17458 net.cpp:100] Creating Layer conv14_1/relu
I0628 16:42:39.687526 17458 net.cpp:434] conv14_1/relu <- conv14_1
I0628 16:42:39.687530 17458 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I0628 16:42:39.688179 17458 net.cpp:150] Setting up conv14_1/relu
I0628 16:42:39.688187 17458 net.cpp:157] Top shape: 4 256 10 10 (102400)
I0628 16:42:39.688190 17458 net.cpp:165] Memory required for data: 641960000
I0628 16:42:39.688194 17458 layer_factory.hpp:77] Creating layer conv14_2
I0628 16:42:39.688221 17458 net.cpp:100] Creating Layer conv14_2
I0628 16:42:39.688225 17458 net.cpp:434] conv14_2 <- conv14_1
I0628 16:42:39.688230 17458 net.cpp:408] conv14_2 -> conv14_2
I0628 16:42:39.702479 17458 net.cpp:150] Setting up conv14_2
I0628 16:42:39.702502 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.702505 17458 net.cpp:165] Memory required for data: 642164800
I0628 16:42:39.702512 17458 layer_factory.hpp:77] Creating layer conv14_2/bn
I0628 16:42:39.702522 17458 net.cpp:100] Creating Layer conv14_2/bn
I0628 16:42:39.702527 17458 net.cpp:434] conv14_2/bn <- conv14_2
I0628 16:42:39.702533 17458 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I0628 16:42:39.702850 17458 net.cpp:150] Setting up conv14_2/bn
I0628 16:42:39.702857 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.702860 17458 net.cpp:165] Memory required for data: 642369600
I0628 16:42:39.702867 17458 layer_factory.hpp:77] Creating layer conv14_2/scale
I0628 16:42:39.702872 17458 net.cpp:100] Creating Layer conv14_2/scale
I0628 16:42:39.702877 17458 net.cpp:434] conv14_2/scale <- conv14_2
I0628 16:42:39.702883 17458 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I0628 16:42:39.702960 17458 layer_factory.hpp:77] Creating layer conv14_2/scale
I0628 16:42:39.703197 17458 net.cpp:150] Setting up conv14_2/scale
I0628 16:42:39.703202 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.703220 17458 net.cpp:165] Memory required for data: 642574400
I0628 16:42:39.703225 17458 layer_factory.hpp:77] Creating layer conv14_2/relu
I0628 16:42:39.703230 17458 net.cpp:100] Creating Layer conv14_2/relu
I0628 16:42:39.703233 17458 net.cpp:434] conv14_2/relu <- conv14_2
I0628 16:42:39.703239 17458 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I0628 16:42:39.704042 17458 net.cpp:150] Setting up conv14_2/relu
I0628 16:42:39.704053 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.704056 17458 net.cpp:165] Memory required for data: 642779200
I0628 16:42:39.704061 17458 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I0628 16:42:39.704066 17458 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I0628 16:42:39.704069 17458 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I0628 16:42:39.704077 17458 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I0628 16:42:39.704083 17458 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I0628 16:42:39.704088 17458 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I0628 16:42:39.704093 17458 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I0628 16:42:39.704229 17458 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I0628 16:42:39.704236 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.704239 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.704243 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.704246 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.704249 17458 net.cpp:165] Memory required for data: 643598400
I0628 16:42:39.704252 17458 layer_factory.hpp:77] Creating layer conv15_1
I0628 16:42:39.704262 17458 net.cpp:100] Creating Layer conv15_1
I0628 16:42:39.704265 17458 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I0628 16:42:39.704272 17458 net.cpp:408] conv15_1 -> conv15_1
I0628 16:42:39.707252 17458 net.cpp:150] Setting up conv15_1
I0628 16:42:39.707263 17458 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0628 16:42:39.707267 17458 net.cpp:165] Memory required for data: 643649600
I0628 16:42:39.707271 17458 layer_factory.hpp:77] Creating layer conv15_1/bn
I0628 16:42:39.707279 17458 net.cpp:100] Creating Layer conv15_1/bn
I0628 16:42:39.707283 17458 net.cpp:434] conv15_1/bn <- conv15_1
I0628 16:42:39.707288 17458 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I0628 16:42:39.707568 17458 net.cpp:150] Setting up conv15_1/bn
I0628 16:42:39.707576 17458 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0628 16:42:39.707578 17458 net.cpp:165] Memory required for data: 643700800
I0628 16:42:39.707584 17458 layer_factory.hpp:77] Creating layer conv15_1/scale
I0628 16:42:39.707589 17458 net.cpp:100] Creating Layer conv15_1/scale
I0628 16:42:39.707593 17458 net.cpp:434] conv15_1/scale <- conv15_1
I0628 16:42:39.707597 17458 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I0628 16:42:39.707679 17458 layer_factory.hpp:77] Creating layer conv15_1/scale
I0628 16:42:39.707906 17458 net.cpp:150] Setting up conv15_1/scale
I0628 16:42:39.707911 17458 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0628 16:42:39.707916 17458 net.cpp:165] Memory required for data: 643752000
I0628 16:42:39.707919 17458 layer_factory.hpp:77] Creating layer conv15_1/relu
I0628 16:42:39.707924 17458 net.cpp:100] Creating Layer conv15_1/relu
I0628 16:42:39.707927 17458 net.cpp:434] conv15_1/relu <- conv15_1
I0628 16:42:39.707932 17458 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I0628 16:42:39.708748 17458 net.cpp:150] Setting up conv15_1/relu
I0628 16:42:39.708758 17458 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0628 16:42:39.708761 17458 net.cpp:165] Memory required for data: 643803200
I0628 16:42:39.708765 17458 layer_factory.hpp:77] Creating layer conv15_2
I0628 16:42:39.708773 17458 net.cpp:100] Creating Layer conv15_2
I0628 16:42:39.708778 17458 net.cpp:434] conv15_2 <- conv15_1
I0628 16:42:39.708784 17458 net.cpp:408] conv15_2 -> conv15_2
I0628 16:42:39.715078 17458 net.cpp:150] Setting up conv15_2
I0628 16:42:39.715096 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.715101 17458 net.cpp:165] Memory required for data: 643840064
I0628 16:42:39.715106 17458 layer_factory.hpp:77] Creating layer conv15_2/bn
I0628 16:42:39.715127 17458 net.cpp:100] Creating Layer conv15_2/bn
I0628 16:42:39.715152 17458 net.cpp:434] conv15_2/bn <- conv15_2
I0628 16:42:39.715157 17458 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I0628 16:42:39.715479 17458 net.cpp:150] Setting up conv15_2/bn
I0628 16:42:39.715487 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.715489 17458 net.cpp:165] Memory required for data: 643876928
I0628 16:42:39.715495 17458 layer_factory.hpp:77] Creating layer conv15_2/scale
I0628 16:42:39.715502 17458 net.cpp:100] Creating Layer conv15_2/scale
I0628 16:42:39.715507 17458 net.cpp:434] conv15_2/scale <- conv15_2
I0628 16:42:39.715510 17458 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I0628 16:42:39.715590 17458 layer_factory.hpp:77] Creating layer conv15_2/scale
I0628 16:42:39.715795 17458 net.cpp:150] Setting up conv15_2/scale
I0628 16:42:39.715801 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.715804 17458 net.cpp:165] Memory required for data: 643913792
I0628 16:42:39.715826 17458 layer_factory.hpp:77] Creating layer conv15_2/relu
I0628 16:42:39.715839 17458 net.cpp:100] Creating Layer conv15_2/relu
I0628 16:42:39.715843 17458 net.cpp:434] conv15_2/relu <- conv15_2
I0628 16:42:39.715847 17458 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I0628 16:42:39.716665 17458 net.cpp:150] Setting up conv15_2/relu
I0628 16:42:39.716675 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.716678 17458 net.cpp:165] Memory required for data: 643950656
I0628 16:42:39.716682 17458 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I0628 16:42:39.716689 17458 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I0628 16:42:39.716693 17458 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I0628 16:42:39.716698 17458 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I0628 16:42:39.716704 17458 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I0628 16:42:39.716711 17458 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I0628 16:42:39.716717 17458 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I0628 16:42:39.716850 17458 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I0628 16:42:39.716856 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.716861 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.716864 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.716867 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.716871 17458 net.cpp:165] Memory required for data: 644098112
I0628 16:42:39.716873 17458 layer_factory.hpp:77] Creating layer conv16_1
I0628 16:42:39.716882 17458 net.cpp:100] Creating Layer conv16_1
I0628 16:42:39.716886 17458 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I0628 16:42:39.716892 17458 net.cpp:408] conv16_1 -> conv16_1
I0628 16:42:39.719630 17458 net.cpp:150] Setting up conv16_1
I0628 16:42:39.719641 17458 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0628 16:42:39.719645 17458 net.cpp:165] Memory required for data: 644116544
I0628 16:42:39.719650 17458 layer_factory.hpp:77] Creating layer conv16_1/bn
I0628 16:42:39.719656 17458 net.cpp:100] Creating Layer conv16_1/bn
I0628 16:42:39.719660 17458 net.cpp:434] conv16_1/bn <- conv16_1
I0628 16:42:39.719666 17458 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I0628 16:42:39.719959 17458 net.cpp:150] Setting up conv16_1/bn
I0628 16:42:39.719966 17458 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0628 16:42:39.719969 17458 net.cpp:165] Memory required for data: 644134976
I0628 16:42:39.719975 17458 layer_factory.hpp:77] Creating layer conv16_1/scale
I0628 16:42:39.719981 17458 net.cpp:100] Creating Layer conv16_1/scale
I0628 16:42:39.719998 17458 net.cpp:434] conv16_1/scale <- conv16_1
I0628 16:42:39.720005 17458 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I0628 16:42:39.720104 17458 layer_factory.hpp:77] Creating layer conv16_1/scale
I0628 16:42:39.720312 17458 net.cpp:150] Setting up conv16_1/scale
I0628 16:42:39.720319 17458 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0628 16:42:39.720321 17458 net.cpp:165] Memory required for data: 644153408
I0628 16:42:39.720326 17458 layer_factory.hpp:77] Creating layer conv16_1/relu
I0628 16:42:39.720330 17458 net.cpp:100] Creating Layer conv16_1/relu
I0628 16:42:39.720335 17458 net.cpp:434] conv16_1/relu <- conv16_1
I0628 16:42:39.720338 17458 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I0628 16:42:39.721112 17458 net.cpp:150] Setting up conv16_1/relu
I0628 16:42:39.721122 17458 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0628 16:42:39.721124 17458 net.cpp:165] Memory required for data: 644171840
I0628 16:42:39.721146 17458 layer_factory.hpp:77] Creating layer conv16_2
I0628 16:42:39.721158 17458 net.cpp:100] Creating Layer conv16_2
I0628 16:42:39.721161 17458 net.cpp:434] conv16_2 <- conv16_1
I0628 16:42:39.721168 17458 net.cpp:408] conv16_2 -> conv16_2
I0628 16:42:39.726821 17458 net.cpp:150] Setting up conv16_2
I0628 16:42:39.726840 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.726845 17458 net.cpp:165] Memory required for data: 644188224
I0628 16:42:39.726851 17458 layer_factory.hpp:77] Creating layer conv16_2/bn
I0628 16:42:39.726860 17458 net.cpp:100] Creating Layer conv16_2/bn
I0628 16:42:39.726864 17458 net.cpp:434] conv16_2/bn <- conv16_2
I0628 16:42:39.726869 17458 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I0628 16:42:39.727149 17458 net.cpp:150] Setting up conv16_2/bn
I0628 16:42:39.727155 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.727159 17458 net.cpp:165] Memory required for data: 644204608
I0628 16:42:39.727164 17458 layer_factory.hpp:77] Creating layer conv16_2/scale
I0628 16:42:39.727171 17458 net.cpp:100] Creating Layer conv16_2/scale
I0628 16:42:39.727175 17458 net.cpp:434] conv16_2/scale <- conv16_2
I0628 16:42:39.727180 17458 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I0628 16:42:39.727258 17458 layer_factory.hpp:77] Creating layer conv16_2/scale
I0628 16:42:39.727463 17458 net.cpp:150] Setting up conv16_2/scale
I0628 16:42:39.727469 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.727473 17458 net.cpp:165] Memory required for data: 644220992
I0628 16:42:39.727478 17458 layer_factory.hpp:77] Creating layer conv16_2/relu
I0628 16:42:39.727483 17458 net.cpp:100] Creating Layer conv16_2/relu
I0628 16:42:39.727488 17458 net.cpp:434] conv16_2/relu <- conv16_2
I0628 16:42:39.727491 17458 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I0628 16:42:39.728269 17458 net.cpp:150] Setting up conv16_2/relu
I0628 16:42:39.728281 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.728283 17458 net.cpp:165] Memory required for data: 644237376
I0628 16:42:39.728287 17458 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I0628 16:42:39.728294 17458 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I0628 16:42:39.728298 17458 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I0628 16:42:39.728303 17458 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I0628 16:42:39.728310 17458 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I0628 16:42:39.728317 17458 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I0628 16:42:39.728322 17458 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I0628 16:42:39.728442 17458 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I0628 16:42:39.728449 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.728453 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.728456 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.728461 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.728463 17458 net.cpp:165] Memory required for data: 644302912
I0628 16:42:39.728479 17458 layer_factory.hpp:77] Creating layer conv17_1
I0628 16:42:39.728490 17458 net.cpp:100] Creating Layer conv17_1
I0628 16:42:39.728494 17458 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I0628 16:42:39.728518 17458 net.cpp:408] conv17_1 -> conv17_1
I0628 16:42:39.731293 17458 net.cpp:150] Setting up conv17_1
I0628 16:42:39.731305 17458 net.cpp:157] Top shape: 4 64 2 2 (1024)
I0628 16:42:39.731309 17458 net.cpp:165] Memory required for data: 644307008
I0628 16:42:39.731314 17458 layer_factory.hpp:77] Creating layer conv17_1/bn
I0628 16:42:39.731320 17458 net.cpp:100] Creating Layer conv17_1/bn
I0628 16:42:39.731325 17458 net.cpp:434] conv17_1/bn <- conv17_1
I0628 16:42:39.731330 17458 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I0628 16:42:39.731632 17458 net.cpp:150] Setting up conv17_1/bn
I0628 16:42:39.731639 17458 net.cpp:157] Top shape: 4 64 2 2 (1024)
I0628 16:42:39.731642 17458 net.cpp:165] Memory required for data: 644311104
I0628 16:42:39.731647 17458 layer_factory.hpp:77] Creating layer conv17_1/scale
I0628 16:42:39.731653 17458 net.cpp:100] Creating Layer conv17_1/scale
I0628 16:42:39.731657 17458 net.cpp:434] conv17_1/scale <- conv17_1
I0628 16:42:39.731668 17458 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I0628 16:42:39.731758 17458 layer_factory.hpp:77] Creating layer conv17_1/scale
I0628 16:42:39.731986 17458 net.cpp:150] Setting up conv17_1/scale
I0628 16:42:39.731992 17458 net.cpp:157] Top shape: 4 64 2 2 (1024)
I0628 16:42:39.731997 17458 net.cpp:165] Memory required for data: 644315200
I0628 16:42:39.732002 17458 layer_factory.hpp:77] Creating layer conv17_1/relu
I0628 16:42:39.732005 17458 net.cpp:100] Creating Layer conv17_1/relu
I0628 16:42:39.732009 17458 net.cpp:434] conv17_1/relu <- conv17_1
I0628 16:42:39.732014 17458 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I0628 16:42:39.732810 17458 net.cpp:150] Setting up conv17_1/relu
I0628 16:42:39.732820 17458 net.cpp:157] Top shape: 4 64 2 2 (1024)
I0628 16:42:39.732823 17458 net.cpp:165] Memory required for data: 644319296
I0628 16:42:39.732827 17458 layer_factory.hpp:77] Creating layer conv17_2
I0628 16:42:39.732836 17458 net.cpp:100] Creating Layer conv17_2
I0628 16:42:39.732841 17458 net.cpp:434] conv17_2 <- conv17_1
I0628 16:42:39.732846 17458 net.cpp:408] conv17_2 -> conv17_2
I0628 16:42:39.736438 17458 net.cpp:150] Setting up conv17_2
I0628 16:42:39.736451 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.736455 17458 net.cpp:165] Memory required for data: 644321344
I0628 16:42:39.736461 17458 layer_factory.hpp:77] Creating layer conv17_2/bn
I0628 16:42:39.736470 17458 net.cpp:100] Creating Layer conv17_2/bn
I0628 16:42:39.736474 17458 net.cpp:434] conv17_2/bn <- conv17_2
I0628 16:42:39.736479 17458 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I0628 16:42:39.736779 17458 net.cpp:150] Setting up conv17_2/bn
I0628 16:42:39.736785 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.736788 17458 net.cpp:165] Memory required for data: 644323392
I0628 16:42:39.736794 17458 layer_factory.hpp:77] Creating layer conv17_2/scale
I0628 16:42:39.736802 17458 net.cpp:100] Creating Layer conv17_2/scale
I0628 16:42:39.736805 17458 net.cpp:434] conv17_2/scale <- conv17_2
I0628 16:42:39.736810 17458 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I0628 16:42:39.736891 17458 layer_factory.hpp:77] Creating layer conv17_2/scale
I0628 16:42:39.737112 17458 net.cpp:150] Setting up conv17_2/scale
I0628 16:42:39.737118 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.737120 17458 net.cpp:165] Memory required for data: 644325440
I0628 16:42:39.737124 17458 layer_factory.hpp:77] Creating layer conv17_2/relu
I0628 16:42:39.737129 17458 net.cpp:100] Creating Layer conv17_2/relu
I0628 16:42:39.737133 17458 net.cpp:434] conv17_2/relu <- conv17_2
I0628 16:42:39.737136 17458 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I0628 16:42:39.737931 17458 net.cpp:150] Setting up conv17_2/relu
I0628 16:42:39.737941 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.737958 17458 net.cpp:165] Memory required for data: 644327488
I0628 16:42:39.737962 17458 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I0628 16:42:39.737969 17458 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I0628 16:42:39.737973 17458 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I0628 16:42:39.737979 17458 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I0628 16:42:39.738013 17458 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I0628 16:42:39.738018 17458 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I0628 16:42:39.738150 17458 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I0628 16:42:39.738157 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.738160 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.738163 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.738166 17458 net.cpp:165] Memory required for data: 644333632
I0628 16:42:39.738169 17458 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I0628 16:42:39.738178 17458 net.cpp:100] Creating Layer conv11_mbox_loc
I0628 16:42:39.738183 17458 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I0628 16:42:39.738188 17458 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I0628 16:42:39.740873 17458 net.cpp:150] Setting up conv11_mbox_loc
I0628 16:42:39.740885 17458 net.cpp:157] Top shape: 4 12 19 19 (17328)
I0628 16:42:39.740888 17458 net.cpp:165] Memory required for data: 644402944
I0628 16:42:39.740895 17458 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I0628 16:42:39.740902 17458 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I0628 16:42:39.740906 17458 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I0628 16:42:39.740911 17458 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I0628 16:42:39.741075 17458 net.cpp:150] Setting up conv11_mbox_loc_perm
I0628 16:42:39.741082 17458 net.cpp:157] Top shape: 4 19 19 12 (17328)
I0628 16:42:39.741086 17458 net.cpp:165] Memory required for data: 644472256
I0628 16:42:39.741088 17458 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I0628 16:42:39.741093 17458 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I0628 16:42:39.741097 17458 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I0628 16:42:39.741104 17458 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I0628 16:42:39.741151 17458 net.cpp:150] Setting up conv11_mbox_loc_flat
I0628 16:42:39.741158 17458 net.cpp:157] Top shape: 4 4332 (17328)
I0628 16:42:39.741161 17458 net.cpp:165] Memory required for data: 644541568
I0628 16:42:39.741164 17458 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I0628 16:42:39.741186 17458 net.cpp:100] Creating Layer conv11_mbox_conf_new
I0628 16:42:39.741189 17458 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I0628 16:42:39.741215 17458 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I0628 16:42:39.743773 17458 net.cpp:150] Setting up conv11_mbox_conf_new
I0628 16:42:39.743785 17458 net.cpp:157] Top shape: 4 6 19 19 (8664)
I0628 16:42:39.743789 17458 net.cpp:165] Memory required for data: 644576224
I0628 16:42:39.743795 17458 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I0628 16:42:39.743803 17458 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I0628 16:42:39.743806 17458 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I0628 16:42:39.743811 17458 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I0628 16:42:39.743996 17458 net.cpp:150] Setting up conv11_mbox_conf_perm
I0628 16:42:39.744004 17458 net.cpp:157] Top shape: 4 19 19 6 (8664)
I0628 16:42:39.744006 17458 net.cpp:165] Memory required for data: 644610880
I0628 16:42:39.744009 17458 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I0628 16:42:39.744015 17458 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I0628 16:42:39.744019 17458 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I0628 16:42:39.744024 17458 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I0628 16:42:39.744083 17458 net.cpp:150] Setting up conv11_mbox_conf_flat
I0628 16:42:39.744107 17458 net.cpp:157] Top shape: 4 2166 (8664)
I0628 16:42:39.744112 17458 net.cpp:165] Memory required for data: 644645536
I0628 16:42:39.744114 17458 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I0628 16:42:39.744138 17458 net.cpp:100] Creating Layer conv11_mbox_priorbox
I0628 16:42:39.744141 17458 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I0628 16:42:39.744164 17458 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I0628 16:42:39.744171 17458 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I0628 16:42:39.744238 17458 net.cpp:150] Setting up conv11_mbox_priorbox
I0628 16:42:39.744244 17458 net.cpp:157] Top shape: 1 2 4332 (8664)
I0628 16:42:39.744247 17458 net.cpp:165] Memory required for data: 644680192
I0628 16:42:39.744251 17458 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I0628 16:42:39.744259 17458 net.cpp:100] Creating Layer conv13_mbox_loc
I0628 16:42:39.744263 17458 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I0628 16:42:39.744268 17458 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I0628 16:42:39.747211 17458 net.cpp:150] Setting up conv13_mbox_loc
I0628 16:42:39.747225 17458 net.cpp:157] Top shape: 4 24 10 10 (9600)
I0628 16:42:39.747227 17458 net.cpp:165] Memory required for data: 644718592
I0628 16:42:39.747233 17458 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I0628 16:42:39.747241 17458 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I0628 16:42:39.747244 17458 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I0628 16:42:39.747251 17458 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I0628 16:42:39.747416 17458 net.cpp:150] Setting up conv13_mbox_loc_perm
I0628 16:42:39.747422 17458 net.cpp:157] Top shape: 4 10 10 24 (9600)
I0628 16:42:39.747426 17458 net.cpp:165] Memory required for data: 644756992
I0628 16:42:39.747429 17458 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I0628 16:42:39.747436 17458 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I0628 16:42:39.747439 17458 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I0628 16:42:39.747443 17458 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I0628 16:42:39.747489 17458 net.cpp:150] Setting up conv13_mbox_loc_flat
I0628 16:42:39.747495 17458 net.cpp:157] Top shape: 4 2400 (9600)
I0628 16:42:39.747498 17458 net.cpp:165] Memory required for data: 644795392
I0628 16:42:39.747519 17458 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I0628 16:42:39.747545 17458 net.cpp:100] Creating Layer conv13_mbox_conf_new
I0628 16:42:39.747550 17458 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I0628 16:42:39.747570 17458 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I0628 16:42:39.750648 17458 net.cpp:150] Setting up conv13_mbox_conf_new
I0628 16:42:39.750659 17458 net.cpp:157] Top shape: 4 12 10 10 (4800)
I0628 16:42:39.750663 17458 net.cpp:165] Memory required for data: 644814592
I0628 16:42:39.750669 17458 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I0628 16:42:39.750676 17458 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I0628 16:42:39.750680 17458 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I0628 16:42:39.750685 17458 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I0628 16:42:39.750864 17458 net.cpp:150] Setting up conv13_mbox_conf_perm
I0628 16:42:39.750870 17458 net.cpp:157] Top shape: 4 10 10 12 (4800)
I0628 16:42:39.750874 17458 net.cpp:165] Memory required for data: 644833792
I0628 16:42:39.750876 17458 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I0628 16:42:39.750882 17458 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I0628 16:42:39.750886 17458 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I0628 16:42:39.750891 17458 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I0628 16:42:39.750918 17458 net.cpp:150] Setting up conv13_mbox_conf_flat
I0628 16:42:39.750943 17458 net.cpp:157] Top shape: 4 1200 (4800)
I0628 16:42:39.750972 17458 net.cpp:165] Memory required for data: 644852992
I0628 16:42:39.750977 17458 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I0628 16:42:39.750999 17458 net.cpp:100] Creating Layer conv13_mbox_priorbox
I0628 16:42:39.751019 17458 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I0628 16:42:39.751024 17458 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I0628 16:42:39.751049 17458 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I0628 16:42:39.751112 17458 net.cpp:150] Setting up conv13_mbox_priorbox
I0628 16:42:39.751118 17458 net.cpp:157] Top shape: 1 2 2400 (4800)
I0628 16:42:39.751121 17458 net.cpp:165] Memory required for data: 644872192
I0628 16:42:39.751124 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I0628 16:42:39.751132 17458 net.cpp:100] Creating Layer conv14_2_mbox_loc
I0628 16:42:39.751137 17458 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I0628 16:42:39.751143 17458 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I0628 16:42:39.753832 17458 net.cpp:150] Setting up conv14_2_mbox_loc
I0628 16:42:39.753845 17458 net.cpp:157] Top shape: 4 24 5 5 (2400)
I0628 16:42:39.753849 17458 net.cpp:165] Memory required for data: 644881792
I0628 16:42:39.753873 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I0628 16:42:39.753882 17458 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I0628 16:42:39.753886 17458 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I0628 16:42:39.753892 17458 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I0628 16:42:39.754040 17458 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I0628 16:42:39.754046 17458 net.cpp:157] Top shape: 4 5 5 24 (2400)
I0628 16:42:39.754050 17458 net.cpp:165] Memory required for data: 644891392
I0628 16:42:39.754053 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I0628 16:42:39.754078 17458 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I0628 16:42:39.754082 17458 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I0628 16:42:39.754087 17458 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I0628 16:42:39.754130 17458 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I0628 16:42:39.754137 17458 net.cpp:157] Top shape: 4 600 (2400)
I0628 16:42:39.754139 17458 net.cpp:165] Memory required for data: 644900992
I0628 16:42:39.754142 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I0628 16:42:39.754169 17458 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I0628 16:42:39.754174 17458 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I0628 16:42:39.754179 17458 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I0628 16:42:39.757251 17458 net.cpp:150] Setting up conv14_2_mbox_conf_new
I0628 16:42:39.757264 17458 net.cpp:157] Top shape: 4 12 5 5 (1200)
I0628 16:42:39.757267 17458 net.cpp:165] Memory required for data: 644905792
I0628 16:42:39.757273 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I0628 16:42:39.757280 17458 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I0628 16:42:39.757284 17458 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I0628 16:42:39.757292 17458 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I0628 16:42:39.757513 17458 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I0628 16:42:39.757520 17458 net.cpp:157] Top shape: 4 5 5 12 (1200)
I0628 16:42:39.757524 17458 net.cpp:165] Memory required for data: 644910592
I0628 16:42:39.757527 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I0628 16:42:39.757532 17458 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I0628 16:42:39.757535 17458 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I0628 16:42:39.757541 17458 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I0628 16:42:39.757589 17458 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I0628 16:42:39.757596 17458 net.cpp:157] Top shape: 4 300 (1200)
I0628 16:42:39.757647 17458 net.cpp:165] Memory required for data: 644915392
I0628 16:42:39.757650 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I0628 16:42:39.757676 17458 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I0628 16:42:39.757679 17458 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I0628 16:42:39.757704 17458 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I0628 16:42:39.757725 17458 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I0628 16:42:39.757771 17458 net.cpp:150] Setting up conv14_2_mbox_priorbox
I0628 16:42:39.757776 17458 net.cpp:157] Top shape: 1 2 600 (1200)
I0628 16:42:39.757779 17458 net.cpp:165] Memory required for data: 644920192
I0628 16:42:39.757783 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I0628 16:42:39.757815 17458 net.cpp:100] Creating Layer conv15_2_mbox_loc
I0628 16:42:39.757833 17458 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I0628 16:42:39.757838 17458 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I0628 16:42:39.760465 17458 net.cpp:150] Setting up conv15_2_mbox_loc
I0628 16:42:39.760476 17458 net.cpp:157] Top shape: 4 24 3 3 (864)
I0628 16:42:39.760479 17458 net.cpp:165] Memory required for data: 644923648
I0628 16:42:39.760484 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I0628 16:42:39.760490 17458 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I0628 16:42:39.760494 17458 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I0628 16:42:39.760501 17458 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I0628 16:42:39.760689 17458 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I0628 16:42:39.760695 17458 net.cpp:157] Top shape: 4 3 3 24 (864)
I0628 16:42:39.760699 17458 net.cpp:165] Memory required for data: 644927104
I0628 16:42:39.760701 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I0628 16:42:39.760706 17458 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I0628 16:42:39.760710 17458 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I0628 16:42:39.760715 17458 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I0628 16:42:39.760743 17458 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I0628 16:42:39.760767 17458 net.cpp:157] Top shape: 4 216 (864)
I0628 16:42:39.760771 17458 net.cpp:165] Memory required for data: 644930560
I0628 16:42:39.760774 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I0628 16:42:39.760802 17458 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I0628 16:42:39.760807 17458 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I0628 16:42:39.760828 17458 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I0628 16:42:39.763746 17458 net.cpp:150] Setting up conv15_2_mbox_conf_new
I0628 16:42:39.763756 17458 net.cpp:157] Top shape: 4 12 3 3 (432)
I0628 16:42:39.763761 17458 net.cpp:165] Memory required for data: 644932288
I0628 16:42:39.763767 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I0628 16:42:39.763773 17458 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I0628 16:42:39.763777 17458 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I0628 16:42:39.763782 17458 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I0628 16:42:39.763968 17458 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I0628 16:42:39.763975 17458 net.cpp:157] Top shape: 4 3 3 12 (432)
I0628 16:42:39.763978 17458 net.cpp:165] Memory required for data: 644934016
I0628 16:42:39.763981 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I0628 16:42:39.763988 17458 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I0628 16:42:39.763991 17458 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I0628 16:42:39.763996 17458 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I0628 16:42:39.764042 17458 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I0628 16:42:39.764048 17458 net.cpp:157] Top shape: 4 108 (432)
I0628 16:42:39.764051 17458 net.cpp:165] Memory required for data: 644935744
I0628 16:42:39.764086 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I0628 16:42:39.764109 17458 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I0628 16:42:39.764132 17458 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I0628 16:42:39.764150 17458 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I0628 16:42:39.764156 17458 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I0628 16:42:39.764240 17458 net.cpp:150] Setting up conv15_2_mbox_priorbox
I0628 16:42:39.764245 17458 net.cpp:157] Top shape: 1 2 216 (432)
I0628 16:42:39.764248 17458 net.cpp:165] Memory required for data: 644937472
I0628 16:42:39.764256 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I0628 16:42:39.764263 17458 net.cpp:100] Creating Layer conv16_2_mbox_loc
I0628 16:42:39.764267 17458 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I0628 16:42:39.764273 17458 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I0628 16:42:39.767081 17458 net.cpp:150] Setting up conv16_2_mbox_loc
I0628 16:42:39.767091 17458 net.cpp:157] Top shape: 4 24 2 2 (384)
I0628 16:42:39.767096 17458 net.cpp:165] Memory required for data: 644939008
I0628 16:42:39.767100 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I0628 16:42:39.767108 17458 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I0628 16:42:39.767112 17458 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I0628 16:42:39.767117 17458 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I0628 16:42:39.767302 17458 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I0628 16:42:39.767308 17458 net.cpp:157] Top shape: 4 2 2 24 (384)
I0628 16:42:39.767313 17458 net.cpp:165] Memory required for data: 644940544
I0628 16:42:39.767315 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I0628 16:42:39.767323 17458 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I0628 16:42:39.767326 17458 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I0628 16:42:39.767330 17458 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I0628 16:42:39.767376 17458 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I0628 16:42:39.767382 17458 net.cpp:157] Top shape: 4 96 (384)
I0628 16:42:39.767385 17458 net.cpp:165] Memory required for data: 644942080
I0628 16:42:39.767388 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I0628 16:42:39.767416 17458 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I0628 16:42:39.767433 17458 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I0628 16:42:39.767441 17458 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I0628 16:42:39.770053 17458 net.cpp:150] Setting up conv16_2_mbox_conf_new
I0628 16:42:39.770084 17458 net.cpp:157] Top shape: 4 12 2 2 (192)
I0628 16:42:39.770088 17458 net.cpp:165] Memory required for data: 644942848
I0628 16:42:39.770093 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I0628 16:42:39.770102 17458 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I0628 16:42:39.770105 17458 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I0628 16:42:39.770112 17458 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I0628 16:42:39.770328 17458 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I0628 16:42:39.770335 17458 net.cpp:157] Top shape: 4 2 2 12 (192)
I0628 16:42:39.770339 17458 net.cpp:165] Memory required for data: 644943616
I0628 16:42:39.770342 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I0628 16:42:39.770367 17458 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I0628 16:42:39.770371 17458 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I0628 16:42:39.770376 17458 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I0628 16:42:39.770452 17458 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I0628 16:42:39.770458 17458 net.cpp:157] Top shape: 4 48 (192)
I0628 16:42:39.770462 17458 net.cpp:165] Memory required for data: 644944384
I0628 16:42:39.770464 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I0628 16:42:39.770505 17458 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I0628 16:42:39.770509 17458 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I0628 16:42:39.770534 17458 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I0628 16:42:39.770553 17458 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I0628 16:42:39.770586 17458 net.cpp:150] Setting up conv16_2_mbox_priorbox
I0628 16:42:39.770592 17458 net.cpp:157] Top shape: 1 2 96 (192)
I0628 16:42:39.770596 17458 net.cpp:165] Memory required for data: 644945152
I0628 16:42:39.770599 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I0628 16:42:39.770608 17458 net.cpp:100] Creating Layer conv17_2_mbox_loc
I0628 16:42:39.770612 17458 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I0628 16:42:39.770619 17458 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I0628 16:42:39.773818 17458 net.cpp:150] Setting up conv17_2_mbox_loc
I0628 16:42:39.773831 17458 net.cpp:157] Top shape: 4 24 1 1 (96)
I0628 16:42:39.773835 17458 net.cpp:165] Memory required for data: 644945536
I0628 16:42:39.773840 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I0628 16:42:39.773849 17458 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I0628 16:42:39.773854 17458 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I0628 16:42:39.773859 17458 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I0628 16:42:39.774050 17458 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I0628 16:42:39.774057 17458 net.cpp:157] Top shape: 4 1 1 24 (96)
I0628 16:42:39.774060 17458 net.cpp:165] Memory required for data: 644945920
I0628 16:42:39.774063 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I0628 16:42:39.774070 17458 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I0628 16:42:39.774075 17458 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I0628 16:42:39.774078 17458 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I0628 16:42:39.774125 17458 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I0628 16:42:39.774130 17458 net.cpp:157] Top shape: 4 24 (96)
I0628 16:42:39.774134 17458 net.cpp:165] Memory required for data: 644946304
I0628 16:42:39.774137 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I0628 16:42:39.774164 17458 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I0628 16:42:39.774184 17458 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I0628 16:42:39.774190 17458 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I0628 16:42:39.776794 17458 net.cpp:150] Setting up conv17_2_mbox_conf_new
I0628 16:42:39.776805 17458 net.cpp:157] Top shape: 4 12 1 1 (48)
I0628 16:42:39.776808 17458 net.cpp:165] Memory required for data: 644946496
I0628 16:42:39.776814 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I0628 16:42:39.776820 17458 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I0628 16:42:39.776824 17458 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I0628 16:42:39.776831 17458 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I0628 16:42:39.777037 17458 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I0628 16:42:39.777045 17458 net.cpp:157] Top shape: 4 1 1 12 (48)
I0628 16:42:39.777047 17458 net.cpp:165] Memory required for data: 644946688
I0628 16:42:39.777050 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I0628 16:42:39.777055 17458 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I0628 16:42:39.777058 17458 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I0628 16:42:39.777065 17458 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I0628 16:42:39.777110 17458 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I0628 16:42:39.777117 17458 net.cpp:157] Top shape: 4 12 (48)
I0628 16:42:39.777119 17458 net.cpp:165] Memory required for data: 644946880
I0628 16:42:39.777122 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I0628 16:42:39.777148 17458 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I0628 16:42:39.777184 17458 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I0628 16:42:39.777204 17458 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I0628 16:42:39.777230 17458 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I0628 16:42:39.777333 17458 net.cpp:150] Setting up conv17_2_mbox_priorbox
I0628 16:42:39.777340 17458 net.cpp:157] Top shape: 1 2 24 (48)
I0628 16:42:39.777343 17458 net.cpp:165] Memory required for data: 644947072
I0628 16:42:39.777346 17458 layer_factory.hpp:77] Creating layer mbox_loc
I0628 16:42:39.777371 17458 net.cpp:100] Creating Layer mbox_loc
I0628 16:42:39.777375 17458 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I0628 16:42:39.777380 17458 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I0628 16:42:39.777384 17458 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I0628 16:42:39.777388 17458 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I0628 16:42:39.777406 17458 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I0628 16:42:39.777410 17458 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I0628 16:42:39.777416 17458 net.cpp:408] mbox_loc -> mbox_loc
I0628 16:42:39.777498 17458 net.cpp:150] Setting up mbox_loc
I0628 16:42:39.777503 17458 net.cpp:157] Top shape: 4 7668 (30672)
I0628 16:42:39.777506 17458 net.cpp:165] Memory required for data: 645069760
I0628 16:42:39.777509 17458 layer_factory.hpp:77] Creating layer mbox_conf
I0628 16:42:39.777534 17458 net.cpp:100] Creating Layer mbox_conf
I0628 16:42:39.777537 17458 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I0628 16:42:39.777555 17458 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I0628 16:42:39.777559 17458 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I0628 16:42:39.777583 17458 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I0628 16:42:39.777587 17458 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I0628 16:42:39.777591 17458 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I0628 16:42:39.777596 17458 net.cpp:408] mbox_conf -> mbox_conf
I0628 16:42:39.777639 17458 net.cpp:150] Setting up mbox_conf
I0628 16:42:39.777645 17458 net.cpp:157] Top shape: 4 3834 (15336)
I0628 16:42:39.777648 17458 net.cpp:165] Memory required for data: 645131104
I0628 16:42:39.777652 17458 layer_factory.hpp:77] Creating layer mbox_priorbox
I0628 16:42:39.777657 17458 net.cpp:100] Creating Layer mbox_priorbox
I0628 16:42:39.777660 17458 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I0628 16:42:39.777664 17458 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I0628 16:42:39.777668 17458 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I0628 16:42:39.777673 17458 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I0628 16:42:39.777675 17458 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I0628 16:42:39.777679 17458 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I0628 16:42:39.777685 17458 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0628 16:42:39.777732 17458 net.cpp:150] Setting up mbox_priorbox
I0628 16:42:39.777755 17458 net.cpp:157] Top shape: 1 2 7668 (15336)
I0628 16:42:39.777758 17458 net.cpp:165] Memory required for data: 645192448
I0628 16:42:39.777761 17458 layer_factory.hpp:77] Creating layer mbox_loss
I0628 16:42:39.777788 17458 net.cpp:100] Creating Layer mbox_loss
I0628 16:42:39.777793 17458 net.cpp:434] mbox_loss <- mbox_loc
I0628 16:42:39.777797 17458 net.cpp:434] mbox_loss <- mbox_conf
I0628 16:42:39.777801 17458 net.cpp:434] mbox_loss <- mbox_priorbox
I0628 16:42:39.777806 17458 net.cpp:434] mbox_loss <- label
I0628 16:42:39.777829 17458 net.cpp:408] mbox_loss -> mbox_loss
I0628 16:42:39.777951 17458 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0628 16:42:39.778141 17458 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0628 16:42:39.778149 17458 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0628 16:42:39.779124 17458 net.cpp:150] Setting up mbox_loss
I0628 16:42:39.779134 17458 net.cpp:157] Top shape: (1)
I0628 16:42:39.779139 17458 net.cpp:160]     with loss weight 1
I0628 16:42:39.779211 17458 net.cpp:165] Memory required for data: 645192452
I0628 16:42:39.779217 17458 net.cpp:226] mbox_loss needs backward computation.
I0628 16:42:39.779224 17458 net.cpp:228] mbox_priorbox does not need backward computation.
I0628 16:42:39.779230 17458 net.cpp:226] mbox_conf needs backward computation.
I0628 16:42:39.779235 17458 net.cpp:226] mbox_loc needs backward computation.
I0628 16:42:39.779242 17458 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I0628 16:42:39.779245 17458 net.cpp:226] conv17_2_mbox_conf_flat needs backward computation.
I0628 16:42:39.779249 17458 net.cpp:226] conv17_2_mbox_conf_perm needs backward computation.
I0628 16:42:39.779253 17458 net.cpp:226] conv17_2_mbox_conf_new needs backward computation.
I0628 16:42:39.779275 17458 net.cpp:226] conv17_2_mbox_loc_flat needs backward computation.
I0628 16:42:39.779279 17458 net.cpp:226] conv17_2_mbox_loc_perm needs backward computation.
I0628 16:42:39.779283 17458 net.cpp:226] conv17_2_mbox_loc needs backward computation.
I0628 16:42:39.779286 17458 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I0628 16:42:39.779292 17458 net.cpp:226] conv16_2_mbox_conf_flat needs backward computation.
I0628 16:42:39.779296 17458 net.cpp:226] conv16_2_mbox_conf_perm needs backward computation.
I0628 16:42:39.779300 17458 net.cpp:226] conv16_2_mbox_conf_new needs backward computation.
I0628 16:42:39.779304 17458 net.cpp:226] conv16_2_mbox_loc_flat needs backward computation.
I0628 16:42:39.779307 17458 net.cpp:226] conv16_2_mbox_loc_perm needs backward computation.
I0628 16:42:39.779311 17458 net.cpp:226] conv16_2_mbox_loc needs backward computation.
I0628 16:42:39.779315 17458 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I0628 16:42:39.779320 17458 net.cpp:226] conv15_2_mbox_conf_flat needs backward computation.
I0628 16:42:39.779325 17458 net.cpp:226] conv15_2_mbox_conf_perm needs backward computation.
I0628 16:42:39.779328 17458 net.cpp:226] conv15_2_mbox_conf_new needs backward computation.
I0628 16:42:39.779331 17458 net.cpp:226] conv15_2_mbox_loc_flat needs backward computation.
I0628 16:42:39.779335 17458 net.cpp:226] conv15_2_mbox_loc_perm needs backward computation.
I0628 16:42:39.779340 17458 net.cpp:226] conv15_2_mbox_loc needs backward computation.
I0628 16:42:39.779343 17458 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I0628 16:42:39.779350 17458 net.cpp:226] conv14_2_mbox_conf_flat needs backward computation.
I0628 16:42:39.779353 17458 net.cpp:226] conv14_2_mbox_conf_perm needs backward computation.
I0628 16:42:39.779356 17458 net.cpp:226] conv14_2_mbox_conf_new needs backward computation.
I0628 16:42:39.779361 17458 net.cpp:226] conv14_2_mbox_loc_flat needs backward computation.
I0628 16:42:39.779364 17458 net.cpp:226] conv14_2_mbox_loc_perm needs backward computation.
I0628 16:42:39.779368 17458 net.cpp:226] conv14_2_mbox_loc needs backward computation.
I0628 16:42:39.779372 17458 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I0628 16:42:39.779376 17458 net.cpp:226] conv13_mbox_conf_flat needs backward computation.
I0628 16:42:39.779394 17458 net.cpp:226] conv13_mbox_conf_perm needs backward computation.
I0628 16:42:39.779398 17458 net.cpp:226] conv13_mbox_conf_new needs backward computation.
I0628 16:42:39.779402 17458 net.cpp:226] conv13_mbox_loc_flat needs backward computation.
I0628 16:42:39.779407 17458 net.cpp:226] conv13_mbox_loc_perm needs backward computation.
I0628 16:42:39.779412 17458 net.cpp:226] conv13_mbox_loc needs backward computation.
I0628 16:42:39.779415 17458 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I0628 16:42:39.779420 17458 net.cpp:226] conv11_mbox_conf_flat needs backward computation.
I0628 16:42:39.779424 17458 net.cpp:226] conv11_mbox_conf_perm needs backward computation.
I0628 16:42:39.779428 17458 net.cpp:226] conv11_mbox_conf_new needs backward computation.
I0628 16:42:39.779431 17458 net.cpp:226] conv11_mbox_loc_flat needs backward computation.
I0628 16:42:39.779441 17458 net.cpp:226] conv11_mbox_loc_perm needs backward computation.
I0628 16:42:39.779446 17458 net.cpp:226] conv11_mbox_loc needs backward computation.
I0628 16:42:39.779450 17458 net.cpp:226] conv17_2_conv17_2/relu_0_split needs backward computation.
I0628 16:42:39.779454 17458 net.cpp:226] conv17_2/relu needs backward computation.
I0628 16:42:39.779458 17458 net.cpp:226] conv17_2/scale needs backward computation.
I0628 16:42:39.779461 17458 net.cpp:226] conv17_2/bn needs backward computation.
I0628 16:42:39.779465 17458 net.cpp:226] conv17_2 needs backward computation.
I0628 16:42:39.779469 17458 net.cpp:226] conv17_1/relu needs backward computation.
I0628 16:42:39.779472 17458 net.cpp:226] conv17_1/scale needs backward computation.
I0628 16:42:39.779476 17458 net.cpp:226] conv17_1/bn needs backward computation.
I0628 16:42:39.779479 17458 net.cpp:226] conv17_1 needs backward computation.
I0628 16:42:39.779484 17458 net.cpp:226] conv16_2_conv16_2/relu_0_split needs backward computation.
I0628 16:42:39.779487 17458 net.cpp:226] conv16_2/relu needs backward computation.
I0628 16:42:39.779491 17458 net.cpp:226] conv16_2/scale needs backward computation.
I0628 16:42:39.779495 17458 net.cpp:226] conv16_2/bn needs backward computation.
I0628 16:42:39.779498 17458 net.cpp:226] conv16_2 needs backward computation.
I0628 16:42:39.779501 17458 net.cpp:226] conv16_1/relu needs backward computation.
I0628 16:42:39.779505 17458 net.cpp:226] conv16_1/scale needs backward computation.
I0628 16:42:39.779508 17458 net.cpp:226] conv16_1/bn needs backward computation.
I0628 16:42:39.779512 17458 net.cpp:226] conv16_1 needs backward computation.
I0628 16:42:39.779516 17458 net.cpp:226] conv15_2_conv15_2/relu_0_split needs backward computation.
I0628 16:42:39.779520 17458 net.cpp:226] conv15_2/relu needs backward computation.
I0628 16:42:39.779523 17458 net.cpp:226] conv15_2/scale needs backward computation.
I0628 16:42:39.779526 17458 net.cpp:226] conv15_2/bn needs backward computation.
I0628 16:42:39.779531 17458 net.cpp:226] conv15_2 needs backward computation.
I0628 16:42:39.779534 17458 net.cpp:226] conv15_1/relu needs backward computation.
I0628 16:42:39.779537 17458 net.cpp:226] conv15_1/scale needs backward computation.
I0628 16:42:39.779541 17458 net.cpp:226] conv15_1/bn needs backward computation.
I0628 16:42:39.779544 17458 net.cpp:226] conv15_1 needs backward computation.
I0628 16:42:39.779549 17458 net.cpp:226] conv14_2_conv14_2/relu_0_split needs backward computation.
I0628 16:42:39.779553 17458 net.cpp:226] conv14_2/relu needs backward computation.
I0628 16:42:39.779557 17458 net.cpp:226] conv14_2/scale needs backward computation.
I0628 16:42:39.779561 17458 net.cpp:226] conv14_2/bn needs backward computation.
I0628 16:42:39.779564 17458 net.cpp:226] conv14_2 needs backward computation.
I0628 16:42:39.779568 17458 net.cpp:226] conv14_1/relu needs backward computation.
I0628 16:42:39.779572 17458 net.cpp:226] conv14_1/scale needs backward computation.
I0628 16:42:39.779575 17458 net.cpp:226] conv14_1/bn needs backward computation.
I0628 16:42:39.779579 17458 net.cpp:226] conv14_1 needs backward computation.
I0628 16:42:39.779583 17458 net.cpp:226] conv13_conv13/relu_0_split needs backward computation.
I0628 16:42:39.779587 17458 net.cpp:226] conv13/relu needs backward computation.
I0628 16:42:39.779592 17458 net.cpp:226] conv13/scale needs backward computation.
I0628 16:42:39.779594 17458 net.cpp:226] conv13/bn needs backward computation.
I0628 16:42:39.779598 17458 net.cpp:226] conv13 needs backward computation.
I0628 16:42:39.779603 17458 net.cpp:226] conv13/dw/relu needs backward computation.
I0628 16:42:39.779605 17458 net.cpp:226] conv13/dw/scale needs backward computation.
I0628 16:42:39.779609 17458 net.cpp:226] conv13/dw/bn needs backward computation.
I0628 16:42:39.779613 17458 net.cpp:226] conv13/dw needs backward computation.
I0628 16:42:39.779616 17458 net.cpp:226] conv12/relu needs backward computation.
I0628 16:42:39.779620 17458 net.cpp:226] conv12/scale needs backward computation.
I0628 16:42:39.779630 17458 net.cpp:226] conv12/bn needs backward computation.
I0628 16:42:39.779634 17458 net.cpp:226] conv12 needs backward computation.
I0628 16:42:39.779639 17458 net.cpp:226] conv12/dw/relu needs backward computation.
I0628 16:42:39.779642 17458 net.cpp:226] conv12/dw/scale needs backward computation.
I0628 16:42:39.779645 17458 net.cpp:226] conv12/dw/bn needs backward computation.
I0628 16:42:39.779649 17458 net.cpp:226] conv12/dw needs backward computation.
I0628 16:42:39.779654 17458 net.cpp:226] conv11_conv11/relu_0_split needs backward computation.
I0628 16:42:39.779657 17458 net.cpp:226] conv11/relu needs backward computation.
I0628 16:42:39.779660 17458 net.cpp:226] conv11/scale needs backward computation.
I0628 16:42:39.779664 17458 net.cpp:226] conv11/bn needs backward computation.
I0628 16:42:39.779667 17458 net.cpp:226] conv11 needs backward computation.
I0628 16:42:39.779671 17458 net.cpp:226] conv11/dw/relu needs backward computation.
I0628 16:42:39.779675 17458 net.cpp:226] conv11/dw/scale needs backward computation.
I0628 16:42:39.779678 17458 net.cpp:226] conv11/dw/bn needs backward computation.
I0628 16:42:39.779682 17458 net.cpp:226] conv11/dw needs backward computation.
I0628 16:42:39.779685 17458 net.cpp:226] conv10/relu needs backward computation.
I0628 16:42:39.779690 17458 net.cpp:226] conv10/scale needs backward computation.
I0628 16:42:39.779693 17458 net.cpp:226] conv10/bn needs backward computation.
I0628 16:42:39.779696 17458 net.cpp:226] conv10 needs backward computation.
I0628 16:42:39.779700 17458 net.cpp:226] conv10/dw/relu needs backward computation.
I0628 16:42:39.779703 17458 net.cpp:226] conv10/dw/scale needs backward computation.
I0628 16:42:39.779707 17458 net.cpp:226] conv10/dw/bn needs backward computation.
I0628 16:42:39.779711 17458 net.cpp:226] conv10/dw needs backward computation.
I0628 16:42:39.779714 17458 net.cpp:226] conv9/relu needs backward computation.
I0628 16:42:39.779718 17458 net.cpp:226] conv9/scale needs backward computation.
I0628 16:42:39.779721 17458 net.cpp:226] conv9/bn needs backward computation.
I0628 16:42:39.779726 17458 net.cpp:226] conv9 needs backward computation.
I0628 16:42:39.779729 17458 net.cpp:226] conv9/dw/relu needs backward computation.
I0628 16:42:39.779732 17458 net.cpp:226] conv9/dw/scale needs backward computation.
I0628 16:42:39.779736 17458 net.cpp:226] conv9/dw/bn needs backward computation.
I0628 16:42:39.779739 17458 net.cpp:226] conv9/dw needs backward computation.
I0628 16:42:39.779743 17458 net.cpp:226] conv8/relu needs backward computation.
I0628 16:42:39.779747 17458 net.cpp:226] conv8/scale needs backward computation.
I0628 16:42:39.779750 17458 net.cpp:226] conv8/bn needs backward computation.
I0628 16:42:39.779754 17458 net.cpp:226] conv8 needs backward computation.
I0628 16:42:39.779758 17458 net.cpp:226] conv8/dw/relu needs backward computation.
I0628 16:42:39.779762 17458 net.cpp:226] conv8/dw/scale needs backward computation.
I0628 16:42:39.779765 17458 net.cpp:226] conv8/dw/bn needs backward computation.
I0628 16:42:39.779768 17458 net.cpp:226] conv8/dw needs backward computation.
I0628 16:42:39.779772 17458 net.cpp:226] conv7/relu needs backward computation.
I0628 16:42:39.779775 17458 net.cpp:226] conv7/scale needs backward computation.
I0628 16:42:39.779779 17458 net.cpp:226] conv7/bn needs backward computation.
I0628 16:42:39.779783 17458 net.cpp:226] conv7 needs backward computation.
I0628 16:42:39.779786 17458 net.cpp:226] conv7/dw/relu needs backward computation.
I0628 16:42:39.779790 17458 net.cpp:226] conv7/dw/scale needs backward computation.
I0628 16:42:39.779793 17458 net.cpp:226] conv7/dw/bn needs backward computation.
I0628 16:42:39.779796 17458 net.cpp:226] conv7/dw needs backward computation.
I0628 16:42:39.779800 17458 net.cpp:226] conv6/relu needs backward computation.
I0628 16:42:39.779803 17458 net.cpp:226] conv6/scale needs backward computation.
I0628 16:42:39.779808 17458 net.cpp:226] conv6/bn needs backward computation.
I0628 16:42:39.779811 17458 net.cpp:226] conv6 needs backward computation.
I0628 16:42:39.779824 17458 net.cpp:226] conv6/dw/relu needs backward computation.
I0628 16:42:39.779829 17458 net.cpp:226] conv6/dw/scale needs backward computation.
I0628 16:42:39.779831 17458 net.cpp:226] conv6/dw/bn needs backward computation.
I0628 16:42:39.779835 17458 net.cpp:226] conv6/dw needs backward computation.
I0628 16:42:39.779839 17458 net.cpp:226] conv5/relu needs backward computation.
I0628 16:42:39.779844 17458 net.cpp:226] conv5/scale needs backward computation.
I0628 16:42:39.779848 17458 net.cpp:226] conv5/bn needs backward computation.
I0628 16:42:39.779851 17458 net.cpp:226] conv5 needs backward computation.
I0628 16:42:39.779855 17458 net.cpp:226] conv5/dw/relu needs backward computation.
I0628 16:42:39.779860 17458 net.cpp:226] conv5/dw/scale needs backward computation.
I0628 16:42:39.779862 17458 net.cpp:226] conv5/dw/bn needs backward computation.
I0628 16:42:39.779866 17458 net.cpp:226] conv5/dw needs backward computation.
I0628 16:42:39.779870 17458 net.cpp:226] conv4/relu needs backward computation.
I0628 16:42:39.779873 17458 net.cpp:226] conv4/scale needs backward computation.
I0628 16:42:39.779876 17458 net.cpp:226] conv4/bn needs backward computation.
I0628 16:42:39.779881 17458 net.cpp:226] conv4 needs backward computation.
I0628 16:42:39.779883 17458 net.cpp:226] conv4/dw/relu needs backward computation.
I0628 16:42:39.779887 17458 net.cpp:226] conv4/dw/scale needs backward computation.
I0628 16:42:39.779891 17458 net.cpp:226] conv4/dw/bn needs backward computation.
I0628 16:42:39.779894 17458 net.cpp:226] conv4/dw needs backward computation.
I0628 16:42:39.779897 17458 net.cpp:226] conv3/relu needs backward computation.
I0628 16:42:39.779901 17458 net.cpp:226] conv3/scale needs backward computation.
I0628 16:42:39.779906 17458 net.cpp:226] conv3/bn needs backward computation.
I0628 16:42:39.779908 17458 net.cpp:226] conv3 needs backward computation.
I0628 16:42:39.779912 17458 net.cpp:226] conv3/dw/relu needs backward computation.
I0628 16:42:39.779915 17458 net.cpp:226] conv3/dw/scale needs backward computation.
I0628 16:42:39.779919 17458 net.cpp:226] conv3/dw/bn needs backward computation.
I0628 16:42:39.779922 17458 net.cpp:226] conv3/dw needs backward computation.
I0628 16:42:39.779927 17458 net.cpp:226] conv2/relu needs backward computation.
I0628 16:42:39.779929 17458 net.cpp:226] conv2/scale needs backward computation.
I0628 16:42:39.779933 17458 net.cpp:226] conv2/bn needs backward computation.
I0628 16:42:39.779937 17458 net.cpp:226] conv2 needs backward computation.
I0628 16:42:39.779940 17458 net.cpp:226] conv2/dw/relu needs backward computation.
I0628 16:42:39.779944 17458 net.cpp:226] conv2/dw/scale needs backward computation.
I0628 16:42:39.779947 17458 net.cpp:226] conv2/dw/bn needs backward computation.
I0628 16:42:39.779951 17458 net.cpp:226] conv2/dw needs backward computation.
I0628 16:42:39.779954 17458 net.cpp:226] conv1/relu needs backward computation.
I0628 16:42:39.779958 17458 net.cpp:226] conv1/scale needs backward computation.
I0628 16:42:39.779961 17458 net.cpp:226] conv1/bn needs backward computation.
I0628 16:42:39.779965 17458 net.cpp:226] conv1 needs backward computation.
I0628 16:42:39.779969 17458 net.cpp:226] conv1/dw/relu needs backward computation.
I0628 16:42:39.779973 17458 net.cpp:226] conv1/dw/scale needs backward computation.
I0628 16:42:39.779976 17458 net.cpp:226] conv1/dw/bn needs backward computation.
I0628 16:42:39.779979 17458 net.cpp:226] conv1/dw needs backward computation.
I0628 16:42:39.779983 17458 net.cpp:226] conv0/relu needs backward computation.
I0628 16:42:39.779986 17458 net.cpp:226] conv0/scale needs backward computation.
I0628 16:42:39.779990 17458 net.cpp:226] conv0/bn needs backward computation.
I0628 16:42:39.779994 17458 net.cpp:226] conv0 needs backward computation.
I0628 16:42:39.779999 17458 net.cpp:228] data_data_0_split does not need backward computation.
I0628 16:42:39.780005 17458 net.cpp:228] data does not need backward computation.
I0628 16:42:39.780009 17458 net.cpp:270] This network produces output mbox_loss
I0628 16:42:39.780092 17458 net.cpp:283] Network initialization done.
I0628 16:42:39.781544 17458 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: example/MobileNetSSD_test.prototxt
I0628 16:42:39.781558 17458 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 16:42:39.781564 17458 solver.cpp:196] Creating test net (#0) specified by test_net file: example/MobileNetSSD_test.prototxt
I0628 16:42:39.782421 17458 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "test_lmdb"
    batch_size: 4
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14_1"
  type: "Convolution"
  bottom: "conv13"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_1/bn"
  type: "BatchNorm"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_1/scale"
  type: "Scale"
  bottom: "conv14_1"
  top: "conv14_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_1/relu"
  type: "ReLU"
  bottom: "conv14_1"
  top: "conv14_1"
}
layer {
  name: "conv14_2"
  type: "Convolution"
  bottom: "conv14_1"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv14_2/bn"
  type: "BatchNorm"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv14_2/scale"
  type: "Scale"
  bottom: "conv14_2"
  top: "conv14_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv14_2/relu"
  type: "ReLU"
  bottom: "conv14_2"
  top: "conv14_2"
}
layer {
  name: "conv15_1"
  type: "Convolution"
  bottom: "conv14_2"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_1/bn"
  type: "BatchNorm"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_1/scale"
  type: "Scale"
  bottom: "conv15_1"
  top: "conv15_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_1/relu"
  type: "ReLU"
  bottom: "conv15_1"
  top: "conv15_1"
}
layer {
  name: "conv15_2"
  type: "Convolution"
  bottom: "conv15_1"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv15_2/bn"
  type: "BatchNorm"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv15_2/scale"
  type: "Scale"
  bottom: "conv15_2"
  top: "conv15_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv15_2/relu"
  type: "ReLU"
  bottom: "conv15_2"
  top: "conv15_2"
}
layer {
  name: "conv16_1"
  type: "Convolution"
  bottom: "conv15_2"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_1/bn"
  type: "BatchNorm"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_1/scale"
  type: "Scale"
  bottom: "conv16_1"
  top: "conv16_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_1/relu"
  type: "ReLU"
  bottom: "conv16_1"
  top: "conv16_1"
}
layer {
  name: "conv16_2"
  type: "Convolution"
  bottom: "conv16_1"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv16_2/bn"
  type: "BatchNorm"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv16_2/scale"
  type: "Scale"
  bottom: "conv16_2"
  top: "conv16_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv16_2/relu"
  type: "ReLU"
  bottom: "conv16_2"
  top: "conv16_2"
}
layer {
  name: "conv17_1"
  type: "Convolution"
  bottom: "conv16_2"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_1/bn"
  type: "BatchNorm"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_1/scale"
  type: "Scale"
  bottom: "conv17_1"
  top: "conv17_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_1/relu"
  type: "ReLU"
  bottom: "conv17_1"
  top: "conv17_1"
}
layer {
  name: "conv17_2"
  type: "Convolution"
  bottom: "conv17_1"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv17_2/bn"
  type: "BatchNorm"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv17_2/scale"
  type: "Scale"
  bottom: "conv17_2"
  top: "conv17_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv17_2/relu"
  type: "ReLU"
  bottom: "conv17_2"
  top: "conv17_2"
}
layer {
  name: "conv11_mbox_loc"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_mbox_loc"
  top: "conv11_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_mbox_loc_perm"
  top: "conv11_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_conf_new"
  type: "Convolution"
  bottom: "conv11"
  top: "conv11_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 6
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_mbox_conf"
  top: "conv11_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_mbox_conf_perm"
  top: "conv11_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11"
  bottom: "data"
  top: "conv11_mbox_priorbox"
  prior_box_param {
    min_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "conv13_mbox_loc"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_loc_perm"
  type: "Permute"
  bottom: "conv13_mbox_loc"
  top: "conv13_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv13_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv13_mbox_loc_perm"
  top: "conv13_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv13_mbox_conf_new"
  type: "Convolution"
  bottom: "conv13"
  top: "conv13_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv13_mbox_conf_perm"
  type: "Permute"
  bottom: "conv13_mbox_conf"
  top: "conv13_mbox_conf_perm"
  permute_param {
    order: 0
I0628 16:42:39.783269 17458 layer_factory.hpp:77] Creating layer data
I0628 16:42:39.783326 17458 net.cpp:100] Creating Layer data
I0628 16:42:39.783334 17458 net.cpp:408] data -> data
I0628 16:42:39.783344 17458 net.cpp:408] data -> label
I0628 16:42:39.784366 17480 db_lmdb.cpp:35] Opened lmdb test_lmdb
I0628 16:42:39.785725 17458 annotated_data_layer.cpp:62] output data size: 4,3,300,300
I0628 16:42:39.791875 17458 net.cpp:150] Setting up data
I0628 16:42:39.791898 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.791903 17458 net.cpp:157] Top shape: 1 1 5 8 (40)
I0628 16:42:39.791908 17458 net.cpp:165] Memory required for data: 4320160
I0628 16:42:39.791914 17458 layer_factory.hpp:77] Creating layer data_data_0_split
I0628 16:42:39.791927 17458 net.cpp:100] Creating Layer data_data_0_split
I0628 16:42:39.791934 17458 net.cpp:434] data_data_0_split <- data
I0628 16:42:39.791944 17458 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0628 16:42:39.791968 17458 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0628 16:42:39.791977 17458 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0628 16:42:39.791985 17458 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0628 16:42:39.791993 17458 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0628 16:42:39.792003 17458 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0628 16:42:39.792026 17458 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0628 16:42:39.792277 17458 net.cpp:150] Setting up data_data_0_split
I0628 16:42:39.792286 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.792290 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.792296 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.792304 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.792309 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.792315 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.792321 17458 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0628 16:42:39.792326 17458 net.cpp:165] Memory required for data: 34560160
I0628 16:42:39.792331 17458 layer_factory.hpp:77] Creating layer conv0
I0628 16:42:39.792358 17458 net.cpp:100] Creating Layer conv0
I0628 16:42:39.792364 17458 net.cpp:434] conv0 <- data_data_0_split_0
I0628 16:42:39.792387 17458 net.cpp:408] conv0 -> conv0
I0628 16:42:39.795697 17458 net.cpp:150] Setting up conv0
I0628 16:42:39.795711 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.795714 17458 net.cpp:165] Memory required for data: 46080160
I0628 16:42:39.795722 17458 layer_factory.hpp:77] Creating layer conv0/bn
I0628 16:42:39.795737 17458 net.cpp:100] Creating Layer conv0/bn
I0628 16:42:39.795744 17458 net.cpp:434] conv0/bn <- conv0
I0628 16:42:39.795751 17458 net.cpp:395] conv0/bn -> conv0 (in-place)
I0628 16:42:39.796098 17458 net.cpp:150] Setting up conv0/bn
I0628 16:42:39.796106 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.796110 17458 net.cpp:165] Memory required for data: 57600160
I0628 16:42:39.796136 17458 layer_factory.hpp:77] Creating layer conv0/scale
I0628 16:42:39.796144 17458 net.cpp:100] Creating Layer conv0/scale
I0628 16:42:39.796149 17458 net.cpp:434] conv0/scale <- conv0
I0628 16:42:39.796154 17458 net.cpp:395] conv0/scale -> conv0 (in-place)
I0628 16:42:39.796227 17458 layer_factory.hpp:77] Creating layer conv0/scale
I0628 16:42:39.796450 17458 net.cpp:150] Setting up conv0/scale
I0628 16:42:39.796458 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.796461 17458 net.cpp:165] Memory required for data: 69120160
I0628 16:42:39.796470 17458 layer_factory.hpp:77] Creating layer conv0/relu
I0628 16:42:39.796478 17458 net.cpp:100] Creating Layer conv0/relu
I0628 16:42:39.796483 17458 net.cpp:434] conv0/relu <- conv0
I0628 16:42:39.796507 17458 net.cpp:395] conv0/relu -> conv0 (in-place)
I0628 16:42:39.797458 17458 net.cpp:150] Setting up conv0/relu
I0628 16:42:39.797469 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.797473 17458 net.cpp:165] Memory required for data: 80640160
I0628 16:42:39.797477 17458 layer_factory.hpp:77] Creating layer conv1/dw
I0628 16:42:39.797505 17458 net.cpp:100] Creating Layer conv1/dw
I0628 16:42:39.797509 17458 net.cpp:434] conv1/dw <- conv0
I0628 16:42:39.797516 17458 net.cpp:408] conv1/dw -> conv1/dw
I0628 16:42:39.797873 17458 net.cpp:150] Setting up conv1/dw
I0628 16:42:39.797880 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.797884 17458 net.cpp:165] Memory required for data: 92160160
I0628 16:42:39.797890 17458 layer_factory.hpp:77] Creating layer conv1/dw/bn
I0628 16:42:39.797897 17458 net.cpp:100] Creating Layer conv1/dw/bn
I0628 16:42:39.797920 17458 net.cpp:434] conv1/dw/bn <- conv1/dw
I0628 16:42:39.797928 17458 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I0628 16:42:39.798249 17458 net.cpp:150] Setting up conv1/dw/bn
I0628 16:42:39.798256 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.798259 17458 net.cpp:165] Memory required for data: 103680160
I0628 16:42:39.798269 17458 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0628 16:42:39.798296 17458 net.cpp:100] Creating Layer conv1/dw/scale
I0628 16:42:39.798300 17458 net.cpp:434] conv1/dw/scale <- conv1/dw
I0628 16:42:39.798308 17458 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I0628 16:42:39.798382 17458 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0628 16:42:39.799010 17458 net.cpp:150] Setting up conv1/dw/scale
I0628 16:42:39.799021 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.799024 17458 net.cpp:165] Memory required for data: 115200160
I0628 16:42:39.799032 17458 layer_factory.hpp:77] Creating layer conv1/dw/relu
I0628 16:42:39.799060 17458 net.cpp:100] Creating Layer conv1/dw/relu
I0628 16:42:39.799067 17458 net.cpp:434] conv1/dw/relu <- conv1/dw
I0628 16:42:39.799072 17458 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I0628 16:42:39.799798 17458 net.cpp:150] Setting up conv1/dw/relu
I0628 16:42:39.799806 17458 net.cpp:157] Top shape: 4 32 150 150 (2880000)
I0628 16:42:39.799810 17458 net.cpp:165] Memory required for data: 126720160
I0628 16:42:39.799814 17458 layer_factory.hpp:77] Creating layer conv1
I0628 16:42:39.799841 17458 net.cpp:100] Creating Layer conv1
I0628 16:42:39.799846 17458 net.cpp:434] conv1 <- conv1/dw
I0628 16:42:39.799898 17458 net.cpp:408] conv1 -> conv1
I0628 16:42:39.803051 17458 net.cpp:150] Setting up conv1
I0628 16:42:39.803064 17458 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0628 16:42:39.803068 17458 net.cpp:165] Memory required for data: 149760160
I0628 16:42:39.803073 17458 layer_factory.hpp:77] Creating layer conv1/bn
I0628 16:42:39.803099 17458 net.cpp:100] Creating Layer conv1/bn
I0628 16:42:39.803104 17458 net.cpp:434] conv1/bn <- conv1
I0628 16:42:39.803110 17458 net.cpp:395] conv1/bn -> conv1 (in-place)
I0628 16:42:39.803490 17458 net.cpp:150] Setting up conv1/bn
I0628 16:42:39.803498 17458 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0628 16:42:39.803501 17458 net.cpp:165] Memory required for data: 172800160
I0628 16:42:39.803506 17458 layer_factory.hpp:77] Creating layer conv1/scale
I0628 16:42:39.803512 17458 net.cpp:100] Creating Layer conv1/scale
I0628 16:42:39.803534 17458 net.cpp:434] conv1/scale <- conv1
I0628 16:42:39.803539 17458 net.cpp:395] conv1/scale -> conv1 (in-place)
I0628 16:42:39.803639 17458 layer_factory.hpp:77] Creating layer conv1/scale
I0628 16:42:39.803898 17458 net.cpp:150] Setting up conv1/scale
I0628 16:42:39.803905 17458 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0628 16:42:39.803908 17458 net.cpp:165] Memory required for data: 195840160
I0628 16:42:39.803915 17458 layer_factory.hpp:77] Creating layer conv1/relu
I0628 16:42:39.803941 17458 net.cpp:100] Creating Layer conv1/relu
I0628 16:42:39.803946 17458 net.cpp:434] conv1/relu <- conv1
I0628 16:42:39.803949 17458 net.cpp:395] conv1/relu -> conv1 (in-place)
I0628 16:42:39.804809 17458 net.cpp:150] Setting up conv1/relu
I0628 16:42:39.804819 17458 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0628 16:42:39.804823 17458 net.cpp:165] Memory required for data: 218880160
I0628 16:42:39.804826 17458 layer_factory.hpp:77] Creating layer conv2/dw
I0628 16:42:39.804849 17458 net.cpp:100] Creating Layer conv2/dw
I0628 16:42:39.804854 17458 net.cpp:434] conv2/dw <- conv1
I0628 16:42:39.804873 17458 net.cpp:408] conv2/dw -> conv2/dw
I0628 16:42:39.805246 17458 net.cpp:150] Setting up conv2/dw
I0628 16:42:39.805254 17458 net.cpp:157] Top shape: 4 64 75 75 (1440000)
I0628 16:42:39.805258 17458 net.cpp:165] Memory required for data: 224640160
I0628 16:42:39.805264 17458 layer_factory.hpp:77] Creating layer conv2/dw/bn
I0628 16:42:39.805286 17458 net.cpp:100] Creating Layer conv2/dw/bn
I0628 16:42:39.805294 17458 net.cpp:434] conv2/dw/bn <- conv2/dw
I0628 16:42:39.805300 17458 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I0628 16:42:39.805730 17458 net.cpp:150] Setting up conv2/dw/bn
I0628 16:42:39.805739 17458 net.cpp:157] Top shape: 4 64 75 75 (1440000)
I0628 16:42:39.805742 17458 net.cpp:165] Memory required for data: 230400160
I0628 16:42:39.805750 17458 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0628 16:42:39.805780 17458 net.cpp:100] Creating Layer conv2/dw/scale
I0628 16:42:39.805785 17458 net.cpp:434] conv2/dw/scale <- conv2/dw
I0628 16:42:39.805790 17458 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I0628 16:42:39.805861 17458 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0628 16:42:39.806035 17458 net.cpp:150] Setting up conv2/dw/scale
I0628 16:42:39.806042 17458 net.cpp:157] Top shape: 4 64 75 75 (1440000)
I0628 16:42:39.806046 17458 net.cpp:165] Memory required for data: 236160160
I0628 16:42:39.806053 17458 layer_factory.hpp:77] Creating layer conv2/dw/relu
I0628 16:42:39.806062 17458 net.cpp:100] Creating Layer conv2/dw/relu
I0628 16:42:39.806067 17458 net.cpp:434] conv2/dw/relu <- conv2/dw
I0628 16:42:39.806074 17458 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I0628 16:42:39.806933 17458 net.cpp:150] Setting up conv2/dw/relu
I0628 16:42:39.806944 17458 net.cpp:157] Top shape: 4 64 75 75 (1440000)
I0628 16:42:39.806947 17458 net.cpp:165] Memory required for data: 241920160
I0628 16:42:39.806952 17458 layer_factory.hpp:77] Creating layer conv2
I0628 16:42:39.806964 17458 net.cpp:100] Creating Layer conv2
I0628 16:42:39.806972 17458 net.cpp:434] conv2 <- conv2/dw
I0628 16:42:39.806993 17458 net.cpp:408] conv2 -> conv2
I0628 16:42:39.810151 17458 net.cpp:150] Setting up conv2
I0628 16:42:39.810170 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.810174 17458 net.cpp:165] Memory required for data: 253440160
I0628 16:42:39.810181 17458 layer_factory.hpp:77] Creating layer conv2/bn
I0628 16:42:39.810214 17458 net.cpp:100] Creating Layer conv2/bn
I0628 16:42:39.810220 17458 net.cpp:434] conv2/bn <- conv2
I0628 16:42:39.810230 17458 net.cpp:395] conv2/bn -> conv2 (in-place)
I0628 16:42:39.810546 17458 net.cpp:150] Setting up conv2/bn
I0628 16:42:39.810554 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.810557 17458 net.cpp:165] Memory required for data: 264960160
I0628 16:42:39.810573 17458 layer_factory.hpp:77] Creating layer conv2/scale
I0628 16:42:39.810602 17458 net.cpp:100] Creating Layer conv2/scale
I0628 16:42:39.810607 17458 net.cpp:434] conv2/scale <- conv2
I0628 16:42:39.810616 17458 net.cpp:395] conv2/scale -> conv2 (in-place)
I0628 16:42:39.810688 17458 layer_factory.hpp:77] Creating layer conv2/scale
I0628 16:42:39.810922 17458 net.cpp:150] Setting up conv2/scale
I0628 16:42:39.810930 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.810932 17458 net.cpp:165] Memory required for data: 276480160
I0628 16:42:39.810937 17458 layer_factory.hpp:77] Creating layer conv2/relu
I0628 16:42:39.810956 17458 net.cpp:100] Creating Layer conv2/relu
I0628 16:42:39.810959 17458 net.cpp:434] conv2/relu <- conv2
I0628 16:42:39.810983 17458 net.cpp:395] conv2/relu -> conv2 (in-place)
I0628 16:42:39.811815 17458 net.cpp:150] Setting up conv2/relu
I0628 16:42:39.811825 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.811830 17458 net.cpp:165] Memory required for data: 288000160
I0628 16:42:39.811833 17458 layer_factory.hpp:77] Creating layer conv3/dw
I0628 16:42:39.811864 17458 net.cpp:100] Creating Layer conv3/dw
I0628 16:42:39.811870 17458 net.cpp:434] conv3/dw <- conv2
I0628 16:42:39.811877 17458 net.cpp:408] conv3/dw -> conv3/dw
I0628 16:42:39.812199 17458 net.cpp:150] Setting up conv3/dw
I0628 16:42:39.812209 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.812213 17458 net.cpp:165] Memory required for data: 299520160
I0628 16:42:39.812220 17458 layer_factory.hpp:77] Creating layer conv3/dw/bn
I0628 16:42:39.812248 17458 net.cpp:100] Creating Layer conv3/dw/bn
I0628 16:42:39.812255 17458 net.cpp:434] conv3/dw/bn <- conv3/dw
I0628 16:42:39.812260 17458 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I0628 16:42:39.812558 17458 net.cpp:150] Setting up conv3/dw/bn
I0628 16:42:39.812566 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.812568 17458 net.cpp:165] Memory required for data: 311040160
I0628 16:42:39.812580 17458 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0628 16:42:39.812608 17458 net.cpp:100] Creating Layer conv3/dw/scale
I0628 16:42:39.812611 17458 net.cpp:434] conv3/dw/scale <- conv3/dw
I0628 16:42:39.812633 17458 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I0628 16:42:39.812690 17458 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0628 16:42:39.812913 17458 net.cpp:150] Setting up conv3/dw/scale
I0628 16:42:39.812922 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.812927 17458 net.cpp:165] Memory required for data: 322560160
I0628 16:42:39.812933 17458 layer_factory.hpp:77] Creating layer conv3/dw/relu
I0628 16:42:39.812958 17458 net.cpp:100] Creating Layer conv3/dw/relu
I0628 16:42:39.812964 17458 net.cpp:434] conv3/dw/relu <- conv3/dw
I0628 16:42:39.812970 17458 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I0628 16:42:39.813935 17458 net.cpp:150] Setting up conv3/dw/relu
I0628 16:42:39.813946 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.813949 17458 net.cpp:165] Memory required for data: 334080160
I0628 16:42:39.813953 17458 layer_factory.hpp:77] Creating layer conv3
I0628 16:42:39.813980 17458 net.cpp:100] Creating Layer conv3
I0628 16:42:39.813985 17458 net.cpp:434] conv3 <- conv3/dw
I0628 16:42:39.814007 17458 net.cpp:408] conv3 -> conv3
I0628 16:42:39.818135 17458 net.cpp:150] Setting up conv3
I0628 16:42:39.818150 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.818154 17458 net.cpp:165] Memory required for data: 345600160
I0628 16:42:39.818161 17458 layer_factory.hpp:77] Creating layer conv3/bn
I0628 16:42:39.818186 17458 net.cpp:100] Creating Layer conv3/bn
I0628 16:42:39.818192 17458 net.cpp:434] conv3/bn <- conv3
I0628 16:42:39.818197 17458 net.cpp:395] conv3/bn -> conv3 (in-place)
I0628 16:42:39.818562 17458 net.cpp:150] Setting up conv3/bn
I0628 16:42:39.818569 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.818573 17458 net.cpp:165] Memory required for data: 357120160
I0628 16:42:39.818578 17458 layer_factory.hpp:77] Creating layer conv3/scale
I0628 16:42:39.818606 17458 net.cpp:100] Creating Layer conv3/scale
I0628 16:42:39.818610 17458 net.cpp:434] conv3/scale <- conv3
I0628 16:42:39.818616 17458 net.cpp:395] conv3/scale -> conv3 (in-place)
I0628 16:42:39.818753 17458 layer_factory.hpp:77] Creating layer conv3/scale
I0628 16:42:39.819001 17458 net.cpp:150] Setting up conv3/scale
I0628 16:42:39.819008 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.819012 17458 net.cpp:165] Memory required for data: 368640160
I0628 16:42:39.819016 17458 layer_factory.hpp:77] Creating layer conv3/relu
I0628 16:42:39.819021 17458 net.cpp:100] Creating Layer conv3/relu
I0628 16:42:39.819038 17458 net.cpp:434] conv3/relu <- conv3
I0628 16:42:39.819043 17458 net.cpp:395] conv3/relu -> conv3 (in-place)
I0628 16:42:39.819887 17458 net.cpp:150] Setting up conv3/relu
I0628 16:42:39.819898 17458 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0628 16:42:39.819901 17458 net.cpp:165] Memory required for data: 380160160
I0628 16:42:39.819905 17458 layer_factory.hpp:77] Creating layer conv4/dw
I0628 16:42:39.819914 17458 net.cpp:100] Creating Layer conv4/dw
I0628 16:42:39.819932 17458 net.cpp:434] conv4/dw <- conv3
I0628 16:42:39.819941 17458 net.cpp:408] conv4/dw -> conv4/dw
I0628 16:42:39.820291 17458 net.cpp:150] Setting up conv4/dw
I0628 16:42:39.820299 17458 net.cpp:157] Top shape: 4 128 38 38 (739328)
I0628 16:42:39.820303 17458 net.cpp:165] Memory required for data: 383117472
I0628 16:42:39.820307 17458 layer_factory.hpp:77] Creating layer conv4/dw/bn
I0628 16:42:39.820333 17458 net.cpp:100] Creating Layer conv4/dw/bn
I0628 16:42:39.820338 17458 net.cpp:434] conv4/dw/bn <- conv4/dw
I0628 16:42:39.820343 17458 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I0628 16:42:39.820631 17458 net.cpp:150] Setting up conv4/dw/bn
I0628 16:42:39.820638 17458 net.cpp:157] Top shape: 4 128 38 38 (739328)
I0628 16:42:39.820641 17458 net.cpp:165] Memory required for data: 386074784
I0628 16:42:39.820647 17458 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0628 16:42:39.820673 17458 net.cpp:100] Creating Layer conv4/dw/scale
I0628 16:42:39.820677 17458 net.cpp:434] conv4/dw/scale <- conv4/dw
I0628 16:42:39.820684 17458 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I0628 16:42:39.820755 17458 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0628 16:42:39.820955 17458 net.cpp:150] Setting up conv4/dw/scale
I0628 16:42:39.820960 17458 net.cpp:157] Top shape: 4 128 38 38 (739328)
I0628 16:42:39.820964 17458 net.cpp:165] Memory required for data: 389032096
I0628 16:42:39.820968 17458 layer_factory.hpp:77] Creating layer conv4/dw/relu
I0628 16:42:39.820973 17458 net.cpp:100] Creating Layer conv4/dw/relu
I0628 16:42:39.820996 17458 net.cpp:434] conv4/dw/relu <- conv4/dw
I0628 16:42:39.821002 17458 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I0628 16:42:39.821916 17458 net.cpp:150] Setting up conv4/dw/relu
I0628 16:42:39.821928 17458 net.cpp:157] Top shape: 4 128 38 38 (739328)
I0628 16:42:39.821933 17458 net.cpp:165] Memory required for data: 391989408
I0628 16:42:39.821936 17458 layer_factory.hpp:77] Creating layer conv4
I0628 16:42:39.821947 17458 net.cpp:100] Creating Layer conv4
I0628 16:42:39.821951 17458 net.cpp:434] conv4 <- conv4/dw
I0628 16:42:39.821957 17458 net.cpp:408] conv4 -> conv4
I0628 16:42:39.825759 17458 net.cpp:150] Setting up conv4
I0628 16:42:39.825776 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.825780 17458 net.cpp:165] Memory required for data: 397904032
I0628 16:42:39.825805 17458 layer_factory.hpp:77] Creating layer conv4/bn
I0628 16:42:39.825814 17458 net.cpp:100] Creating Layer conv4/bn
I0628 16:42:39.825819 17458 net.cpp:434] conv4/bn <- conv4
I0628 16:42:39.825826 17458 net.cpp:395] conv4/bn -> conv4 (in-place)
I0628 16:42:39.826056 17458 net.cpp:150] Setting up conv4/bn
I0628 16:42:39.826064 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.826067 17458 net.cpp:165] Memory required for data: 403818656
I0628 16:42:39.826092 17458 layer_factory.hpp:77] Creating layer conv4/scale
I0628 16:42:39.826100 17458 net.cpp:100] Creating Layer conv4/scale
I0628 16:42:39.826104 17458 net.cpp:434] conv4/scale <- conv4
I0628 16:42:39.826108 17458 net.cpp:395] conv4/scale -> conv4 (in-place)
I0628 16:42:39.826189 17458 layer_factory.hpp:77] Creating layer conv4/scale
I0628 16:42:39.826376 17458 net.cpp:150] Setting up conv4/scale
I0628 16:42:39.826383 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.826387 17458 net.cpp:165] Memory required for data: 409733280
I0628 16:42:39.826411 17458 layer_factory.hpp:77] Creating layer conv4/relu
I0628 16:42:39.826416 17458 net.cpp:100] Creating Layer conv4/relu
I0628 16:42:39.826419 17458 net.cpp:434] conv4/relu <- conv4
I0628 16:42:39.826423 17458 net.cpp:395] conv4/relu -> conv4 (in-place)
I0628 16:42:39.827127 17458 net.cpp:150] Setting up conv4/relu
I0628 16:42:39.827136 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.827139 17458 net.cpp:165] Memory required for data: 415647904
I0628 16:42:39.827143 17458 layer_factory.hpp:77] Creating layer conv5/dw
I0628 16:42:39.827172 17458 net.cpp:100] Creating Layer conv5/dw
I0628 16:42:39.827178 17458 net.cpp:434] conv5/dw <- conv4
I0628 16:42:39.827183 17458 net.cpp:408] conv5/dw -> conv5/dw
I0628 16:42:39.827414 17458 net.cpp:150] Setting up conv5/dw
I0628 16:42:39.827421 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.827425 17458 net.cpp:165] Memory required for data: 421562528
I0628 16:42:39.827430 17458 layer_factory.hpp:77] Creating layer conv5/dw/bn
I0628 16:42:39.827435 17458 net.cpp:100] Creating Layer conv5/dw/bn
I0628 16:42:39.827459 17458 net.cpp:434] conv5/dw/bn <- conv5/dw
I0628 16:42:39.827464 17458 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I0628 16:42:39.827657 17458 net.cpp:150] Setting up conv5/dw/bn
I0628 16:42:39.827663 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.827666 17458 net.cpp:165] Memory required for data: 427477152
I0628 16:42:39.827672 17458 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0628 16:42:39.827677 17458 net.cpp:100] Creating Layer conv5/dw/scale
I0628 16:42:39.827700 17458 net.cpp:434] conv5/dw/scale <- conv5/dw
I0628 16:42:39.827706 17458 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I0628 16:42:39.827739 17458 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0628 16:42:39.827915 17458 net.cpp:150] Setting up conv5/dw/scale
I0628 16:42:39.827922 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.827926 17458 net.cpp:165] Memory required for data: 433391776
I0628 16:42:39.827931 17458 layer_factory.hpp:77] Creating layer conv5/dw/relu
I0628 16:42:39.827936 17458 net.cpp:100] Creating Layer conv5/dw/relu
I0628 16:42:39.827939 17458 net.cpp:434] conv5/dw/relu <- conv5/dw
I0628 16:42:39.827946 17458 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I0628 16:42:39.828883 17458 net.cpp:150] Setting up conv5/dw/relu
I0628 16:42:39.828896 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.828900 17458 net.cpp:165] Memory required for data: 439306400
I0628 16:42:39.828904 17458 layer_factory.hpp:77] Creating layer conv5
I0628 16:42:39.828914 17458 net.cpp:100] Creating Layer conv5
I0628 16:42:39.828918 17458 net.cpp:434] conv5 <- conv5/dw
I0628 16:42:39.828925 17458 net.cpp:408] conv5 -> conv5
I0628 16:42:39.833168 17458 net.cpp:150] Setting up conv5
I0628 16:42:39.833185 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.833189 17458 net.cpp:165] Memory required for data: 445221024
I0628 16:42:39.833199 17458 layer_factory.hpp:77] Creating layer conv5/bn
I0628 16:42:39.833228 17458 net.cpp:100] Creating Layer conv5/bn
I0628 16:42:39.833236 17458 net.cpp:434] conv5/bn <- conv5
I0628 16:42:39.833261 17458 net.cpp:395] conv5/bn -> conv5 (in-place)
I0628 16:42:39.833483 17458 net.cpp:150] Setting up conv5/bn
I0628 16:42:39.833492 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.833495 17458 net.cpp:165] Memory required for data: 451135648
I0628 16:42:39.833504 17458 layer_factory.hpp:77] Creating layer conv5/scale
I0628 16:42:39.833534 17458 net.cpp:100] Creating Layer conv5/scale
I0628 16:42:39.833557 17458 net.cpp:434] conv5/scale <- conv5
I0628 16:42:39.833570 17458 net.cpp:395] conv5/scale -> conv5 (in-place)
I0628 16:42:39.833626 17458 layer_factory.hpp:77] Creating layer conv5/scale
I0628 16:42:39.833797 17458 net.cpp:150] Setting up conv5/scale
I0628 16:42:39.833804 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.833811 17458 net.cpp:165] Memory required for data: 457050272
I0628 16:42:39.833843 17458 layer_factory.hpp:77] Creating layer conv5/relu
I0628 16:42:39.833850 17458 net.cpp:100] Creating Layer conv5/relu
I0628 16:42:39.833856 17458 net.cpp:434] conv5/relu <- conv5
I0628 16:42:39.833863 17458 net.cpp:395] conv5/relu -> conv5 (in-place)
I0628 16:42:39.834719 17458 net.cpp:150] Setting up conv5/relu
I0628 16:42:39.834731 17458 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0628 16:42:39.834738 17458 net.cpp:165] Memory required for data: 462964896
I0628 16:42:39.834743 17458 layer_factory.hpp:77] Creating layer conv6/dw
I0628 16:42:39.834776 17458 net.cpp:100] Creating Layer conv6/dw
I0628 16:42:39.834782 17458 net.cpp:434] conv6/dw <- conv5
I0628 16:42:39.834805 17458 net.cpp:408] conv6/dw -> conv6/dw
I0628 16:42:39.835039 17458 net.cpp:150] Setting up conv6/dw
I0628 16:42:39.835047 17458 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0628 16:42:39.835050 17458 net.cpp:165] Memory required for data: 464443552
I0628 16:42:39.835055 17458 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0628 16:42:39.835059 17458 net.cpp:100] Creating Layer conv6/dw/bn
I0628 16:42:39.835083 17458 net.cpp:434] conv6/dw/bn <- conv6/dw
I0628 16:42:39.835088 17458 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I0628 16:42:39.835290 17458 net.cpp:150] Setting up conv6/dw/bn
I0628 16:42:39.835299 17458 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0628 16:42:39.835301 17458 net.cpp:165] Memory required for data: 465922208
I0628 16:42:39.835307 17458 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0628 16:42:39.835312 17458 net.cpp:100] Creating Layer conv6/dw/scale
I0628 16:42:39.835335 17458 net.cpp:434] conv6/dw/scale <- conv6/dw
I0628 16:42:39.835340 17458 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I0628 16:42:39.835373 17458 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0628 16:42:39.835546 17458 net.cpp:150] Setting up conv6/dw/scale
I0628 16:42:39.835553 17458 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0628 16:42:39.835556 17458 net.cpp:165] Memory required for data: 467400864
I0628 16:42:39.835561 17458 layer_factory.hpp:77] Creating layer conv6/dw/relu
I0628 16:42:39.835567 17458 net.cpp:100] Creating Layer conv6/dw/relu
I0628 16:42:39.835590 17458 net.cpp:434] conv6/dw/relu <- conv6/dw
I0628 16:42:39.835594 17458 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I0628 16:42:39.836263 17458 net.cpp:150] Setting up conv6/dw/relu
I0628 16:42:39.836272 17458 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0628 16:42:39.836277 17458 net.cpp:165] Memory required for data: 468879520
I0628 16:42:39.836279 17458 layer_factory.hpp:77] Creating layer conv6
I0628 16:42:39.836306 17458 net.cpp:100] Creating Layer conv6
I0628 16:42:39.836311 17458 net.cpp:434] conv6 <- conv6/dw
I0628 16:42:39.836318 17458 net.cpp:408] conv6 -> conv6
I0628 16:42:39.841158 17458 net.cpp:150] Setting up conv6
I0628 16:42:39.841174 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.841178 17458 net.cpp:165] Memory required for data: 471836832
I0628 16:42:39.841184 17458 layer_factory.hpp:77] Creating layer conv6/bn
I0628 16:42:39.841190 17458 net.cpp:100] Creating Layer conv6/bn
I0628 16:42:39.841213 17458 net.cpp:434] conv6/bn <- conv6
I0628 16:42:39.841238 17458 net.cpp:395] conv6/bn -> conv6 (in-place)
I0628 16:42:39.841526 17458 net.cpp:150] Setting up conv6/bn
I0628 16:42:39.841534 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.841538 17458 net.cpp:165] Memory required for data: 474794144
I0628 16:42:39.841547 17458 layer_factory.hpp:77] Creating layer conv6/scale
I0628 16:42:39.841570 17458 net.cpp:100] Creating Layer conv6/scale
I0628 16:42:39.841578 17458 net.cpp:434] conv6/scale <- conv6
I0628 16:42:39.841586 17458 net.cpp:395] conv6/scale -> conv6 (in-place)
I0628 16:42:39.841655 17458 layer_factory.hpp:77] Creating layer conv6/scale
I0628 16:42:39.841805 17458 net.cpp:150] Setting up conv6/scale
I0628 16:42:39.841814 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.841817 17458 net.cpp:165] Memory required for data: 477751456
I0628 16:42:39.841825 17458 layer_factory.hpp:77] Creating layer conv6/relu
I0628 16:42:39.841850 17458 net.cpp:100] Creating Layer conv6/relu
I0628 16:42:39.841857 17458 net.cpp:434] conv6/relu <- conv6
I0628 16:42:39.841866 17458 net.cpp:395] conv6/relu -> conv6 (in-place)
I0628 16:42:39.842720 17458 net.cpp:150] Setting up conv6/relu
I0628 16:42:39.842730 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.842736 17458 net.cpp:165] Memory required for data: 480708768
I0628 16:42:39.842742 17458 layer_factory.hpp:77] Creating layer conv7/dw
I0628 16:42:39.842777 17458 net.cpp:100] Creating Layer conv7/dw
I0628 16:42:39.842782 17458 net.cpp:434] conv7/dw <- conv6
I0628 16:42:39.842790 17458 net.cpp:408] conv7/dw -> conv7/dw
I0628 16:42:39.843058 17458 net.cpp:150] Setting up conv7/dw
I0628 16:42:39.843065 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.843070 17458 net.cpp:165] Memory required for data: 483666080
I0628 16:42:39.843073 17458 layer_factory.hpp:77] Creating layer conv7/dw/bn
I0628 16:42:39.843098 17458 net.cpp:100] Creating Layer conv7/dw/bn
I0628 16:42:39.843103 17458 net.cpp:434] conv7/dw/bn <- conv7/dw
I0628 16:42:39.843108 17458 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I0628 16:42:39.843331 17458 net.cpp:150] Setting up conv7/dw/bn
I0628 16:42:39.843338 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.843341 17458 net.cpp:165] Memory required for data: 486623392
I0628 16:42:39.843346 17458 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0628 16:42:39.843353 17458 net.cpp:100] Creating Layer conv7/dw/scale
I0628 16:42:39.843375 17458 net.cpp:434] conv7/dw/scale <- conv7/dw
I0628 16:42:39.843381 17458 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I0628 16:42:39.843456 17458 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0628 16:42:39.843621 17458 net.cpp:150] Setting up conv7/dw/scale
I0628 16:42:39.843627 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.843631 17458 net.cpp:165] Memory required for data: 489580704
I0628 16:42:39.843636 17458 layer_factory.hpp:77] Creating layer conv7/dw/relu
I0628 16:42:39.843641 17458 net.cpp:100] Creating Layer conv7/dw/relu
I0628 16:42:39.843663 17458 net.cpp:434] conv7/dw/relu <- conv7/dw
I0628 16:42:39.843667 17458 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I0628 16:42:39.844509 17458 net.cpp:150] Setting up conv7/dw/relu
I0628 16:42:39.844521 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.844523 17458 net.cpp:165] Memory required for data: 492538016
I0628 16:42:39.844527 17458 layer_factory.hpp:77] Creating layer conv7
I0628 16:42:39.844555 17458 net.cpp:100] Creating Layer conv7
I0628 16:42:39.844560 17458 net.cpp:434] conv7 <- conv7/dw
I0628 16:42:39.844566 17458 net.cpp:408] conv7 -> conv7
I0628 16:42:39.849859 17458 net.cpp:150] Setting up conv7
I0628 16:42:39.849896 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.849900 17458 net.cpp:165] Memory required for data: 495495328
I0628 16:42:39.849906 17458 layer_factory.hpp:77] Creating layer conv7/bn
I0628 16:42:39.849934 17458 net.cpp:100] Creating Layer conv7/bn
I0628 16:42:39.849954 17458 net.cpp:434] conv7/bn <- conv7
I0628 16:42:39.849961 17458 net.cpp:395] conv7/bn -> conv7 (in-place)
I0628 16:42:39.850204 17458 net.cpp:150] Setting up conv7/bn
I0628 16:42:39.850211 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.850214 17458 net.cpp:165] Memory required for data: 498452640
I0628 16:42:39.850245 17458 layer_factory.hpp:77] Creating layer conv7/scale
I0628 16:42:39.850253 17458 net.cpp:100] Creating Layer conv7/scale
I0628 16:42:39.850256 17458 net.cpp:434] conv7/scale <- conv7
I0628 16:42:39.850261 17458 net.cpp:395] conv7/scale -> conv7 (in-place)
I0628 16:42:39.850328 17458 layer_factory.hpp:77] Creating layer conv7/scale
I0628 16:42:39.850495 17458 net.cpp:150] Setting up conv7/scale
I0628 16:42:39.850502 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.850505 17458 net.cpp:165] Memory required for data: 501409952
I0628 16:42:39.850510 17458 layer_factory.hpp:77] Creating layer conv7/relu
I0628 16:42:39.850535 17458 net.cpp:100] Creating Layer conv7/relu
I0628 16:42:39.850540 17458 net.cpp:434] conv7/relu <- conv7
I0628 16:42:39.850544 17458 net.cpp:395] conv7/relu -> conv7 (in-place)
I0628 16:42:39.851414 17458 net.cpp:150] Setting up conv7/relu
I0628 16:42:39.851426 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.851429 17458 net.cpp:165] Memory required for data: 504367264
I0628 16:42:39.851433 17458 layer_factory.hpp:77] Creating layer conv8/dw
I0628 16:42:39.851444 17458 net.cpp:100] Creating Layer conv8/dw
I0628 16:42:39.851449 17458 net.cpp:434] conv8/dw <- conv7
I0628 16:42:39.851454 17458 net.cpp:408] conv8/dw -> conv8/dw
I0628 16:42:39.851689 17458 net.cpp:150] Setting up conv8/dw
I0628 16:42:39.851697 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.851701 17458 net.cpp:165] Memory required for data: 507324576
I0628 16:42:39.851706 17458 layer_factory.hpp:77] Creating layer conv8/dw/bn
I0628 16:42:39.851711 17458 net.cpp:100] Creating Layer conv8/dw/bn
I0628 16:42:39.851713 17458 net.cpp:434] conv8/dw/bn <- conv8/dw
I0628 16:42:39.851718 17458 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I0628 16:42:39.851935 17458 net.cpp:150] Setting up conv8/dw/bn
I0628 16:42:39.851943 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.851948 17458 net.cpp:165] Memory required for data: 510281888
I0628 16:42:39.851954 17458 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0628 16:42:39.851965 17458 net.cpp:100] Creating Layer conv8/dw/scale
I0628 16:42:39.851969 17458 net.cpp:434] conv8/dw/scale <- conv8/dw
I0628 16:42:39.851974 17458 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I0628 16:42:39.852022 17458 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0628 16:42:39.852155 17458 net.cpp:150] Setting up conv8/dw/scale
I0628 16:42:39.852162 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.852166 17458 net.cpp:165] Memory required for data: 513239200
I0628 16:42:39.852171 17458 layer_factory.hpp:77] Creating layer conv8/dw/relu
I0628 16:42:39.852177 17458 net.cpp:100] Creating Layer conv8/dw/relu
I0628 16:42:39.852180 17458 net.cpp:434] conv8/dw/relu <- conv8/dw
I0628 16:42:39.852185 17458 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I0628 16:42:39.853056 17458 net.cpp:150] Setting up conv8/dw/relu
I0628 16:42:39.853070 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.853072 17458 net.cpp:165] Memory required for data: 516196512
I0628 16:42:39.853077 17458 layer_factory.hpp:77] Creating layer conv8
I0628 16:42:39.853086 17458 net.cpp:100] Creating Layer conv8
I0628 16:42:39.853091 17458 net.cpp:434] conv8 <- conv8/dw
I0628 16:42:39.853098 17458 net.cpp:408] conv8 -> conv8
I0628 16:42:39.858471 17458 net.cpp:150] Setting up conv8
I0628 16:42:39.858507 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.858530 17458 net.cpp:165] Memory required for data: 519153824
I0628 16:42:39.858536 17458 layer_factory.hpp:77] Creating layer conv8/bn
I0628 16:42:39.858558 17458 net.cpp:100] Creating Layer conv8/bn
I0628 16:42:39.858563 17458 net.cpp:434] conv8/bn <- conv8
I0628 16:42:39.858588 17458 net.cpp:395] conv8/bn -> conv8 (in-place)
I0628 16:42:39.858850 17458 net.cpp:150] Setting up conv8/bn
I0628 16:42:39.858858 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.858861 17458 net.cpp:165] Memory required for data: 522111136
I0628 16:42:39.858886 17458 layer_factory.hpp:77] Creating layer conv8/scale
I0628 16:42:39.858908 17458 net.cpp:100] Creating Layer conv8/scale
I0628 16:42:39.858912 17458 net.cpp:434] conv8/scale <- conv8
I0628 16:42:39.858916 17458 net.cpp:395] conv8/scale -> conv8 (in-place)
I0628 16:42:39.859002 17458 layer_factory.hpp:77] Creating layer conv8/scale
I0628 16:42:39.859176 17458 net.cpp:150] Setting up conv8/scale
I0628 16:42:39.859184 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.859186 17458 net.cpp:165] Memory required for data: 525068448
I0628 16:42:39.859191 17458 layer_factory.hpp:77] Creating layer conv8/relu
I0628 16:42:39.859199 17458 net.cpp:100] Creating Layer conv8/relu
I0628 16:42:39.859201 17458 net.cpp:434] conv8/relu <- conv8
I0628 16:42:39.859205 17458 net.cpp:395] conv8/relu -> conv8 (in-place)
I0628 16:42:39.860106 17458 net.cpp:150] Setting up conv8/relu
I0628 16:42:39.860116 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.860147 17458 net.cpp:165] Memory required for data: 528025760
I0628 16:42:39.860152 17458 layer_factory.hpp:77] Creating layer conv9/dw
I0628 16:42:39.860219 17458 net.cpp:100] Creating Layer conv9/dw
I0628 16:42:39.860225 17458 net.cpp:434] conv9/dw <- conv8
I0628 16:42:39.860232 17458 net.cpp:408] conv9/dw -> conv9/dw
I0628 16:42:39.860641 17458 net.cpp:150] Setting up conv9/dw
I0628 16:42:39.860651 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.860653 17458 net.cpp:165] Memory required for data: 530983072
I0628 16:42:39.860677 17458 layer_factory.hpp:77] Creating layer conv9/dw/bn
I0628 16:42:39.860682 17458 net.cpp:100] Creating Layer conv9/dw/bn
I0628 16:42:39.860685 17458 net.cpp:434] conv9/dw/bn <- conv9/dw
I0628 16:42:39.860693 17458 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I0628 16:42:39.860977 17458 net.cpp:150] Setting up conv9/dw/bn
I0628 16:42:39.860985 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.860987 17458 net.cpp:165] Memory required for data: 533940384
I0628 16:42:39.861011 17458 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0628 16:42:39.861017 17458 net.cpp:100] Creating Layer conv9/dw/scale
I0628 16:42:39.861022 17458 net.cpp:434] conv9/dw/scale <- conv9/dw
I0628 16:42:39.861029 17458 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I0628 16:42:39.861132 17458 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0628 16:42:39.861344 17458 net.cpp:150] Setting up conv9/dw/scale
I0628 16:42:39.861352 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.861356 17458 net.cpp:165] Memory required for data: 536897696
I0628 16:42:39.861379 17458 layer_factory.hpp:77] Creating layer conv9/dw/relu
I0628 16:42:39.861384 17458 net.cpp:100] Creating Layer conv9/dw/relu
I0628 16:42:39.861387 17458 net.cpp:434] conv9/dw/relu <- conv9/dw
I0628 16:42:39.861394 17458 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I0628 16:42:39.862285 17458 net.cpp:150] Setting up conv9/dw/relu
I0628 16:42:39.862298 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.862301 17458 net.cpp:165] Memory required for data: 539855008
I0628 16:42:39.862323 17458 layer_factory.hpp:77] Creating layer conv9
I0628 16:42:39.862334 17458 net.cpp:100] Creating Layer conv9
I0628 16:42:39.862354 17458 net.cpp:434] conv9 <- conv9/dw
I0628 16:42:39.862362 17458 net.cpp:408] conv9 -> conv9
I0628 16:42:39.868248 17458 net.cpp:150] Setting up conv9
I0628 16:42:39.868268 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.868309 17458 net.cpp:165] Memory required for data: 542812320
I0628 16:42:39.868319 17458 layer_factory.hpp:77] Creating layer conv9/bn
I0628 16:42:39.868350 17458 net.cpp:100] Creating Layer conv9/bn
I0628 16:42:39.868356 17458 net.cpp:434] conv9/bn <- conv9
I0628 16:42:39.868364 17458 net.cpp:395] conv9/bn -> conv9 (in-place)
I0628 16:42:39.868638 17458 net.cpp:150] Setting up conv9/bn
I0628 16:42:39.868645 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.868649 17458 net.cpp:165] Memory required for data: 545769632
I0628 16:42:39.868674 17458 layer_factory.hpp:77] Creating layer conv9/scale
I0628 16:42:39.868681 17458 net.cpp:100] Creating Layer conv9/scale
I0628 16:42:39.868685 17458 net.cpp:434] conv9/scale <- conv9
I0628 16:42:39.868690 17458 net.cpp:395] conv9/scale -> conv9 (in-place)
I0628 16:42:39.868788 17458 layer_factory.hpp:77] Creating layer conv9/scale
I0628 16:42:39.869004 17458 net.cpp:150] Setting up conv9/scale
I0628 16:42:39.869010 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.869014 17458 net.cpp:165] Memory required for data: 548726944
I0628 16:42:39.869019 17458 layer_factory.hpp:77] Creating layer conv9/relu
I0628 16:42:39.869038 17458 net.cpp:100] Creating Layer conv9/relu
I0628 16:42:39.869041 17458 net.cpp:434] conv9/relu <- conv9
I0628 16:42:39.869060 17458 net.cpp:395] conv9/relu -> conv9 (in-place)
I0628 16:42:39.869772 17458 net.cpp:150] Setting up conv9/relu
I0628 16:42:39.869781 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.869786 17458 net.cpp:165] Memory required for data: 551684256
I0628 16:42:39.869788 17458 layer_factory.hpp:77] Creating layer conv10/dw
I0628 16:42:39.869818 17458 net.cpp:100] Creating Layer conv10/dw
I0628 16:42:39.869823 17458 net.cpp:434] conv10/dw <- conv9
I0628 16:42:39.869832 17458 net.cpp:408] conv10/dw -> conv10/dw
I0628 16:42:39.870131 17458 net.cpp:150] Setting up conv10/dw
I0628 16:42:39.870138 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.870142 17458 net.cpp:165] Memory required for data: 554641568
I0628 16:42:39.870165 17458 layer_factory.hpp:77] Creating layer conv10/dw/bn
I0628 16:42:39.870172 17458 net.cpp:100] Creating Layer conv10/dw/bn
I0628 16:42:39.870175 17458 net.cpp:434] conv10/dw/bn <- conv10/dw
I0628 16:42:39.870195 17458 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I0628 16:42:39.870463 17458 net.cpp:150] Setting up conv10/dw/bn
I0628 16:42:39.870471 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.870473 17458 net.cpp:165] Memory required for data: 557598880
I0628 16:42:39.870498 17458 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0628 16:42:39.870505 17458 net.cpp:100] Creating Layer conv10/dw/scale
I0628 16:42:39.870523 17458 net.cpp:434] conv10/dw/scale <- conv10/dw
I0628 16:42:39.870532 17458 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I0628 16:42:39.870620 17458 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0628 16:42:39.870795 17458 net.cpp:150] Setting up conv10/dw/scale
I0628 16:42:39.870803 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.870807 17458 net.cpp:165] Memory required for data: 560556192
I0628 16:42:39.870811 17458 layer_factory.hpp:77] Creating layer conv10/dw/relu
I0628 16:42:39.870817 17458 net.cpp:100] Creating Layer conv10/dw/relu
I0628 16:42:39.870821 17458 net.cpp:434] conv10/dw/relu <- conv10/dw
I0628 16:42:39.870826 17458 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I0628 16:42:39.871678 17458 net.cpp:150] Setting up conv10/dw/relu
I0628 16:42:39.871690 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.871692 17458 net.cpp:165] Memory required for data: 563513504
I0628 16:42:39.871714 17458 layer_factory.hpp:77] Creating layer conv10
I0628 16:42:39.871724 17458 net.cpp:100] Creating Layer conv10
I0628 16:42:39.871728 17458 net.cpp:434] conv10 <- conv10/dw
I0628 16:42:39.871737 17458 net.cpp:408] conv10 -> conv10
I0628 16:42:39.876821 17458 net.cpp:150] Setting up conv10
I0628 16:42:39.876852 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.876874 17458 net.cpp:165] Memory required for data: 566470816
I0628 16:42:39.876883 17458 layer_factory.hpp:77] Creating layer conv10/bn
I0628 16:42:39.876910 17458 net.cpp:100] Creating Layer conv10/bn
I0628 16:42:39.876917 17458 net.cpp:434] conv10/bn <- conv10
I0628 16:42:39.876940 17458 net.cpp:395] conv10/bn -> conv10 (in-place)
I0628 16:42:39.877239 17458 net.cpp:150] Setting up conv10/bn
I0628 16:42:39.877247 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.877250 17458 net.cpp:165] Memory required for data: 569428128
I0628 16:42:39.877256 17458 layer_factory.hpp:77] Creating layer conv10/scale
I0628 16:42:39.877275 17458 net.cpp:100] Creating Layer conv10/scale
I0628 16:42:39.877280 17458 net.cpp:434] conv10/scale <- conv10
I0628 16:42:39.877286 17458 net.cpp:395] conv10/scale -> conv10 (in-place)
I0628 16:42:39.877445 17458 layer_factory.hpp:77] Creating layer conv10/scale
I0628 16:42:39.877666 17458 net.cpp:150] Setting up conv10/scale
I0628 16:42:39.877673 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.877676 17458 net.cpp:165] Memory required for data: 572385440
I0628 16:42:39.877681 17458 layer_factory.hpp:77] Creating layer conv10/relu
I0628 16:42:39.877686 17458 net.cpp:100] Creating Layer conv10/relu
I0628 16:42:39.877709 17458 net.cpp:434] conv10/relu <- conv10
I0628 16:42:39.877730 17458 net.cpp:395] conv10/relu -> conv10 (in-place)
I0628 16:42:39.878515 17458 net.cpp:150] Setting up conv10/relu
I0628 16:42:39.878525 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.878530 17458 net.cpp:165] Memory required for data: 575342752
I0628 16:42:39.878537 17458 layer_factory.hpp:77] Creating layer conv11/dw
I0628 16:42:39.878582 17458 net.cpp:100] Creating Layer conv11/dw
I0628 16:42:39.878588 17458 net.cpp:434] conv11/dw <- conv10
I0628 16:42:39.878609 17458 net.cpp:408] conv11/dw -> conv11/dw
I0628 16:42:39.878926 17458 net.cpp:150] Setting up conv11/dw
I0628 16:42:39.878933 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.878937 17458 net.cpp:165] Memory required for data: 578300064
I0628 16:42:39.878942 17458 layer_factory.hpp:77] Creating layer conv11/dw/bn
I0628 16:42:39.878969 17458 net.cpp:100] Creating Layer conv11/dw/bn
I0628 16:42:39.878975 17458 net.cpp:434] conv11/dw/bn <- conv11/dw
I0628 16:42:39.878999 17458 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I0628 16:42:39.879254 17458 net.cpp:150] Setting up conv11/dw/bn
I0628 16:42:39.879262 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.879266 17458 net.cpp:165] Memory required for data: 581257376
I0628 16:42:39.879282 17458 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0628 16:42:39.879312 17458 net.cpp:100] Creating Layer conv11/dw/scale
I0628 16:42:39.879315 17458 net.cpp:434] conv11/dw/scale <- conv11/dw
I0628 16:42:39.879321 17458 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I0628 16:42:39.879408 17458 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0628 16:42:39.879591 17458 net.cpp:150] Setting up conv11/dw/scale
I0628 16:42:39.879598 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.879602 17458 net.cpp:165] Memory required for data: 584214688
I0628 16:42:39.879609 17458 layer_factory.hpp:77] Creating layer conv11/dw/relu
I0628 16:42:39.879617 17458 net.cpp:100] Creating Layer conv11/dw/relu
I0628 16:42:39.879644 17458 net.cpp:434] conv11/dw/relu <- conv11/dw
I0628 16:42:39.879649 17458 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I0628 16:42:39.880306 17458 net.cpp:150] Setting up conv11/dw/relu
I0628 16:42:39.880317 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.880321 17458 net.cpp:165] Memory required for data: 587172000
I0628 16:42:39.880326 17458 layer_factory.hpp:77] Creating layer conv11
I0628 16:42:39.880355 17458 net.cpp:100] Creating Layer conv11
I0628 16:42:39.880360 17458 net.cpp:434] conv11 <- conv11/dw
I0628 16:42:39.880367 17458 net.cpp:408] conv11 -> conv11
I0628 16:42:39.886777 17458 net.cpp:150] Setting up conv11
I0628 16:42:39.886813 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.886818 17458 net.cpp:165] Memory required for data: 590129312
I0628 16:42:39.886824 17458 layer_factory.hpp:77] Creating layer conv11/bn
I0628 16:42:39.886852 17458 net.cpp:100] Creating Layer conv11/bn
I0628 16:42:39.886857 17458 net.cpp:434] conv11/bn <- conv11
I0628 16:42:39.886863 17458 net.cpp:395] conv11/bn -> conv11 (in-place)
I0628 16:42:39.887174 17458 net.cpp:150] Setting up conv11/bn
I0628 16:42:39.887181 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.887184 17458 net.cpp:165] Memory required for data: 593086624
I0628 16:42:39.887190 17458 layer_factory.hpp:77] Creating layer conv11/scale
I0628 16:42:39.887217 17458 net.cpp:100] Creating Layer conv11/scale
I0628 16:42:39.887221 17458 net.cpp:434] conv11/scale <- conv11
I0628 16:42:39.887225 17458 net.cpp:395] conv11/scale -> conv11 (in-place)
I0628 16:42:39.887326 17458 layer_factory.hpp:77] Creating layer conv11/scale
I0628 16:42:39.887516 17458 net.cpp:150] Setting up conv11/scale
I0628 16:42:39.887523 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.887526 17458 net.cpp:165] Memory required for data: 596043936
I0628 16:42:39.887531 17458 layer_factory.hpp:77] Creating layer conv11/relu
I0628 16:42:39.887537 17458 net.cpp:100] Creating Layer conv11/relu
I0628 16:42:39.887560 17458 net.cpp:434] conv11/relu <- conv11
I0628 16:42:39.887564 17458 net.cpp:395] conv11/relu -> conv11 (in-place)
I0628 16:42:39.888379 17458 net.cpp:150] Setting up conv11/relu
I0628 16:42:39.888389 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.888393 17458 net.cpp:165] Memory required for data: 599001248
I0628 16:42:39.888396 17458 layer_factory.hpp:77] Creating layer conv11_conv11/relu_0_split
I0628 16:42:39.888423 17458 net.cpp:100] Creating Layer conv11_conv11/relu_0_split
I0628 16:42:39.888429 17458 net.cpp:434] conv11_conv11/relu_0_split <- conv11
I0628 16:42:39.888435 17458 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_0
I0628 16:42:39.888463 17458 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_1
I0628 16:42:39.888470 17458 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_2
I0628 16:42:39.888478 17458 net.cpp:408] conv11_conv11/relu_0_split -> conv11_conv11/relu_0_split_3
I0628 16:42:39.888550 17458 net.cpp:150] Setting up conv11_conv11/relu_0_split
I0628 16:42:39.888557 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.888561 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.888566 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.888569 17458 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0628 16:42:39.888572 17458 net.cpp:165] Memory required for data: 610830496
I0628 16:42:39.888576 17458 layer_factory.hpp:77] Creating layer conv12/dw
I0628 16:42:39.888607 17458 net.cpp:100] Creating Layer conv12/dw
I0628 16:42:39.888612 17458 net.cpp:434] conv12/dw <- conv11_conv11/relu_0_split_0
I0628 16:42:39.888617 17458 net.cpp:408] conv12/dw -> conv12/dw
I0628 16:42:39.888877 17458 net.cpp:150] Setting up conv12/dw
I0628 16:42:39.888885 17458 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0628 16:42:39.888887 17458 net.cpp:165] Memory required for data: 611649696
I0628 16:42:39.888891 17458 layer_factory.hpp:77] Creating layer conv12/dw/bn
I0628 16:42:39.888896 17458 net.cpp:100] Creating Layer conv12/dw/bn
I0628 16:42:39.888900 17458 net.cpp:434] conv12/dw/bn <- conv12/dw
I0628 16:42:39.888904 17458 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I0628 16:42:39.889166 17458 net.cpp:150] Setting up conv12/dw/bn
I0628 16:42:39.889173 17458 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0628 16:42:39.889176 17458 net.cpp:165] Memory required for data: 612468896
I0628 16:42:39.889181 17458 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0628 16:42:39.889186 17458 net.cpp:100] Creating Layer conv12/dw/scale
I0628 16:42:39.889209 17458 net.cpp:434] conv12/dw/scale <- conv12/dw
I0628 16:42:39.889214 17458 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I0628 16:42:39.889287 17458 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0628 16:42:39.889437 17458 net.cpp:150] Setting up conv12/dw/scale
I0628 16:42:39.889446 17458 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0628 16:42:39.889448 17458 net.cpp:165] Memory required for data: 613288096
I0628 16:42:39.889453 17458 layer_factory.hpp:77] Creating layer conv12/dw/relu
I0628 16:42:39.889461 17458 net.cpp:100] Creating Layer conv12/dw/relu
I0628 16:42:39.889483 17458 net.cpp:434] conv12/dw/relu <- conv12/dw
I0628 16:42:39.889487 17458 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I0628 16:42:39.890273 17458 net.cpp:150] Setting up conv12/dw/relu
I0628 16:42:39.890285 17458 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0628 16:42:39.890288 17458 net.cpp:165] Memory required for data: 614107296
I0628 16:42:39.890293 17458 layer_factory.hpp:77] Creating layer conv12
I0628 16:42:39.890328 17458 net.cpp:100] Creating Layer conv12
I0628 16:42:39.890334 17458 net.cpp:434] conv12 <- conv12/dw
I0628 16:42:39.890358 17458 net.cpp:408] conv12 -> conv12
I0628 16:42:39.897739 17458 net.cpp:150] Setting up conv12
I0628 16:42:39.897758 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.897761 17458 net.cpp:165] Memory required for data: 615745696
I0628 16:42:39.897768 17458 layer_factory.hpp:77] Creating layer conv12/bn
I0628 16:42:39.897797 17458 net.cpp:100] Creating Layer conv12/bn
I0628 16:42:39.897804 17458 net.cpp:434] conv12/bn <- conv12
I0628 16:42:39.897831 17458 net.cpp:395] conv12/bn -> conv12 (in-place)
I0628 16:42:39.898106 17458 net.cpp:150] Setting up conv12/bn
I0628 16:42:39.898114 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.898118 17458 net.cpp:165] Memory required for data: 617384096
I0628 16:42:39.898126 17458 layer_factory.hpp:77] Creating layer conv12/scale
I0628 16:42:39.898156 17458 net.cpp:100] Creating Layer conv12/scale
I0628 16:42:39.898180 17458 net.cpp:434] conv12/scale <- conv12
I0628 16:42:39.898185 17458 net.cpp:395] conv12/scale -> conv12 (in-place)
I0628 16:42:39.898299 17458 layer_factory.hpp:77] Creating layer conv12/scale
I0628 16:42:39.898483 17458 net.cpp:150] Setting up conv12/scale
I0628 16:42:39.898489 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.898494 17458 net.cpp:165] Memory required for data: 619022496
I0628 16:42:39.898499 17458 layer_factory.hpp:77] Creating layer conv12/relu
I0628 16:42:39.898526 17458 net.cpp:100] Creating Layer conv12/relu
I0628 16:42:39.898530 17458 net.cpp:434] conv12/relu <- conv12
I0628 16:42:39.898535 17458 net.cpp:395] conv12/relu -> conv12 (in-place)
I0628 16:42:39.899330 17458 net.cpp:150] Setting up conv12/relu
I0628 16:42:39.899340 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.899344 17458 net.cpp:165] Memory required for data: 620660896
I0628 16:42:39.899348 17458 layer_factory.hpp:77] Creating layer conv13/dw
I0628 16:42:39.899379 17458 net.cpp:100] Creating Layer conv13/dw
I0628 16:42:39.899384 17458 net.cpp:434] conv13/dw <- conv12
I0628 16:42:39.899407 17458 net.cpp:408] conv13/dw -> conv13/dw
I0628 16:42:39.899798 17458 net.cpp:150] Setting up conv13/dw
I0628 16:42:39.899806 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.899809 17458 net.cpp:165] Memory required for data: 622299296
I0628 16:42:39.899813 17458 layer_factory.hpp:77] Creating layer conv13/dw/bn
I0628 16:42:39.899837 17458 net.cpp:100] Creating Layer conv13/dw/bn
I0628 16:42:39.899842 17458 net.cpp:434] conv13/dw/bn <- conv13/dw
I0628 16:42:39.899847 17458 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I0628 16:42:39.900118 17458 net.cpp:150] Setting up conv13/dw/bn
I0628 16:42:39.900125 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.900128 17458 net.cpp:165] Memory required for data: 623937696
I0628 16:42:39.900135 17458 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0628 16:42:39.900159 17458 net.cpp:100] Creating Layer conv13/dw/scale
I0628 16:42:39.900163 17458 net.cpp:434] conv13/dw/scale <- conv13/dw
I0628 16:42:39.900213 17458 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I0628 16:42:39.900292 17458 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0628 16:42:39.900463 17458 net.cpp:150] Setting up conv13/dw/scale
I0628 16:42:39.900470 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.900472 17458 net.cpp:165] Memory required for data: 625576096
I0628 16:42:39.900477 17458 layer_factory.hpp:77] Creating layer conv13/dw/relu
I0628 16:42:39.900501 17458 net.cpp:100] Creating Layer conv13/dw/relu
I0628 16:42:39.900506 17458 net.cpp:434] conv13/dw/relu <- conv13/dw
I0628 16:42:39.900511 17458 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I0628 16:42:39.901305 17458 net.cpp:150] Setting up conv13/dw/relu
I0628 16:42:39.901340 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.901343 17458 net.cpp:165] Memory required for data: 627214496
I0628 16:42:39.901346 17458 layer_factory.hpp:77] Creating layer conv13
I0628 16:42:39.901356 17458 net.cpp:100] Creating Layer conv13
I0628 16:42:39.901360 17458 net.cpp:434] conv13 <- conv13/dw
I0628 16:42:39.901386 17458 net.cpp:408] conv13 -> conv13
I0628 16:42:39.914228 17458 net.cpp:150] Setting up conv13
I0628 16:42:39.914252 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.914255 17458 net.cpp:165] Memory required for data: 628852896
I0628 16:42:39.914266 17458 layer_factory.hpp:77] Creating layer conv13/bn
I0628 16:42:39.914299 17458 net.cpp:100] Creating Layer conv13/bn
I0628 16:42:39.914306 17458 net.cpp:434] conv13/bn <- conv13
I0628 16:42:39.914314 17458 net.cpp:395] conv13/bn -> conv13 (in-place)
I0628 16:42:39.914577 17458 net.cpp:150] Setting up conv13/bn
I0628 16:42:39.914583 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.914587 17458 net.cpp:165] Memory required for data: 630491296
I0628 16:42:39.914597 17458 layer_factory.hpp:77] Creating layer conv13/scale
I0628 16:42:39.914624 17458 net.cpp:100] Creating Layer conv13/scale
I0628 16:42:39.914649 17458 net.cpp:434] conv13/scale <- conv13
I0628 16:42:39.914655 17458 net.cpp:395] conv13/scale -> conv13 (in-place)
I0628 16:42:39.914739 17458 layer_factory.hpp:77] Creating layer conv13/scale
I0628 16:42:39.914913 17458 net.cpp:150] Setting up conv13/scale
I0628 16:42:39.914921 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.914924 17458 net.cpp:165] Memory required for data: 632129696
I0628 16:42:39.914928 17458 layer_factory.hpp:77] Creating layer conv13/relu
I0628 16:42:39.914935 17458 net.cpp:100] Creating Layer conv13/relu
I0628 16:42:39.914959 17458 net.cpp:434] conv13/relu <- conv13
I0628 16:42:39.914963 17458 net.cpp:395] conv13/relu -> conv13 (in-place)
I0628 16:42:39.915848 17458 net.cpp:150] Setting up conv13/relu
I0628 16:42:39.915859 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.915863 17458 net.cpp:165] Memory required for data: 633768096
I0628 16:42:39.915866 17458 layer_factory.hpp:77] Creating layer conv13_conv13/relu_0_split
I0628 16:42:39.915874 17458 net.cpp:100] Creating Layer conv13_conv13/relu_0_split
I0628 16:42:39.915879 17458 net.cpp:434] conv13_conv13/relu_0_split <- conv13
I0628 16:42:39.915885 17458 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_0
I0628 16:42:39.915892 17458 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_1
I0628 16:42:39.915900 17458 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_2
I0628 16:42:39.915907 17458 net.cpp:408] conv13_conv13/relu_0_split -> conv13_conv13/relu_0_split_3
I0628 16:42:39.915977 17458 net.cpp:150] Setting up conv13_conv13/relu_0_split
I0628 16:42:39.915984 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.915988 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.915992 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.915997 17458 net.cpp:157] Top shape: 4 1024 10 10 (409600)
I0628 16:42:39.915999 17458 net.cpp:165] Memory required for data: 640321696
I0628 16:42:39.916002 17458 layer_factory.hpp:77] Creating layer conv14_1
I0628 16:42:39.916040 17458 net.cpp:100] Creating Layer conv14_1
I0628 16:42:39.916045 17458 net.cpp:434] conv14_1 <- conv13_conv13/relu_0_split_0
I0628 16:42:39.916052 17458 net.cpp:408] conv14_1 -> conv14_1
I0628 16:42:39.921486 17458 net.cpp:150] Setting up conv14_1
I0628 16:42:39.921506 17458 net.cpp:157] Top shape: 4 256 10 10 (102400)
I0628 16:42:39.921510 17458 net.cpp:165] Memory required for data: 640731296
I0628 16:42:39.921517 17458 layer_factory.hpp:77] Creating layer conv14_1/bn
I0628 16:42:39.921545 17458 net.cpp:100] Creating Layer conv14_1/bn
I0628 16:42:39.921553 17458 net.cpp:434] conv14_1/bn <- conv14_1
I0628 16:42:39.921576 17458 net.cpp:395] conv14_1/bn -> conv14_1 (in-place)
I0628 16:42:39.921798 17458 net.cpp:150] Setting up conv14_1/bn
I0628 16:42:39.921805 17458 net.cpp:157] Top shape: 4 256 10 10 (102400)
I0628 16:42:39.921810 17458 net.cpp:165] Memory required for data: 641140896
I0628 16:42:39.921818 17458 layer_factory.hpp:77] Creating layer conv14_1/scale
I0628 16:42:39.921849 17458 net.cpp:100] Creating Layer conv14_1/scale
I0628 16:42:39.921854 17458 net.cpp:434] conv14_1/scale <- conv14_1
I0628 16:42:39.921859 17458 net.cpp:395] conv14_1/scale -> conv14_1 (in-place)
I0628 16:42:39.921985 17458 layer_factory.hpp:77] Creating layer conv14_1/scale
I0628 16:42:39.922192 17458 net.cpp:150] Setting up conv14_1/scale
I0628 16:42:39.922199 17458 net.cpp:157] Top shape: 4 256 10 10 (102400)
I0628 16:42:39.922201 17458 net.cpp:165] Memory required for data: 641550496
I0628 16:42:39.922206 17458 layer_factory.hpp:77] Creating layer conv14_1/relu
I0628 16:42:39.922231 17458 net.cpp:100] Creating Layer conv14_1/relu
I0628 16:42:39.922235 17458 net.cpp:434] conv14_1/relu <- conv14_1
I0628 16:42:39.922240 17458 net.cpp:395] conv14_1/relu -> conv14_1 (in-place)
I0628 16:42:39.923056 17458 net.cpp:150] Setting up conv14_1/relu
I0628 16:42:39.923068 17458 net.cpp:157] Top shape: 4 256 10 10 (102400)
I0628 16:42:39.923071 17458 net.cpp:165] Memory required for data: 641960096
I0628 16:42:39.923075 17458 layer_factory.hpp:77] Creating layer conv14_2
I0628 16:42:39.923103 17458 net.cpp:100] Creating Layer conv14_2
I0628 16:42:39.923108 17458 net.cpp:434] conv14_2 <- conv14_1
I0628 16:42:39.923116 17458 net.cpp:408] conv14_2 -> conv14_2
I0628 16:42:39.937273 17458 net.cpp:150] Setting up conv14_2
I0628 16:42:39.937296 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.937300 17458 net.cpp:165] Memory required for data: 642164896
I0628 16:42:39.937336 17458 layer_factory.hpp:77] Creating layer conv14_2/bn
I0628 16:42:39.937364 17458 net.cpp:100] Creating Layer conv14_2/bn
I0628 16:42:39.937389 17458 net.cpp:434] conv14_2/bn <- conv14_2
I0628 16:42:39.937397 17458 net.cpp:395] conv14_2/bn -> conv14_2 (in-place)
I0628 16:42:39.937678 17458 net.cpp:150] Setting up conv14_2/bn
I0628 16:42:39.937685 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.937688 17458 net.cpp:165] Memory required for data: 642369696
I0628 16:42:39.937695 17458 layer_factory.hpp:77] Creating layer conv14_2/scale
I0628 16:42:39.937721 17458 net.cpp:100] Creating Layer conv14_2/scale
I0628 16:42:39.937726 17458 net.cpp:434] conv14_2/scale <- conv14_2
I0628 16:42:39.937731 17458 net.cpp:395] conv14_2/scale -> conv14_2 (in-place)
I0628 16:42:39.937883 17458 layer_factory.hpp:77] Creating layer conv14_2/scale
I0628 16:42:39.938096 17458 net.cpp:150] Setting up conv14_2/scale
I0628 16:42:39.938102 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.938105 17458 net.cpp:165] Memory required for data: 642574496
I0628 16:42:39.938110 17458 layer_factory.hpp:77] Creating layer conv14_2/relu
I0628 16:42:39.938135 17458 net.cpp:100] Creating Layer conv14_2/relu
I0628 16:42:39.938139 17458 net.cpp:434] conv14_2/relu <- conv14_2
I0628 16:42:39.938143 17458 net.cpp:395] conv14_2/relu -> conv14_2 (in-place)
I0628 16:42:39.938947 17458 net.cpp:150] Setting up conv14_2/relu
I0628 16:42:39.938957 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.938961 17458 net.cpp:165] Memory required for data: 642779296
I0628 16:42:39.938998 17458 layer_factory.hpp:77] Creating layer conv14_2_conv14_2/relu_0_split
I0628 16:42:39.939024 17458 net.cpp:100] Creating Layer conv14_2_conv14_2/relu_0_split
I0628 16:42:39.939029 17458 net.cpp:434] conv14_2_conv14_2/relu_0_split <- conv14_2
I0628 16:42:39.939051 17458 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_0
I0628 16:42:39.939076 17458 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_1
I0628 16:42:39.939097 17458 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_2
I0628 16:42:39.939121 17458 net.cpp:408] conv14_2_conv14_2/relu_0_split -> conv14_2_conv14_2/relu_0_split_3
I0628 16:42:39.939294 17458 net.cpp:150] Setting up conv14_2_conv14_2/relu_0_split
I0628 16:42:39.939301 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.939304 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.939308 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.939312 17458 net.cpp:157] Top shape: 4 512 5 5 (51200)
I0628 16:42:39.939329 17458 net.cpp:165] Memory required for data: 643598496
I0628 16:42:39.939332 17458 layer_factory.hpp:77] Creating layer conv15_1
I0628 16:42:39.939343 17458 net.cpp:100] Creating Layer conv15_1
I0628 16:42:39.939348 17458 net.cpp:434] conv15_1 <- conv14_2_conv14_2/relu_0_split_0
I0628 16:42:39.939353 17458 net.cpp:408] conv15_1 -> conv15_1
I0628 16:42:39.943140 17458 net.cpp:150] Setting up conv15_1
I0628 16:42:39.943153 17458 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0628 16:42:39.943157 17458 net.cpp:165] Memory required for data: 643649696
I0628 16:42:39.943163 17458 layer_factory.hpp:77] Creating layer conv15_1/bn
I0628 16:42:39.943172 17458 net.cpp:100] Creating Layer conv15_1/bn
I0628 16:42:39.943179 17458 net.cpp:434] conv15_1/bn <- conv15_1
I0628 16:42:39.943186 17458 net.cpp:395] conv15_1/bn -> conv15_1 (in-place)
I0628 16:42:39.943401 17458 net.cpp:150] Setting up conv15_1/bn
I0628 16:42:39.943408 17458 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0628 16:42:39.943413 17458 net.cpp:165] Memory required for data: 643700896
I0628 16:42:39.943421 17458 layer_factory.hpp:77] Creating layer conv15_1/scale
I0628 16:42:39.943431 17458 net.cpp:100] Creating Layer conv15_1/scale
I0628 16:42:39.943436 17458 net.cpp:434] conv15_1/scale <- conv15_1
I0628 16:42:39.943441 17458 net.cpp:395] conv15_1/scale -> conv15_1 (in-place)
I0628 16:42:39.943480 17458 layer_factory.hpp:77] Creating layer conv15_1/scale
I0628 16:42:39.943651 17458 net.cpp:150] Setting up conv15_1/scale
I0628 16:42:39.943658 17458 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0628 16:42:39.943661 17458 net.cpp:165] Memory required for data: 643752096
I0628 16:42:39.943665 17458 layer_factory.hpp:77] Creating layer conv15_1/relu
I0628 16:42:39.943672 17458 net.cpp:100] Creating Layer conv15_1/relu
I0628 16:42:39.943694 17458 net.cpp:434] conv15_1/relu <- conv15_1
I0628 16:42:39.943699 17458 net.cpp:395] conv15_1/relu -> conv15_1 (in-place)
I0628 16:42:39.944316 17458 net.cpp:150] Setting up conv15_1/relu
I0628 16:42:39.944325 17458 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0628 16:42:39.944330 17458 net.cpp:165] Memory required for data: 643803296
I0628 16:42:39.944335 17458 layer_factory.hpp:77] Creating layer conv15_2
I0628 16:42:39.944365 17458 net.cpp:100] Creating Layer conv15_2
I0628 16:42:39.944370 17458 net.cpp:434] conv15_2 <- conv15_1
I0628 16:42:39.944377 17458 net.cpp:408] conv15_2 -> conv15_2
I0628 16:42:39.950467 17458 net.cpp:150] Setting up conv15_2
I0628 16:42:39.950489 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.950492 17458 net.cpp:165] Memory required for data: 643840160
I0628 16:42:39.950500 17458 layer_factory.hpp:77] Creating layer conv15_2/bn
I0628 16:42:39.950527 17458 net.cpp:100] Creating Layer conv15_2/bn
I0628 16:42:39.950533 17458 net.cpp:434] conv15_2/bn <- conv15_2
I0628 16:42:39.950558 17458 net.cpp:395] conv15_2/bn -> conv15_2 (in-place)
I0628 16:42:39.950876 17458 net.cpp:150] Setting up conv15_2/bn
I0628 16:42:39.950882 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.950917 17458 net.cpp:165] Memory required for data: 643877024
I0628 16:42:39.950942 17458 layer_factory.hpp:77] Creating layer conv15_2/scale
I0628 16:42:39.950966 17458 net.cpp:100] Creating Layer conv15_2/scale
I0628 16:42:39.950971 17458 net.cpp:434] conv15_2/scale <- conv15_2
I0628 16:42:39.950994 17458 net.cpp:395] conv15_2/scale -> conv15_2 (in-place)
I0628 16:42:39.951088 17458 layer_factory.hpp:77] Creating layer conv15_2/scale
I0628 16:42:39.951297 17458 net.cpp:150] Setting up conv15_2/scale
I0628 16:42:39.951303 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.951306 17458 net.cpp:165] Memory required for data: 643913888
I0628 16:42:39.951330 17458 layer_factory.hpp:77] Creating layer conv15_2/relu
I0628 16:42:39.951340 17458 net.cpp:100] Creating Layer conv15_2/relu
I0628 16:42:39.951364 17458 net.cpp:434] conv15_2/relu <- conv15_2
I0628 16:42:39.951367 17458 net.cpp:395] conv15_2/relu -> conv15_2 (in-place)
I0628 16:42:39.952240 17458 net.cpp:150] Setting up conv15_2/relu
I0628 16:42:39.952251 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.952255 17458 net.cpp:165] Memory required for data: 643950752
I0628 16:42:39.952260 17458 layer_factory.hpp:77] Creating layer conv15_2_conv15_2/relu_0_split
I0628 16:42:39.952266 17458 net.cpp:100] Creating Layer conv15_2_conv15_2/relu_0_split
I0628 16:42:39.952291 17458 net.cpp:434] conv15_2_conv15_2/relu_0_split <- conv15_2
I0628 16:42:39.952296 17458 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_0
I0628 16:42:39.952304 17458 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_1
I0628 16:42:39.952311 17458 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_2
I0628 16:42:39.952316 17458 net.cpp:408] conv15_2_conv15_2/relu_0_split -> conv15_2_conv15_2/relu_0_split_3
I0628 16:42:39.952404 17458 net.cpp:150] Setting up conv15_2_conv15_2/relu_0_split
I0628 16:42:39.952410 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.952414 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.952419 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.952440 17458 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0628 16:42:39.952445 17458 net.cpp:165] Memory required for data: 644098208
I0628 16:42:39.952448 17458 layer_factory.hpp:77] Creating layer conv16_1
I0628 16:42:39.952473 17458 net.cpp:100] Creating Layer conv16_1
I0628 16:42:39.952491 17458 net.cpp:434] conv16_1 <- conv15_2_conv15_2/relu_0_split_0
I0628 16:42:39.952497 17458 net.cpp:408] conv16_1 -> conv16_1
I0628 16:42:39.955250 17458 net.cpp:150] Setting up conv16_1
I0628 16:42:39.955261 17458 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0628 16:42:39.955265 17458 net.cpp:165] Memory required for data: 644116640
I0628 16:42:39.955271 17458 layer_factory.hpp:77] Creating layer conv16_1/bn
I0628 16:42:39.955296 17458 net.cpp:100] Creating Layer conv16_1/bn
I0628 16:42:39.955302 17458 net.cpp:434] conv16_1/bn <- conv16_1
I0628 16:42:39.955322 17458 net.cpp:395] conv16_1/bn -> conv16_1 (in-place)
I0628 16:42:39.955619 17458 net.cpp:150] Setting up conv16_1/bn
I0628 16:42:39.955626 17458 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0628 16:42:39.955628 17458 net.cpp:165] Memory required for data: 644135072
I0628 16:42:39.955634 17458 layer_factory.hpp:77] Creating layer conv16_1/scale
I0628 16:42:39.955639 17458 net.cpp:100] Creating Layer conv16_1/scale
I0628 16:42:39.955662 17458 net.cpp:434] conv16_1/scale <- conv16_1
I0628 16:42:39.955667 17458 net.cpp:395] conv16_1/scale -> conv16_1 (in-place)
I0628 16:42:39.955755 17458 layer_factory.hpp:77] Creating layer conv16_1/scale
I0628 16:42:39.955911 17458 net.cpp:150] Setting up conv16_1/scale
I0628 16:42:39.955919 17458 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0628 16:42:39.955921 17458 net.cpp:165] Memory required for data: 644153504
I0628 16:42:39.955925 17458 layer_factory.hpp:77] Creating layer conv16_1/relu
I0628 16:42:39.955931 17458 net.cpp:100] Creating Layer conv16_1/relu
I0628 16:42:39.955935 17458 net.cpp:434] conv16_1/relu <- conv16_1
I0628 16:42:39.955968 17458 net.cpp:395] conv16_1/relu -> conv16_1 (in-place)
I0628 16:42:39.956773 17458 net.cpp:150] Setting up conv16_1/relu
I0628 16:42:39.956784 17458 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0628 16:42:39.956789 17458 net.cpp:165] Memory required for data: 644171936
I0628 16:42:39.956791 17458 layer_factory.hpp:77] Creating layer conv16_2
I0628 16:42:39.956820 17458 net.cpp:100] Creating Layer conv16_2
I0628 16:42:39.956825 17458 net.cpp:434] conv16_2 <- conv16_1
I0628 16:42:39.956830 17458 net.cpp:408] conv16_2 -> conv16_2
I0628 16:42:39.962774 17458 net.cpp:150] Setting up conv16_2
I0628 16:42:39.962793 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.962797 17458 net.cpp:165] Memory required for data: 644188320
I0628 16:42:39.962805 17458 layer_factory.hpp:77] Creating layer conv16_2/bn
I0628 16:42:39.962831 17458 net.cpp:100] Creating Layer conv16_2/bn
I0628 16:42:39.962838 17458 net.cpp:434] conv16_2/bn <- conv16_2
I0628 16:42:39.962857 17458 net.cpp:395] conv16_2/bn -> conv16_2 (in-place)
I0628 16:42:39.963110 17458 net.cpp:150] Setting up conv16_2/bn
I0628 16:42:39.963117 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.963120 17458 net.cpp:165] Memory required for data: 644204704
I0628 16:42:39.963129 17458 layer_factory.hpp:77] Creating layer conv16_2/scale
I0628 16:42:39.963156 17458 net.cpp:100] Creating Layer conv16_2/scale
I0628 16:42:39.963160 17458 net.cpp:434] conv16_2/scale <- conv16_2
I0628 16:42:39.963184 17458 net.cpp:395] conv16_2/scale -> conv16_2 (in-place)
I0628 16:42:39.963272 17458 layer_factory.hpp:77] Creating layer conv16_2/scale
I0628 16:42:39.963467 17458 net.cpp:150] Setting up conv16_2/scale
I0628 16:42:39.963474 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.963479 17458 net.cpp:165] Memory required for data: 644221088
I0628 16:42:39.963483 17458 layer_factory.hpp:77] Creating layer conv16_2/relu
I0628 16:42:39.963488 17458 net.cpp:100] Creating Layer conv16_2/relu
I0628 16:42:39.963493 17458 net.cpp:434] conv16_2/relu <- conv16_2
I0628 16:42:39.963500 17458 net.cpp:395] conv16_2/relu -> conv16_2 (in-place)
I0628 16:42:39.964363 17458 net.cpp:150] Setting up conv16_2/relu
I0628 16:42:39.964375 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.964378 17458 net.cpp:165] Memory required for data: 644237472
I0628 16:42:39.964382 17458 layer_factory.hpp:77] Creating layer conv16_2_conv16_2/relu_0_split
I0628 16:42:39.964390 17458 net.cpp:100] Creating Layer conv16_2_conv16_2/relu_0_split
I0628 16:42:39.964412 17458 net.cpp:434] conv16_2_conv16_2/relu_0_split <- conv16_2
I0628 16:42:39.964419 17458 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_0
I0628 16:42:39.964442 17458 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_1
I0628 16:42:39.964448 17458 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_2
I0628 16:42:39.964454 17458 net.cpp:408] conv16_2_conv16_2/relu_0_split -> conv16_2_conv16_2/relu_0_split_3
I0628 16:42:39.964541 17458 net.cpp:150] Setting up conv16_2_conv16_2/relu_0_split
I0628 16:42:39.964547 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.964551 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.964555 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.964560 17458 net.cpp:157] Top shape: 4 256 2 2 (4096)
I0628 16:42:39.964581 17458 net.cpp:165] Memory required for data: 644303008
I0628 16:42:39.964584 17458 layer_factory.hpp:77] Creating layer conv17_1
I0628 16:42:39.964593 17458 net.cpp:100] Creating Layer conv17_1
I0628 16:42:39.964598 17458 net.cpp:434] conv17_1 <- conv16_2_conv16_2/relu_0_split_0
I0628 16:42:39.964603 17458 net.cpp:408] conv17_1 -> conv17_1
I0628 16:42:39.967221 17458 net.cpp:150] Setting up conv17_1
I0628 16:42:39.967231 17458 net.cpp:157] Top shape: 4 64 2 2 (1024)
I0628 16:42:39.967236 17458 net.cpp:165] Memory required for data: 644307104
I0628 16:42:39.967240 17458 layer_factory.hpp:77] Creating layer conv17_1/bn
I0628 16:42:39.967284 17458 net.cpp:100] Creating Layer conv17_1/bn
I0628 16:42:39.967289 17458 net.cpp:434] conv17_1/bn <- conv17_1
I0628 16:42:39.967294 17458 net.cpp:395] conv17_1/bn -> conv17_1 (in-place)
I0628 16:42:39.967522 17458 net.cpp:150] Setting up conv17_1/bn
I0628 16:42:39.967530 17458 net.cpp:157] Top shape: 4 64 2 2 (1024)
I0628 16:42:39.967532 17458 net.cpp:165] Memory required for data: 644311200
I0628 16:42:39.967538 17458 layer_factory.hpp:77] Creating layer conv17_1/scale
I0628 16:42:39.967564 17458 net.cpp:100] Creating Layer conv17_1/scale
I0628 16:42:39.967569 17458 net.cpp:434] conv17_1/scale <- conv17_1
I0628 16:42:39.967574 17458 net.cpp:395] conv17_1/scale -> conv17_1 (in-place)
I0628 16:42:39.967629 17458 layer_factory.hpp:77] Creating layer conv17_1/scale
I0628 16:42:39.967795 17458 net.cpp:150] Setting up conv17_1/scale
I0628 16:42:39.967801 17458 net.cpp:157] Top shape: 4 64 2 2 (1024)
I0628 16:42:39.967805 17458 net.cpp:165] Memory required for data: 644315296
I0628 16:42:39.967809 17458 layer_factory.hpp:77] Creating layer conv17_1/relu
I0628 16:42:39.967814 17458 net.cpp:100] Creating Layer conv17_1/relu
I0628 16:42:39.967837 17458 net.cpp:434] conv17_1/relu <- conv17_1
I0628 16:42:39.967841 17458 net.cpp:395] conv17_1/relu -> conv17_1 (in-place)
I0628 16:42:39.968621 17458 net.cpp:150] Setting up conv17_1/relu
I0628 16:42:39.968632 17458 net.cpp:157] Top shape: 4 64 2 2 (1024)
I0628 16:42:39.968636 17458 net.cpp:165] Memory required for data: 644319392
I0628 16:42:39.968639 17458 layer_factory.hpp:77] Creating layer conv17_2
I0628 16:42:39.968667 17458 net.cpp:100] Creating Layer conv17_2
I0628 16:42:39.968672 17458 net.cpp:434] conv17_2 <- conv17_1
I0628 16:42:39.968679 17458 net.cpp:408] conv17_2 -> conv17_2
I0628 16:42:39.971899 17458 net.cpp:150] Setting up conv17_2
I0628 16:42:39.971911 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.971915 17458 net.cpp:165] Memory required for data: 644321440
I0628 16:42:39.971920 17458 layer_factory.hpp:77] Creating layer conv17_2/bn
I0628 16:42:39.971946 17458 net.cpp:100] Creating Layer conv17_2/bn
I0628 16:42:39.971952 17458 net.cpp:434] conv17_2/bn <- conv17_2
I0628 16:42:39.971957 17458 net.cpp:395] conv17_2/bn -> conv17_2 (in-place)
I0628 16:42:39.972187 17458 net.cpp:150] Setting up conv17_2/bn
I0628 16:42:39.972193 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.972198 17458 net.cpp:165] Memory required for data: 644323488
I0628 16:42:39.972203 17458 layer_factory.hpp:77] Creating layer conv17_2/scale
I0628 16:42:39.972229 17458 net.cpp:100] Creating Layer conv17_2/scale
I0628 16:42:39.972234 17458 net.cpp:434] conv17_2/scale <- conv17_2
I0628 16:42:39.972254 17458 net.cpp:395] conv17_2/scale -> conv17_2 (in-place)
I0628 16:42:39.972291 17458 layer_factory.hpp:77] Creating layer conv17_2/scale
I0628 16:42:39.972407 17458 net.cpp:150] Setting up conv17_2/scale
I0628 16:42:39.972414 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.972417 17458 net.cpp:165] Memory required for data: 644325536
I0628 16:42:39.972422 17458 layer_factory.hpp:77] Creating layer conv17_2/relu
I0628 16:42:39.972429 17458 net.cpp:100] Creating Layer conv17_2/relu
I0628 16:42:39.972432 17458 net.cpp:434] conv17_2/relu <- conv17_2
I0628 16:42:39.972436 17458 net.cpp:395] conv17_2/relu -> conv17_2 (in-place)
I0628 16:42:39.973065 17458 net.cpp:150] Setting up conv17_2/relu
I0628 16:42:39.973073 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.973076 17458 net.cpp:165] Memory required for data: 644327584
I0628 16:42:39.973080 17458 layer_factory.hpp:77] Creating layer conv17_2_conv17_2/relu_0_split
I0628 16:42:39.973088 17458 net.cpp:100] Creating Layer conv17_2_conv17_2/relu_0_split
I0628 16:42:39.973111 17458 net.cpp:434] conv17_2_conv17_2/relu_0_split <- conv17_2
I0628 16:42:39.973116 17458 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_0
I0628 16:42:39.973129 17458 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_1
I0628 16:42:39.973136 17458 net.cpp:408] conv17_2_conv17_2/relu_0_split -> conv17_2_conv17_2/relu_0_split_2
I0628 16:42:39.973224 17458 net.cpp:150] Setting up conv17_2_conv17_2/relu_0_split
I0628 16:42:39.973232 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.973235 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.973253 17458 net.cpp:157] Top shape: 4 128 1 1 (512)
I0628 16:42:39.973255 17458 net.cpp:165] Memory required for data: 644333728
I0628 16:42:39.973258 17458 layer_factory.hpp:77] Creating layer conv11_mbox_loc
I0628 16:42:39.973295 17458 net.cpp:100] Creating Layer conv11_mbox_loc
I0628 16:42:39.973311 17458 net.cpp:434] conv11_mbox_loc <- conv11_conv11/relu_0_split_1
I0628 16:42:39.973320 17458 net.cpp:408] conv11_mbox_loc -> conv11_mbox_loc
I0628 16:42:39.976035 17458 net.cpp:150] Setting up conv11_mbox_loc
I0628 16:42:39.976048 17458 net.cpp:157] Top shape: 4 12 19 19 (17328)
I0628 16:42:39.976052 17458 net.cpp:165] Memory required for data: 644403040
I0628 16:42:39.976058 17458 layer_factory.hpp:77] Creating layer conv11_mbox_loc_perm
I0628 16:42:39.976083 17458 net.cpp:100] Creating Layer conv11_mbox_loc_perm
I0628 16:42:39.976089 17458 net.cpp:434] conv11_mbox_loc_perm <- conv11_mbox_loc
I0628 16:42:39.976096 17458 net.cpp:408] conv11_mbox_loc_perm -> conv11_mbox_loc_perm
I0628 16:42:39.976227 17458 net.cpp:150] Setting up conv11_mbox_loc_perm
I0628 16:42:39.976233 17458 net.cpp:157] Top shape: 4 19 19 12 (17328)
I0628 16:42:39.976236 17458 net.cpp:165] Memory required for data: 644472352
I0628 16:42:39.976240 17458 layer_factory.hpp:77] Creating layer conv11_mbox_loc_flat
I0628 16:42:39.976245 17458 net.cpp:100] Creating Layer conv11_mbox_loc_flat
I0628 16:42:39.976269 17458 net.cpp:434] conv11_mbox_loc_flat <- conv11_mbox_loc_perm
I0628 16:42:39.976275 17458 net.cpp:408] conv11_mbox_loc_flat -> conv11_mbox_loc_flat
I0628 16:42:39.976301 17458 net.cpp:150] Setting up conv11_mbox_loc_flat
I0628 16:42:39.976307 17458 net.cpp:157] Top shape: 4 4332 (17328)
I0628 16:42:39.976327 17458 net.cpp:165] Memory required for data: 644541664
I0628 16:42:39.976330 17458 layer_factory.hpp:77] Creating layer conv11_mbox_conf_new
I0628 16:42:39.976359 17458 net.cpp:100] Creating Layer conv11_mbox_conf_new
I0628 16:42:39.976366 17458 net.cpp:434] conv11_mbox_conf_new <- conv11_conv11/relu_0_split_2
I0628 16:42:39.976372 17458 net.cpp:408] conv11_mbox_conf_new -> conv11_mbox_conf
I0628 16:42:39.979111 17458 net.cpp:150] Setting up conv11_mbox_conf_new
I0628 16:42:39.979125 17458 net.cpp:157] Top shape: 4 6 19 19 (8664)
I0628 16:42:39.979128 17458 net.cpp:165] Memory required for data: 644576320
I0628 16:42:39.979135 17458 layer_factory.hpp:77] Creating layer conv11_mbox_conf_perm
I0628 16:42:39.979142 17458 net.cpp:100] Creating Layer conv11_mbox_conf_perm
I0628 16:42:39.979148 17458 net.cpp:434] conv11_mbox_conf_perm <- conv11_mbox_conf
I0628 16:42:39.979156 17458 net.cpp:408] conv11_mbox_conf_perm -> conv11_mbox_conf_perm
I0628 16:42:39.979270 17458 net.cpp:150] Setting up conv11_mbox_conf_perm
I0628 16:42:39.979277 17458 net.cpp:157] Top shape: 4 19 19 6 (8664)
I0628 16:42:39.979280 17458 net.cpp:165] Memory required for data: 644610976
I0628 16:42:39.979285 17458 layer_factory.hpp:77] Creating layer conv11_mbox_conf_flat
I0628 16:42:39.979290 17458 net.cpp:100] Creating Layer conv11_mbox_conf_flat
I0628 16:42:39.979295 17458 net.cpp:434] conv11_mbox_conf_flat <- conv11_mbox_conf_perm
I0628 16:42:39.979300 17458 net.cpp:408] conv11_mbox_conf_flat -> conv11_mbox_conf_flat
I0628 16:42:39.979323 17458 net.cpp:150] Setting up conv11_mbox_conf_flat
I0628 16:42:39.979329 17458 net.cpp:157] Top shape: 4 2166 (8664)
I0628 16:42:39.979333 17458 net.cpp:165] Memory required for data: 644645632
I0628 16:42:39.979341 17458 layer_factory.hpp:77] Creating layer conv11_mbox_priorbox
I0628 16:42:39.979347 17458 net.cpp:100] Creating Layer conv11_mbox_priorbox
I0628 16:42:39.979351 17458 net.cpp:434] conv11_mbox_priorbox <- conv11_conv11/relu_0_split_3
I0628 16:42:39.979357 17458 net.cpp:434] conv11_mbox_priorbox <- data_data_0_split_1
I0628 16:42:39.979377 17458 net.cpp:408] conv11_mbox_priorbox -> conv11_mbox_priorbox
I0628 16:42:39.979408 17458 net.cpp:150] Setting up conv11_mbox_priorbox
I0628 16:42:39.979413 17458 net.cpp:157] Top shape: 1 2 4332 (8664)
I0628 16:42:39.979416 17458 net.cpp:165] Memory required for data: 644680288
I0628 16:42:39.979420 17458 layer_factory.hpp:77] Creating layer conv13_mbox_loc
I0628 16:42:39.979429 17458 net.cpp:100] Creating Layer conv13_mbox_loc
I0628 16:42:39.979434 17458 net.cpp:434] conv13_mbox_loc <- conv13_conv13/relu_0_split_1
I0628 16:42:39.979439 17458 net.cpp:408] conv13_mbox_loc -> conv13_mbox_loc
I0628 16:42:39.982990 17458 net.cpp:150] Setting up conv13_mbox_loc
I0628 16:42:39.983006 17458 net.cpp:157] Top shape: 4 24 10 10 (9600)
I0628 16:42:39.983009 17458 net.cpp:165] Memory required for data: 644718688
I0628 16:42:39.983016 17458 layer_factory.hpp:77] Creating layer conv13_mbox_loc_perm
I0628 16:42:39.983026 17458 net.cpp:100] Creating Layer conv13_mbox_loc_perm
I0628 16:42:39.983048 17458 net.cpp:434] conv13_mbox_loc_perm <- conv13_mbox_loc
I0628 16:42:39.983054 17458 net.cpp:408] conv13_mbox_loc_perm -> conv13_mbox_loc_perm
I0628 16:42:39.983201 17458 net.cpp:150] Setting up conv13_mbox_loc_perm
I0628 16:42:39.983207 17458 net.cpp:157] Top shape: 4 10 10 24 (9600)
I0628 16:42:39.983211 17458 net.cpp:165] Memory required for data: 644757088
I0628 16:42:39.983214 17458 layer_factory.hpp:77] Creating layer conv13_mbox_loc_flat
I0628 16:42:39.983222 17458 net.cpp:100] Creating Layer conv13_mbox_loc_flat
I0628 16:42:39.983245 17458 net.cpp:434] conv13_mbox_loc_flat <- conv13_mbox_loc_perm
I0628 16:42:39.983250 17458 net.cpp:408] conv13_mbox_loc_flat -> conv13_mbox_loc_flat
I0628 16:42:39.983276 17458 net.cpp:150] Setting up conv13_mbox_loc_flat
I0628 16:42:39.983281 17458 net.cpp:157] Top shape: 4 2400 (9600)
I0628 16:42:39.983285 17458 net.cpp:165] Memory required for data: 644795488
I0628 16:42:39.983305 17458 layer_factory.hpp:77] Creating layer conv13_mbox_conf_new
I0628 16:42:39.983335 17458 net.cpp:100] Creating Layer conv13_mbox_conf_new
I0628 16:42:39.983340 17458 net.cpp:434] conv13_mbox_conf_new <- conv13_conv13/relu_0_split_2
I0628 16:42:39.983345 17458 net.cpp:408] conv13_mbox_conf_new -> conv13_mbox_conf
I0628 16:42:39.986160 17458 net.cpp:150] Setting up conv13_mbox_conf_new
I0628 16:42:39.986173 17458 net.cpp:157] Top shape: 4 12 10 10 (4800)
I0628 16:42:39.986177 17458 net.cpp:165] Memory required for data: 644814688
I0628 16:42:39.986182 17458 layer_factory.hpp:77] Creating layer conv13_mbox_conf_perm
I0628 16:42:39.986210 17458 net.cpp:100] Creating Layer conv13_mbox_conf_perm
I0628 16:42:39.986217 17458 net.cpp:434] conv13_mbox_conf_perm <- conv13_mbox_conf
I0628 16:42:39.986222 17458 net.cpp:408] conv13_mbox_conf_perm -> conv13_mbox_conf_perm
I0628 16:42:39.986351 17458 net.cpp:150] Setting up conv13_mbox_conf_perm
I0628 16:42:39.986356 17458 net.cpp:157] Top shape: 4 10 10 12 (4800)
I0628 16:42:39.986361 17458 net.cpp:165] Memory required for data: 644833888
I0628 16:42:39.986377 17458 layer_factory.hpp:77] Creating layer conv13_mbox_conf_flat
I0628 16:42:39.986402 17458 net.cpp:100] Creating Layer conv13_mbox_conf_flat
I0628 16:42:39.986407 17458 net.cpp:434] conv13_mbox_conf_flat <- conv13_mbox_conf_perm
I0628 16:42:39.986411 17458 net.cpp:408] conv13_mbox_conf_flat -> conv13_mbox_conf_flat
I0628 16:42:39.986450 17458 net.cpp:150] Setting up conv13_mbox_conf_flat
I0628 16:42:39.986455 17458 net.cpp:157] Top shape: 4 1200 (4800)
I0628 16:42:39.986459 17458 net.cpp:165] Memory required for data: 644853088
I0628 16:42:39.986462 17458 layer_factory.hpp:77] Creating layer conv13_mbox_priorbox
I0628 16:42:39.986470 17458 net.cpp:100] Creating Layer conv13_mbox_priorbox
I0628 16:42:39.986474 17458 net.cpp:434] conv13_mbox_priorbox <- conv13_conv13/relu_0_split_3
I0628 16:42:39.986479 17458 net.cpp:434] conv13_mbox_priorbox <- data_data_0_split_2
I0628 16:42:39.986485 17458 net.cpp:408] conv13_mbox_priorbox -> conv13_mbox_priorbox
I0628 16:42:39.986526 17458 net.cpp:150] Setting up conv13_mbox_priorbox
I0628 16:42:39.986560 17458 net.cpp:157] Top shape: 1 2 2400 (4800)
I0628 16:42:39.986563 17458 net.cpp:165] Memory required for data: 644872288
I0628 16:42:39.986567 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc
I0628 16:42:39.986577 17458 net.cpp:100] Creating Layer conv14_2_mbox_loc
I0628 16:42:39.986582 17458 net.cpp:434] conv14_2_mbox_loc <- conv14_2_conv14_2/relu_0_split_1
I0628 16:42:39.986601 17458 net.cpp:408] conv14_2_mbox_loc -> conv14_2_mbox_loc
I0628 16:42:39.989287 17458 net.cpp:150] Setting up conv14_2_mbox_loc
I0628 16:42:39.989300 17458 net.cpp:157] Top shape: 4 24 5 5 (2400)
I0628 16:42:39.989303 17458 net.cpp:165] Memory required for data: 644881888
I0628 16:42:39.989315 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_perm
I0628 16:42:39.989323 17458 net.cpp:100] Creating Layer conv14_2_mbox_loc_perm
I0628 16:42:39.989329 17458 net.cpp:434] conv14_2_mbox_loc_perm <- conv14_2_mbox_loc
I0628 16:42:39.989336 17458 net.cpp:408] conv14_2_mbox_loc_perm -> conv14_2_mbox_loc_perm
I0628 16:42:39.989464 17458 net.cpp:150] Setting up conv14_2_mbox_loc_perm
I0628 16:42:39.989470 17458 net.cpp:157] Top shape: 4 5 5 24 (2400)
I0628 16:42:39.989473 17458 net.cpp:165] Memory required for data: 644891488
I0628 16:42:39.989476 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_loc_flat
I0628 16:42:39.989483 17458 net.cpp:100] Creating Layer conv14_2_mbox_loc_flat
I0628 16:42:39.989506 17458 net.cpp:434] conv14_2_mbox_loc_flat <- conv14_2_mbox_loc_perm
I0628 16:42:39.989511 17458 net.cpp:408] conv14_2_mbox_loc_flat -> conv14_2_mbox_loc_flat
I0628 16:42:39.989536 17458 net.cpp:150] Setting up conv14_2_mbox_loc_flat
I0628 16:42:39.989540 17458 net.cpp:157] Top shape: 4 600 (2400)
I0628 16:42:39.989560 17458 net.cpp:165] Memory required for data: 644901088
I0628 16:42:39.989563 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_new
I0628 16:42:39.989594 17458 net.cpp:100] Creating Layer conv14_2_mbox_conf_new
I0628 16:42:39.989599 17458 net.cpp:434] conv14_2_mbox_conf_new <- conv14_2_conv14_2/relu_0_split_2
I0628 16:42:39.989606 17458 net.cpp:408] conv14_2_mbox_conf_new -> conv14_2_mbox_conf
I0628 16:42:39.992291 17458 net.cpp:150] Setting up conv14_2_mbox_conf_new
I0628 16:42:39.992302 17458 net.cpp:157] Top shape: 4 12 5 5 (1200)
I0628 16:42:39.992306 17458 net.cpp:165] Memory required for data: 644905888
I0628 16:42:39.992312 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_perm
I0628 16:42:39.992338 17458 net.cpp:100] Creating Layer conv14_2_mbox_conf_perm
I0628 16:42:39.992344 17458 net.cpp:434] conv14_2_mbox_conf_perm <- conv14_2_mbox_conf
I0628 16:42:39.992350 17458 net.cpp:408] conv14_2_mbox_conf_perm -> conv14_2_mbox_conf_perm
I0628 16:42:39.992491 17458 net.cpp:150] Setting up conv14_2_mbox_conf_perm
I0628 16:42:39.992498 17458 net.cpp:157] Top shape: 4 5 5 12 (1200)
I0628 16:42:39.992501 17458 net.cpp:165] Memory required for data: 644910688
I0628 16:42:39.992506 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_conf_flat
I0628 16:42:39.992511 17458 net.cpp:100] Creating Layer conv14_2_mbox_conf_flat
I0628 16:42:39.992513 17458 net.cpp:434] conv14_2_mbox_conf_flat <- conv14_2_mbox_conf_perm
I0628 16:42:39.992538 17458 net.cpp:408] conv14_2_mbox_conf_flat -> conv14_2_mbox_conf_flat
I0628 16:42:39.992563 17458 net.cpp:150] Setting up conv14_2_mbox_conf_flat
I0628 16:42:39.992569 17458 net.cpp:157] Top shape: 4 300 (1200)
I0628 16:42:39.992573 17458 net.cpp:165] Memory required for data: 644915488
I0628 16:42:39.992592 17458 layer_factory.hpp:77] Creating layer conv14_2_mbox_priorbox
I0628 16:42:39.992599 17458 net.cpp:100] Creating Layer conv14_2_mbox_priorbox
I0628 16:42:39.992622 17458 net.cpp:434] conv14_2_mbox_priorbox <- conv14_2_conv14_2/relu_0_split_3
I0628 16:42:39.992627 17458 net.cpp:434] conv14_2_mbox_priorbox <- data_data_0_split_3
I0628 16:42:39.992635 17458 net.cpp:408] conv14_2_mbox_priorbox -> conv14_2_mbox_priorbox
I0628 16:42:39.992677 17458 net.cpp:150] Setting up conv14_2_mbox_priorbox
I0628 16:42:39.992683 17458 net.cpp:157] Top shape: 1 2 600 (1200)
I0628 16:42:39.992699 17458 net.cpp:165] Memory required for data: 644920288
I0628 16:42:39.992703 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc
I0628 16:42:39.992712 17458 net.cpp:100] Creating Layer conv15_2_mbox_loc
I0628 16:42:39.992717 17458 net.cpp:434] conv15_2_mbox_loc <- conv15_2_conv15_2/relu_0_split_1
I0628 16:42:39.992723 17458 net.cpp:408] conv15_2_mbox_loc -> conv15_2_mbox_loc
I0628 16:42:39.995437 17458 net.cpp:150] Setting up conv15_2_mbox_loc
I0628 16:42:39.995448 17458 net.cpp:157] Top shape: 4 24 3 3 (864)
I0628 16:42:39.995452 17458 net.cpp:165] Memory required for data: 644923744
I0628 16:42:39.995458 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_perm
I0628 16:42:39.995483 17458 net.cpp:100] Creating Layer conv15_2_mbox_loc_perm
I0628 16:42:39.995489 17458 net.cpp:434] conv15_2_mbox_loc_perm <- conv15_2_mbox_loc
I0628 16:42:39.995512 17458 net.cpp:408] conv15_2_mbox_loc_perm -> conv15_2_mbox_loc_perm
I0628 16:42:39.995645 17458 net.cpp:150] Setting up conv15_2_mbox_loc_perm
I0628 16:42:39.995651 17458 net.cpp:157] Top shape: 4 3 3 24 (864)
I0628 16:42:39.995654 17458 net.cpp:165] Memory required for data: 644927200
I0628 16:42:39.995657 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_loc_flat
I0628 16:42:39.995663 17458 net.cpp:100] Creating Layer conv15_2_mbox_loc_flat
I0628 16:42:39.995685 17458 net.cpp:434] conv15_2_mbox_loc_flat <- conv15_2_mbox_loc_perm
I0628 16:42:39.995692 17458 net.cpp:408] conv15_2_mbox_loc_flat -> conv15_2_mbox_loc_flat
I0628 16:42:39.995728 17458 net.cpp:150] Setting up conv15_2_mbox_loc_flat
I0628 16:42:39.995734 17458 net.cpp:157] Top shape: 4 216 (864)
I0628 16:42:39.995738 17458 net.cpp:165] Memory required for data: 644930656
I0628 16:42:39.995741 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_new
I0628 16:42:39.995752 17458 net.cpp:100] Creating Layer conv15_2_mbox_conf_new
I0628 16:42:39.995757 17458 net.cpp:434] conv15_2_mbox_conf_new <- conv15_2_conv15_2/relu_0_split_2
I0628 16:42:39.995762 17458 net.cpp:408] conv15_2_mbox_conf_new -> conv15_2_mbox_conf
I0628 16:42:39.998462 17458 net.cpp:150] Setting up conv15_2_mbox_conf_new
I0628 16:42:39.998478 17458 net.cpp:157] Top shape: 4 12 3 3 (432)
I0628 16:42:39.998483 17458 net.cpp:165] Memory required for data: 644932384
I0628 16:42:39.998497 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_perm
I0628 16:42:39.998504 17458 net.cpp:100] Creating Layer conv15_2_mbox_conf_perm
I0628 16:42:39.998508 17458 net.cpp:434] conv15_2_mbox_conf_perm <- conv15_2_mbox_conf
I0628 16:42:39.998514 17458 net.cpp:408] conv15_2_mbox_conf_perm -> conv15_2_mbox_conf_perm
I0628 16:42:39.998632 17458 net.cpp:150] Setting up conv15_2_mbox_conf_perm
I0628 16:42:39.998638 17458 net.cpp:157] Top shape: 4 3 3 12 (432)
I0628 16:42:39.998642 17458 net.cpp:165] Memory required for data: 644934112
I0628 16:42:39.998646 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_conf_flat
I0628 16:42:39.998652 17458 net.cpp:100] Creating Layer conv15_2_mbox_conf_flat
I0628 16:42:39.998656 17458 net.cpp:434] conv15_2_mbox_conf_flat <- conv15_2_mbox_conf_perm
I0628 16:42:39.998661 17458 net.cpp:408] conv15_2_mbox_conf_flat -> conv15_2_mbox_conf_flat
I0628 16:42:39.998685 17458 net.cpp:150] Setting up conv15_2_mbox_conf_flat
I0628 16:42:39.998692 17458 net.cpp:157] Top shape: 4 108 (432)
I0628 16:42:39.998695 17458 net.cpp:165] Memory required for data: 644935840
I0628 16:42:39.998698 17458 layer_factory.hpp:77] Creating layer conv15_2_mbox_priorbox
I0628 16:42:39.998706 17458 net.cpp:100] Creating Layer conv15_2_mbox_priorbox
I0628 16:42:39.998711 17458 net.cpp:434] conv15_2_mbox_priorbox <- conv15_2_conv15_2/relu_0_split_3
I0628 16:42:39.998716 17458 net.cpp:434] conv15_2_mbox_priorbox <- data_data_0_split_4
I0628 16:42:39.998723 17458 net.cpp:408] conv15_2_mbox_priorbox -> conv15_2_mbox_priorbox
I0628 16:42:39.998750 17458 net.cpp:150] Setting up conv15_2_mbox_priorbox
I0628 16:42:39.998755 17458 net.cpp:157] Top shape: 1 2 216 (432)
I0628 16:42:39.998759 17458 net.cpp:165] Memory required for data: 644937568
I0628 16:42:39.998775 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc
I0628 16:42:39.998788 17458 net.cpp:100] Creating Layer conv16_2_mbox_loc
I0628 16:42:39.998793 17458 net.cpp:434] conv16_2_mbox_loc <- conv16_2_conv16_2/relu_0_split_1
I0628 16:42:39.998800 17458 net.cpp:408] conv16_2_mbox_loc -> conv16_2_mbox_loc
I0628 16:42:40.001675 17458 net.cpp:150] Setting up conv16_2_mbox_loc
I0628 16:42:40.001689 17458 net.cpp:157] Top shape: 4 24 2 2 (384)
I0628 16:42:40.001693 17458 net.cpp:165] Memory required for data: 644939104
I0628 16:42:40.001698 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_perm
I0628 16:42:40.001725 17458 net.cpp:100] Creating Layer conv16_2_mbox_loc_perm
I0628 16:42:40.001731 17458 net.cpp:434] conv16_2_mbox_loc_perm <- conv16_2_mbox_loc
I0628 16:42:40.001737 17458 net.cpp:408] conv16_2_mbox_loc_perm -> conv16_2_mbox_loc_perm
I0628 16:42:40.001865 17458 net.cpp:150] Setting up conv16_2_mbox_loc_perm
I0628 16:42:40.001871 17458 net.cpp:157] Top shape: 4 2 2 24 (384)
I0628 16:42:40.001875 17458 net.cpp:165] Memory required for data: 644940640
I0628 16:42:40.001878 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_loc_flat
I0628 16:42:40.001885 17458 net.cpp:100] Creating Layer conv16_2_mbox_loc_flat
I0628 16:42:40.001909 17458 net.cpp:434] conv16_2_mbox_loc_flat <- conv16_2_mbox_loc_perm
I0628 16:42:40.001914 17458 net.cpp:408] conv16_2_mbox_loc_flat -> conv16_2_mbox_loc_flat
I0628 16:42:40.001955 17458 net.cpp:150] Setting up conv16_2_mbox_loc_flat
I0628 16:42:40.001961 17458 net.cpp:157] Top shape: 4 96 (384)
I0628 16:42:40.001965 17458 net.cpp:165] Memory required for data: 644942176
I0628 16:42:40.001968 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_new
I0628 16:42:40.001977 17458 net.cpp:100] Creating Layer conv16_2_mbox_conf_new
I0628 16:42:40.001982 17458 net.cpp:434] conv16_2_mbox_conf_new <- conv16_2_conv16_2/relu_0_split_2
I0628 16:42:40.001989 17458 net.cpp:408] conv16_2_mbox_conf_new -> conv16_2_mbox_conf
I0628 16:42:40.004552 17458 net.cpp:150] Setting up conv16_2_mbox_conf_new
I0628 16:42:40.004564 17458 net.cpp:157] Top shape: 4 12 2 2 (192)
I0628 16:42:40.004567 17458 net.cpp:165] Memory required for data: 644942944
I0628 16:42:40.004573 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_perm
I0628 16:42:40.004601 17458 net.cpp:100] Creating Layer conv16_2_mbox_conf_perm
I0628 16:42:40.004606 17458 net.cpp:434] conv16_2_mbox_conf_perm <- conv16_2_mbox_conf
I0628 16:42:40.004612 17458 net.cpp:408] conv16_2_mbox_conf_perm -> conv16_2_mbox_conf_perm
I0628 16:42:40.004770 17458 net.cpp:150] Setting up conv16_2_mbox_conf_perm
I0628 16:42:40.004776 17458 net.cpp:157] Top shape: 4 2 2 12 (192)
I0628 16:42:40.004779 17458 net.cpp:165] Memory required for data: 644943712
I0628 16:42:40.004783 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_conf_flat
I0628 16:42:40.004789 17458 net.cpp:100] Creating Layer conv16_2_mbox_conf_flat
I0628 16:42:40.004813 17458 net.cpp:434] conv16_2_mbox_conf_flat <- conv16_2_mbox_conf_perm
I0628 16:42:40.004818 17458 net.cpp:408] conv16_2_mbox_conf_flat -> conv16_2_mbox_conf_flat
I0628 16:42:40.004843 17458 net.cpp:150] Setting up conv16_2_mbox_conf_flat
I0628 16:42:40.004863 17458 net.cpp:157] Top shape: 4 48 (192)
I0628 16:42:40.004866 17458 net.cpp:165] Memory required for data: 644944480
I0628 16:42:40.004869 17458 layer_factory.hpp:77] Creating layer conv16_2_mbox_priorbox
I0628 16:42:40.004878 17458 net.cpp:100] Creating Layer conv16_2_mbox_priorbox
I0628 16:42:40.004882 17458 net.cpp:434] conv16_2_mbox_priorbox <- conv16_2_conv16_2/relu_0_split_3
I0628 16:42:40.004886 17458 net.cpp:434] conv16_2_mbox_priorbox <- data_data_0_split_5
I0628 16:42:40.004892 17458 net.cpp:408] conv16_2_mbox_priorbox -> conv16_2_mbox_priorbox
I0628 16:42:40.004920 17458 net.cpp:150] Setting up conv16_2_mbox_priorbox
I0628 16:42:40.004925 17458 net.cpp:157] Top shape: 1 2 96 (192)
I0628 16:42:40.004928 17458 net.cpp:165] Memory required for data: 644945248
I0628 16:42:40.004947 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc
I0628 16:42:40.004956 17458 net.cpp:100] Creating Layer conv17_2_mbox_loc
I0628 16:42:40.004961 17458 net.cpp:434] conv17_2_mbox_loc <- conv17_2_conv17_2/relu_0_split_0
I0628 16:42:40.004967 17458 net.cpp:408] conv17_2_mbox_loc -> conv17_2_mbox_loc
I0628 16:42:40.007690 17458 net.cpp:150] Setting up conv17_2_mbox_loc
I0628 16:42:40.007702 17458 net.cpp:157] Top shape: 4 24 1 1 (96)
I0628 16:42:40.007706 17458 net.cpp:165] Memory required for data: 644945632
I0628 16:42:40.007711 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_perm
I0628 16:42:40.007740 17458 net.cpp:100] Creating Layer conv17_2_mbox_loc_perm
I0628 16:42:40.007745 17458 net.cpp:434] conv17_2_mbox_loc_perm <- conv17_2_mbox_loc
I0628 16:42:40.007750 17458 net.cpp:408] conv17_2_mbox_loc_perm -> conv17_2_mbox_loc_perm
I0628 16:42:40.007894 17458 net.cpp:150] Setting up conv17_2_mbox_loc_perm
I0628 16:42:40.007900 17458 net.cpp:157] Top shape: 4 1 1 24 (96)
I0628 16:42:40.007903 17458 net.cpp:165] Memory required for data: 644946016
I0628 16:42:40.007906 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_loc_flat
I0628 16:42:40.007913 17458 net.cpp:100] Creating Layer conv17_2_mbox_loc_flat
I0628 16:42:40.007936 17458 net.cpp:434] conv17_2_mbox_loc_flat <- conv17_2_mbox_loc_perm
I0628 16:42:40.007941 17458 net.cpp:408] conv17_2_mbox_loc_flat -> conv17_2_mbox_loc_flat
I0628 16:42:40.007967 17458 net.cpp:150] Setting up conv17_2_mbox_loc_flat
I0628 16:42:40.007974 17458 net.cpp:157] Top shape: 4 24 (96)
I0628 16:42:40.007993 17458 net.cpp:165] Memory required for data: 644946400
I0628 16:42:40.007997 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_new
I0628 16:42:40.008024 17458 net.cpp:100] Creating Layer conv17_2_mbox_conf_new
I0628 16:42:40.008029 17458 net.cpp:434] conv17_2_mbox_conf_new <- conv17_2_conv17_2/relu_0_split_1
I0628 16:42:40.008038 17458 net.cpp:408] conv17_2_mbox_conf_new -> conv17_2_mbox_conf
I0628 16:42:40.010788 17458 net.cpp:150] Setting up conv17_2_mbox_conf_new
I0628 16:42:40.010800 17458 net.cpp:157] Top shape: 4 12 1 1 (48)
I0628 16:42:40.010804 17458 net.cpp:165] Memory required for data: 644946592
I0628 16:42:40.010810 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_perm
I0628 16:42:40.010818 17458 net.cpp:100] Creating Layer conv17_2_mbox_conf_perm
I0628 16:42:40.010823 17458 net.cpp:434] conv17_2_mbox_conf_perm <- conv17_2_mbox_conf
I0628 16:42:40.010830 17458 net.cpp:408] conv17_2_mbox_conf_perm -> conv17_2_mbox_conf_perm
I0628 16:42:40.010951 17458 net.cpp:150] Setting up conv17_2_mbox_conf_perm
I0628 16:42:40.010957 17458 net.cpp:157] Top shape: 4 1 1 12 (48)
I0628 16:42:40.010960 17458 net.cpp:165] Memory required for data: 644946784
I0628 16:42:40.010964 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_conf_flat
I0628 16:42:40.010969 17458 net.cpp:100] Creating Layer conv17_2_mbox_conf_flat
I0628 16:42:40.010973 17458 net.cpp:434] conv17_2_mbox_conf_flat <- conv17_2_mbox_conf_perm
I0628 16:42:40.010980 17458 net.cpp:408] conv17_2_mbox_conf_flat -> conv17_2_mbox_conf_flat
I0628 16:42:40.011006 17458 net.cpp:150] Setting up conv17_2_mbox_conf_flat
I0628 16:42:40.011013 17458 net.cpp:157] Top shape: 4 12 (48)
I0628 16:42:40.011016 17458 net.cpp:165] Memory required for data: 644946976
I0628 16:42:40.011019 17458 layer_factory.hpp:77] Creating layer conv17_2_mbox_priorbox
I0628 16:42:40.011025 17458 net.cpp:100] Creating Layer conv17_2_mbox_priorbox
I0628 16:42:40.011029 17458 net.cpp:434] conv17_2_mbox_priorbox <- conv17_2_conv17_2/relu_0_split_2
I0628 16:42:40.011034 17458 net.cpp:434] conv17_2_mbox_priorbox <- data_data_0_split_6
I0628 16:42:40.011041 17458 net.cpp:408] conv17_2_mbox_priorbox -> conv17_2_mbox_priorbox
I0628 16:42:40.011070 17458 net.cpp:150] Setting up conv17_2_mbox_priorbox
I0628 16:42:40.011076 17458 net.cpp:157] Top shape: 1 2 24 (48)
I0628 16:42:40.011080 17458 net.cpp:165] Memory required for data: 644947168
I0628 16:42:40.011082 17458 layer_factory.hpp:77] Creating layer mbox_loc
I0628 16:42:40.011101 17458 net.cpp:100] Creating Layer mbox_loc
I0628 16:42:40.011106 17458 net.cpp:434] mbox_loc <- conv11_mbox_loc_flat
I0628 16:42:40.011111 17458 net.cpp:434] mbox_loc <- conv13_mbox_loc_flat
I0628 16:42:40.011116 17458 net.cpp:434] mbox_loc <- conv14_2_mbox_loc_flat
I0628 16:42:40.011122 17458 net.cpp:434] mbox_loc <- conv15_2_mbox_loc_flat
I0628 16:42:40.011127 17458 net.cpp:434] mbox_loc <- conv16_2_mbox_loc_flat
I0628 16:42:40.011130 17458 net.cpp:434] mbox_loc <- conv17_2_mbox_loc_flat
I0628 16:42:40.011135 17458 net.cpp:408] mbox_loc -> mbox_loc
I0628 16:42:40.011163 17458 net.cpp:150] Setting up mbox_loc
I0628 16:42:40.011169 17458 net.cpp:157] Top shape: 4 7668 (30672)
I0628 16:42:40.011173 17458 net.cpp:165] Memory required for data: 645069856
I0628 16:42:40.011176 17458 layer_factory.hpp:77] Creating layer mbox_conf
I0628 16:42:40.011183 17458 net.cpp:100] Creating Layer mbox_conf
I0628 16:42:40.011186 17458 net.cpp:434] mbox_conf <- conv11_mbox_conf_flat
I0628 16:42:40.011190 17458 net.cpp:434] mbox_conf <- conv13_mbox_conf_flat
I0628 16:42:40.011194 17458 net.cpp:434] mbox_conf <- conv14_2_mbox_conf_flat
I0628 16:42:40.011198 17458 net.cpp:434] mbox_conf <- conv15_2_mbox_conf_flat
I0628 16:42:40.011202 17458 net.cpp:434] mbox_conf <- conv16_2_mbox_conf_flat
I0628 16:42:40.011206 17458 net.cpp:434] mbox_conf <- conv17_2_mbox_conf_flat
I0628 16:42:40.011210 17458 net.cpp:408] mbox_conf -> mbox_conf
I0628 16:42:40.011234 17458 net.cpp:150] Setting up mbox_conf
I0628 16:42:40.011240 17458 net.cpp:157] Top shape: 4 3834 (15336)
I0628 16:42:40.011243 17458 net.cpp:165] Memory required for data: 645131200
I0628 16:42:40.011246 17458 layer_factory.hpp:77] Creating layer mbox_priorbox
I0628 16:42:40.011253 17458 net.cpp:100] Creating Layer mbox_priorbox
I0628 16:42:40.011257 17458 net.cpp:434] mbox_priorbox <- conv11_mbox_priorbox
I0628 16:42:40.011261 17458 net.cpp:434] mbox_priorbox <- conv13_mbox_priorbox
I0628 16:42:40.011265 17458 net.cpp:434] mbox_priorbox <- conv14_2_mbox_priorbox
I0628 16:42:40.011270 17458 net.cpp:434] mbox_priorbox <- conv15_2_mbox_priorbox
I0628 16:42:40.011273 17458 net.cpp:434] mbox_priorbox <- conv16_2_mbox_priorbox
I0628 16:42:40.011277 17458 net.cpp:434] mbox_priorbox <- conv17_2_mbox_priorbox
I0628 16:42:40.011282 17458 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0628 16:42:40.011307 17458 net.cpp:150] Setting up mbox_priorbox
I0628 16:42:40.011313 17458 net.cpp:157] Top shape: 1 2 7668 (15336)
I0628 16:42:40.011317 17458 net.cpp:165] Memory required for data: 645192544
I0628 16:42:40.011320 17458 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0628 16:42:40.011328 17458 net.cpp:100] Creating Layer mbox_conf_reshape
I0628 16:42:40.011333 17458 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0628 16:42:40.011338 17458 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0628 16:42:40.011371 17458 net.cpp:150] Setting up mbox_conf_reshape
I0628 16:42:40.011377 17458 net.cpp:157] Top shape: 4 1917 2 (15336)
I0628 16:42:40.011381 17458 net.cpp:165] Memory required for data: 645253888
I0628 16:42:40.011384 17458 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0628 16:42:40.011389 17458 net.cpp:100] Creating Layer mbox_conf_softmax
I0628 16:42:40.011394 17458 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0628 16:42:40.011400 17458 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0628 16:42:40.012125 17458 net.cpp:150] Setting up mbox_conf_softmax
I0628 16:42:40.012135 17458 net.cpp:157] Top shape: 4 1917 2 (15336)
I0628 16:42:40.012140 17458 net.cpp:165] Memory required for data: 645315232
I0628 16:42:40.012143 17458 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0628 16:42:40.012149 17458 net.cpp:100] Creating Layer mbox_conf_flatten
I0628 16:42:40.012153 17458 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0628 16:42:40.012158 17458 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0628 16:42:40.012185 17458 net.cpp:150] Setting up mbox_conf_flatten
I0628 16:42:40.012192 17458 net.cpp:157] Top shape: 4 3834 (15336)
I0628 16:42:40.012203 17458 net.cpp:165] Memory required for data: 645376576
I0628 16:42:40.012207 17458 layer_factory.hpp:77] Creating layer detection_out
I0628 16:42:40.012219 17458 net.cpp:100] Creating Layer detection_out
I0628 16:42:40.012224 17458 net.cpp:434] detection_out <- mbox_loc
I0628 16:42:40.012229 17458 net.cpp:434] detection_out <- mbox_conf_flatten
I0628 16:42:40.012233 17458 net.cpp:434] detection_out <- mbox_priorbox
I0628 16:42:40.012239 17458 net.cpp:408] detection_out -> detection_out
I0628 16:42:40.012305 17458 net.cpp:150] Setting up detection_out
I0628 16:42:40.012315 17458 net.cpp:157] Top shape: 1 1 1 7 (7)
I0628 16:42:40.012317 17458 net.cpp:165] Memory required for data: 645376604
I0628 16:42:40.012320 17458 layer_factory.hpp:77] Creating layer detection_eval
I0628 16:42:40.012326 17458 net.cpp:100] Creating Layer detection_eval
I0628 16:42:40.012331 17458 net.cpp:434] detection_eval <- detection_out
I0628 16:42:40.012334 17458 net.cpp:434] detection_eval <- label
I0628 16:42:40.012339 17458 net.cpp:408] detection_eval -> detection_eval
I0628 16:42:40.012389 17458 net.cpp:150] Setting up detection_eval
I0628 16:42:40.012395 17458 net.cpp:157] Top shape: 1 1 2 5 (10)
I0628 16:42:40.012398 17458 net.cpp:165] Memory required for data: 645376644
I0628 16:42:40.012403 17458 net.cpp:228] detection_eval does not need backward computation.
I0628 16:42:40.012406 17458 net.cpp:228] detection_out does not need backward computation.
I0628 16:42:40.012410 17458 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0628 16:42:40.012414 17458 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0628 16:42:40.012418 17458 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0628 16:42:40.012421 17458 net.cpp:228] mbox_priorbox does not need backward computation.
I0628 16:42:40.012428 17458 net.cpp:228] mbox_conf does not need backward computation.
I0628 16:42:40.012434 17458 net.cpp:228] mbox_loc does not need backward computation.
I0628 16:42:40.012439 17458 net.cpp:228] conv17_2_mbox_priorbox does not need backward computation.
I0628 16:42:40.012444 17458 net.cpp:228] conv17_2_mbox_conf_flat does not need backward computation.
I0628 16:42:40.012447 17458 net.cpp:228] conv17_2_mbox_conf_perm does not need backward computation.
I0628 16:42:40.012451 17458 net.cpp:228] conv17_2_mbox_conf_new does not need backward computation.
I0628 16:42:40.012455 17458 net.cpp:228] conv17_2_mbox_loc_flat does not need backward computation.
I0628 16:42:40.012459 17458 net.cpp:228] conv17_2_mbox_loc_perm does not need backward computation.
I0628 16:42:40.012462 17458 net.cpp:228] conv17_2_mbox_loc does not need backward computation.
I0628 16:42:40.012466 17458 net.cpp:228] conv16_2_mbox_priorbox does not need backward computation.
I0628 16:42:40.012470 17458 net.cpp:228] conv16_2_mbox_conf_flat does not need backward computation.
I0628 16:42:40.012475 17458 net.cpp:228] conv16_2_mbox_conf_perm does not need backward computation.
I0628 16:42:40.012477 17458 net.cpp:228] conv16_2_mbox_conf_new does not need backward computation.
I0628 16:42:40.012481 17458 net.cpp:228] conv16_2_mbox_loc_flat does not need backward computation.
I0628 16:42:40.012485 17458 net.cpp:228] conv16_2_mbox_loc_perm does not need backward computation.
I0628 16:42:40.012490 17458 net.cpp:228] conv16_2_mbox_loc does not need backward computation.
I0628 16:42:40.012493 17458 net.cpp:228] conv15_2_mbox_priorbox does not need backward computation.
I0628 16:42:40.012497 17458 net.cpp:228] conv15_2_mbox_conf_flat does not need backward computation.
I0628 16:42:40.012501 17458 net.cpp:228] conv15_2_mbox_conf_perm does not need backward computation.
I0628 16:42:40.012504 17458 net.cpp:228] conv15_2_mbox_conf_new does not need backward computation.
I0628 16:42:40.012508 17458 net.cpp:228] conv15_2_mbox_loc_flat does not need backward computation.
I0628 16:42:40.012513 17458 net.cpp:228] conv15_2_mbox_loc_perm does not need backward computation.
I0628 16:42:40.012517 17458 net.cpp:228] conv15_2_mbox_loc does not need backward computation.
I0628 16:42:40.012528 17458 net.cpp:228] conv14_2_mbox_priorbox does not need backward computation.
I0628 16:42:40.012533 17458 net.cpp:228] conv14_2_mbox_conf_flat does not need backward computation.
I0628 16:42:40.012537 17458 net.cpp:228] conv14_2_mbox_conf_perm does not need backward computation.
I0628 16:42:40.012540 17458 net.cpp:228] conv14_2_mbox_conf_new does not need backward computation.
I0628 16:42:40.012544 17458 net.cpp:228] conv14_2_mbox_loc_flat does not need backward computation.
I0628 16:42:40.012547 17458 net.cpp:228] conv14_2_mbox_loc_perm does not need backward computation.
I0628 16:42:40.012552 17458 net.cpp:228] conv14_2_mbox_loc does not need backward computation.
I0628 16:42:40.012555 17458 net.cpp:228] conv13_mbox_priorbox does not need backward computation.
I0628 16:42:40.012559 17458 net.cpp:228] conv13_mbox_conf_flat does not need backward computation.
I0628 16:42:40.012563 17458 net.cpp:228] conv13_mbox_conf_perm does not need backward computation.
I0628 16:42:40.012567 17458 net.cpp:228] conv13_mbox_conf_new does not need backward computation.
I0628 16:42:40.012570 17458 net.cpp:228] conv13_mbox_loc_flat does not need backward computation.
I0628 16:42:40.012575 17458 net.cpp:228] conv13_mbox_loc_perm does not need backward computation.
I0628 16:42:40.012579 17458 net.cpp:228] conv13_mbox_loc does not need backward computation.
I0628 16:42:40.012583 17458 net.cpp:228] conv11_mbox_priorbox does not need backward computation.
I0628 16:42:40.012588 17458 net.cpp:228] conv11_mbox_conf_flat does not need backward computation.
I0628 16:42:40.012591 17458 net.cpp:228] conv11_mbox_conf_perm does not need backward computation.
I0628 16:42:40.012595 17458 net.cpp:228] conv11_mbox_conf_new does not need backward computation.
I0628 16:42:40.012599 17458 net.cpp:228] conv11_mbox_loc_flat does not need backward computation.
I0628 16:42:40.012603 17458 net.cpp:228] conv11_mbox_loc_perm does not need backward computation.
I0628 16:42:40.012607 17458 net.cpp:228] conv11_mbox_loc does not need backward computation.
I0628 16:42:40.012611 17458 net.cpp:228] conv17_2_conv17_2/relu_0_split does not need backward computation.
I0628 16:42:40.012615 17458 net.cpp:228] conv17_2/relu does not need backward computation.
I0628 16:42:40.012619 17458 net.cpp:228] conv17_2/scale does not need backward computation.
I0628 16:42:40.012622 17458 net.cpp:228] conv17_2/bn does not need backward computation.
I0628 16:42:40.012626 17458 net.cpp:228] conv17_2 does not need backward computation.
I0628 16:42:40.012630 17458 net.cpp:228] conv17_1/relu does not need backward computation.
I0628 16:42:40.012634 17458 net.cpp:228] conv17_1/scale does not need backward computation.
I0628 16:42:40.012637 17458 net.cpp:228] conv17_1/bn does not need backward computation.
I0628 16:42:40.012640 17458 net.cpp:228] conv17_1 does not need backward computation.
I0628 16:42:40.012645 17458 net.cpp:228] conv16_2_conv16_2/relu_0_split does not need backward computation.
I0628 16:42:40.012648 17458 net.cpp:228] conv16_2/relu does not need backward computation.
I0628 16:42:40.012652 17458 net.cpp:228] conv16_2/scale does not need backward computation.
I0628 16:42:40.012655 17458 net.cpp:228] conv16_2/bn does not need backward computation.
I0628 16:42:40.012660 17458 net.cpp:228] conv16_2 does not need backward computation.
I0628 16:42:40.012662 17458 net.cpp:228] conv16_1/relu does not need backward computation.
I0628 16:42:40.012666 17458 net.cpp:228] conv16_1/scale does not need backward computation.
I0628 16:42:40.012670 17458 net.cpp:228] conv16_1/bn does not need backward computation.
I0628 16:42:40.012673 17458 net.cpp:228] conv16_1 does not need backward computation.
I0628 16:42:40.012677 17458 net.cpp:228] conv15_2_conv15_2/relu_0_split does not need backward computation.
I0628 16:42:40.012681 17458 net.cpp:228] conv15_2/relu does not need backward computation.
I0628 16:42:40.012686 17458 net.cpp:228] conv15_2/scale does not need backward computation.
I0628 16:42:40.012688 17458 net.cpp:228] conv15_2/bn does not need backward computation.
I0628 16:42:40.012697 17458 net.cpp:228] conv15_2 does not need backward computation.
I0628 16:42:40.012701 17458 net.cpp:228] conv15_1/relu does not need backward computation.
I0628 16:42:40.012704 17458 net.cpp:228] conv15_1/scale does not need backward computation.
I0628 16:42:40.012708 17458 net.cpp:228] conv15_1/bn does not need backward computation.
I0628 16:42:40.012712 17458 net.cpp:228] conv15_1 does not need backward computation.
I0628 16:42:40.012717 17458 net.cpp:228] conv14_2_conv14_2/relu_0_split does not need backward computation.
I0628 16:42:40.012719 17458 net.cpp:228] conv14_2/relu does not need backward computation.
I0628 16:42:40.012723 17458 net.cpp:228] conv14_2/scale does not need backward computation.
I0628 16:42:40.012727 17458 net.cpp:228] conv14_2/bn does not need backward computation.
I0628 16:42:40.012730 17458 net.cpp:228] conv14_2 does not need backward computation.
I0628 16:42:40.012734 17458 net.cpp:228] conv14_1/relu does not need backward computation.
I0628 16:42:40.012737 17458 net.cpp:228] conv14_1/scale does not need backward computation.
I0628 16:42:40.012740 17458 net.cpp:228] conv14_1/bn does not need backward computation.
I0628 16:42:40.012744 17458 net.cpp:228] conv14_1 does not need backward computation.
I0628 16:42:40.012749 17458 net.cpp:228] conv13_conv13/relu_0_split does not need backward computation.
I0628 16:42:40.012753 17458 net.cpp:228] conv13/relu does not need backward computation.
I0628 16:42:40.012758 17458 net.cpp:228] conv13/scale does not need backward computation.
I0628 16:42:40.012761 17458 net.cpp:228] conv13/bn does not need backward computation.
I0628 16:42:40.012764 17458 net.cpp:228] conv13 does not need backward computation.
I0628 16:42:40.012768 17458 net.cpp:228] conv13/dw/relu does not need backward computation.
I0628 16:42:40.012773 17458 net.cpp:228] conv13/dw/scale does not need backward computation.
I0628 16:42:40.012775 17458 net.cpp:228] conv13/dw/bn does not need backward computation.
I0628 16:42:40.012779 17458 net.cpp:228] conv13/dw does not need backward computation.
I0628 16:42:40.012784 17458 net.cpp:228] conv12/relu does not need backward computation.
I0628 16:42:40.012787 17458 net.cpp:228] conv12/scale does not need backward computation.
I0628 16:42:40.012791 17458 net.cpp:228] conv12/bn does not need backward computation.
I0628 16:42:40.012794 17458 net.cpp:228] conv12 does not need backward computation.
I0628 16:42:40.012799 17458 net.cpp:228] conv12/dw/relu does not need backward computation.
I0628 16:42:40.012801 17458 net.cpp:228] conv12/dw/scale does not need backward computation.
I0628 16:42:40.012805 17458 net.cpp:228] conv12/dw/bn does not need backward computation.
I0628 16:42:40.012809 17458 net.cpp:228] conv12/dw does not need backward computation.
I0628 16:42:40.012812 17458 net.cpp:228] conv11_conv11/relu_0_split does not need backward computation.
I0628 16:42:40.012816 17458 net.cpp:228] conv11/relu does not need backward computation.
I0628 16:42:40.012820 17458 net.cpp:228] conv11/scale does not need backward computation.
I0628 16:42:40.012825 17458 net.cpp:228] conv11/bn does not need backward computation.
I0628 16:42:40.012827 17458 net.cpp:228] conv11 does not need backward computation.
I0628 16:42:40.012831 17458 net.cpp:228] conv11/dw/relu does not need backward computation.
I0628 16:42:40.012835 17458 net.cpp:228] conv11/dw/scale does not need backward computation.
I0628 16:42:40.012838 17458 net.cpp:228] conv11/dw/bn does not need backward computation.
I0628 16:42:40.012841 17458 net.cpp:228] conv11/dw does not need backward computation.
I0628 16:42:40.012845 17458 net.cpp:228] conv10/relu does not need backward computation.
I0628 16:42:40.012850 17458 net.cpp:228] conv10/scale does not need backward computation.
I0628 16:42:40.012852 17458 net.cpp:228] conv10/bn does not need backward computation.
I0628 16:42:40.012856 17458 net.cpp:228] conv10 does not need backward computation.
I0628 16:42:40.012859 17458 net.cpp:228] conv10/dw/relu does not need backward computation.
I0628 16:42:40.012863 17458 net.cpp:228] conv10/dw/scale does not need backward computation.
I0628 16:42:40.012872 17458 net.cpp:228] conv10/dw/bn does not need backward computation.
I0628 16:42:40.012876 17458 net.cpp:228] conv10/dw does not need backward computation.
I0628 16:42:40.012881 17458 net.cpp:228] conv9/relu does not need backward computation.
I0628 16:42:40.012883 17458 net.cpp:228] conv9/scale does not need backward computation.
I0628 16:42:40.012887 17458 net.cpp:228] conv9/bn does not need backward computation.
I0628 16:42:40.012890 17458 net.cpp:228] conv9 does not need backward computation.
I0628 16:42:40.012894 17458 net.cpp:228] conv9/dw/relu does not need backward computation.
I0628 16:42:40.012897 17458 net.cpp:228] conv9/dw/scale does not need backward computation.
I0628 16:42:40.012902 17458 net.cpp:228] conv9/dw/bn does not need backward computation.
I0628 16:42:40.012905 17458 net.cpp:228] conv9/dw does not need backward computation.
I0628 16:42:40.012908 17458 net.cpp:228] conv8/relu does not need backward computation.
I0628 16:42:40.012912 17458 net.cpp:228] conv8/scale does not need backward computation.
I0628 16:42:40.012917 17458 net.cpp:228] conv8/bn does not need backward computation.
I0628 16:42:40.012919 17458 net.cpp:228] conv8 does not need backward computation.
I0628 16:42:40.012923 17458 net.cpp:228] conv8/dw/relu does not need backward computation.
I0628 16:42:40.012926 17458 net.cpp:228] conv8/dw/scale does not need backward computation.
I0628 16:42:40.012930 17458 net.cpp:228] conv8/dw/bn does not need backward computation.
I0628 16:42:40.012933 17458 net.cpp:228] conv8/dw does not need backward computation.
I0628 16:42:40.012938 17458 net.cpp:228] conv7/relu does not need backward computation.
I0628 16:42:40.012940 17458 net.cpp:228] conv7/scale does not need backward computation.
I0628 16:42:40.012944 17458 net.cpp:228] conv7/bn does not need backward computation.
I0628 16:42:40.012948 17458 net.cpp:228] conv7 does not need backward computation.
I0628 16:42:40.012951 17458 net.cpp:228] conv7/dw/relu does not need backward computation.
I0628 16:42:40.012955 17458 net.cpp:228] conv7/dw/scale does not need backward computation.
I0628 16:42:40.012959 17458 net.cpp:228] conv7/dw/bn does not need backward computation.
I0628 16:42:40.012962 17458 net.cpp:228] conv7/dw does not need backward computation.
I0628 16:42:40.012965 17458 net.cpp:228] conv6/relu does not need backward computation.
I0628 16:42:40.012969 17458 net.cpp:228] conv6/scale does not need backward computation.
I0628 16:42:40.012972 17458 net.cpp:228] conv6/bn does not need backward computation.
I0628 16:42:40.012976 17458 net.cpp:228] conv6 does not need backward computation.
I0628 16:42:40.012980 17458 net.cpp:228] conv6/dw/relu does not need backward computation.
I0628 16:42:40.012984 17458 net.cpp:228] conv6/dw/scale does not need backward computation.
I0628 16:42:40.012987 17458 net.cpp:228] conv6/dw/bn does not need backward computation.
I0628 16:42:40.012990 17458 net.cpp:228] conv6/dw does not need backward computation.
I0628 16:42:40.012995 17458 net.cpp:228] conv5/relu does not need backward computation.
I0628 16:42:40.012997 17458 net.cpp:228] conv5/scale does not need backward computation.
I0628 16:42:40.013001 17458 net.cpp:228] conv5/bn does not need backward computation.
I0628 16:42:40.013005 17458 net.cpp:228] conv5 does not need backward computation.
I0628 16:42:40.013008 17458 net.cpp:228] conv5/dw/relu does not need backward computation.
I0628 16:42:40.013012 17458 net.cpp:228] conv5/dw/scale does not need backward computation.
I0628 16:42:40.013015 17458 net.cpp:228] conv5/dw/bn does not need backward computation.
I0628 16:42:40.013020 17458 net.cpp:228] conv5/dw does not need backward computation.
I0628 16:42:40.013023 17458 net.cpp:228] conv4/relu does not need backward computation.
I0628 16:42:40.013026 17458 net.cpp:228] conv4/scale does not need backward computation.
I0628 16:42:40.013031 17458 net.cpp:228] conv4/bn does not need backward computation.
I0628 16:42:40.013033 17458 net.cpp:228] conv4 does not need backward computation.
I0628 16:42:40.013046 17458 net.cpp:228] conv4/dw/relu does not need backward computation.
I0628 16:42:40.013051 17458 net.cpp:228] conv4/dw/scale does not need backward computation.
I0628 16:42:40.013054 17458 net.cpp:228] conv4/dw/bn does not need backward computation.
I0628 16:42:40.013057 17458 net.cpp:228] conv4/dw does not need backward computation.
I0628 16:42:40.013062 17458 net.cpp:228] conv3/relu does not need backward computation.
I0628 16:42:40.013065 17458 net.cpp:228] conv3/scale does not need backward computation.
I0628 16:42:40.013069 17458 net.cpp:228] conv3/bn does not need backward computation.
I0628 16:42:40.013072 17458 net.cpp:228] conv3 does not need backward computation.
I0628 16:42:40.013077 17458 net.cpp:228] conv3/dw/relu does not need backward computation.
I0628 16:42:40.013080 17458 net.cpp:228] conv3/dw/scale does not need backward computation.
I0628 16:42:40.013083 17458 net.cpp:228] conv3/dw/bn does not need backward computation.
I0628 16:42:40.013087 17458 net.cpp:228] conv3/dw does not need backward computation.
I0628 16:42:40.013090 17458 net.cpp:228] conv2/relu does not need backward computation.
I0628 16:42:40.013094 17458 net.cpp:228] conv2/scale does not need backward computation.
I0628 16:42:40.013098 17458 net.cpp:228] conv2/bn does not need backward computation.
I0628 16:42:40.013101 17458 net.cpp:228] conv2 does not need backward computation.
I0628 16:42:40.013105 17458 net.cpp:228] conv2/dw/relu does not need backward computation.
I0628 16:42:40.013108 17458 net.cpp:228] conv2/dw/scale does not need backward computation.
I0628 16:42:40.013113 17458 net.cpp:228] conv2/dw/bn does not need backward computation.
I0628 16:42:40.013115 17458 net.cpp:228] conv2/dw does not need backward computation.
I0628 16:42:40.013120 17458 net.cpp:228] conv1/relu does not need backward computation.
I0628 16:42:40.013124 17458 net.cpp:228] conv1/scale does not need backward computation.
I0628 16:42:40.013128 17458 net.cpp:228] conv1/bn does not need backward computation.
I0628 16:42:40.013131 17458 net.cpp:228] conv1 does not need backward computation.
I0628 16:42:40.013135 17458 net.cpp:228] conv1/dw/relu does not need backward computation.
I0628 16:42:40.013139 17458 net.cpp:228] conv1/dw/scale does not need backward computation.
I0628 16:42:40.013142 17458 net.cpp:228] conv1/dw/bn does not need backward computation.
I0628 16:42:40.013146 17458 net.cpp:228] conv1/dw does not need backward computation.
I0628 16:42:40.013150 17458 net.cpp:228] conv0/relu does not need backward computation.
I0628 16:42:40.013154 17458 net.cpp:228] conv0/scale does not need backward computation.
I0628 16:42:40.013157 17458 net.cpp:228] conv0/bn does not need backward computation.
I0628 16:42:40.013160 17458 net.cpp:228] conv0 does not need backward computation.
I0628 16:42:40.013165 17458 net.cpp:228] data_data_0_split does not need backward computation.
I0628 16:42:40.013170 17458 net.cpp:228] data does not need backward computation.
I0628 16:42:40.013172 17458 net.cpp:270] This network produces output detection_eval
I0628 16:42:40.013245 17458 net.cpp:283] Network initialization done.
I0628 16:42:40.013630 17458 solver.cpp:75] Solver scaffolding done.
I0628 16:42:40.023344 17458 caffe.cpp:155] Finetuning from mobilenet_iter_73000.caffemodel
I0628 16:42:40.041075 17458 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet_iter_73000.caffemodel
I0628 16:42:40.041131 17458 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 16:42:40.044584 17458 net.cpp:761] Ignoring source layer conv11_mbox_conf
I0628 16:42:40.044626 17458 net.cpp:761] Ignoring source layer conv13_mbox_conf
I0628 16:42:40.044673 17458 net.cpp:761] Ignoring source layer conv14_2_mbox_conf
I0628 16:42:40.044683 17458 net.cpp:761] Ignoring source layer conv15_2_mbox_conf
I0628 16:42:40.044710 17458 net.cpp:761] Ignoring source layer conv16_2_mbox_conf
I0628 16:42:40.044718 17458 net.cpp:761] Ignoring source layer conv17_2_mbox_conf
I0628 16:42:40.056457 17458 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet_iter_73000.caffemodel
I0628 16:42:40.056550 17458 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0628 16:42:40.060048 17458 net.cpp:761] Ignoring source layer conv11_mbox_conf
I0628 16:42:40.060073 17458 net.cpp:761] Ignoring source layer conv13_mbox_conf
I0628 16:42:40.060086 17458 net.cpp:761] Ignoring source layer conv14_2_mbox_conf
I0628 16:42:40.060096 17458 net.cpp:761] Ignoring source layer conv15_2_mbox_conf
I0628 16:42:40.060106 17458 net.cpp:761] Ignoring source layer conv16_2_mbox_conf
I0628 16:42:40.060133 17458 net.cpp:761] Ignoring source layer conv17_2_mbox_conf
I0628 16:42:40.060140 17458 net.cpp:761] Ignoring source layer mbox_loss
I0628 16:42:40.060346 17458 caffe.cpp:251] Starting Optimization
I0628 16:42:40.060353 17458 solver.cpp:294] Solving MobileNet-SSD
I0628 16:42:40.060356 17458 solver.cpp:295] Learning Rate Policy: multistep
I0628 16:42:40.984248 17458 solver.cpp:243] Iteration 0, loss = 41.406
I0628 16:42:40.984273 17458 solver.cpp:259]     Train net output #0: mbox_loss = 41.406 (* 1 = 41.406 loss)
I0628 16:42:40.984314 17458 sgd_solver.cpp:138] Iteration 0, lr = 0.0005
I0628 16:42:49.986932 17458 solver.cpp:243] Iteration 10, loss = 16.1733
I0628 16:42:49.986956 17458 solver.cpp:259]     Train net output #0: mbox_loss = 17.6777 (* 1 = 17.6777 loss)
I0628 16:42:49.986981 17458 sgd_solver.cpp:138] Iteration 10, lr = 0.0005
I0628 16:42:59.116117 17458 solver.cpp:243] Iteration 20, loss = 10.5389
I0628 16:42:59.116143 17458 solver.cpp:259]     Train net output #0: mbox_loss = 8.32642 (* 1 = 8.32642 loss)
I0628 16:42:59.116168 17458 sgd_solver.cpp:138] Iteration 20, lr = 0.0005
I0628 16:43:08.223210 17458 solver.cpp:243] Iteration 30, loss = 9.00557
I0628 16:43:08.223253 17458 solver.cpp:259]     Train net output #0: mbox_loss = 9.89355 (* 1 = 9.89355 loss)
I0628 16:43:08.223279 17458 sgd_solver.cpp:138] Iteration 30, lr = 0.0005
I0628 16:43:17.359433 17458 solver.cpp:243] Iteration 40, loss = 9.50971
I0628 16:43:17.359534 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.03975 (* 1 = 7.03975 loss)
I0628 16:43:17.359560 17458 sgd_solver.cpp:138] Iteration 40, lr = 0.0005
I0628 16:43:26.472048 17458 solver.cpp:243] Iteration 50, loss = 7.95691
I0628 16:43:26.472090 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.34082 (* 1 = 5.34082 loss)
I0628 16:43:26.472115 17458 sgd_solver.cpp:138] Iteration 50, lr = 0.0005
I0628 16:43:35.614189 17458 solver.cpp:243] Iteration 60, loss = 9.45263
I0628 16:43:35.614214 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.47751 (* 1 = 5.47751 loss)
I0628 16:43:35.614240 17458 sgd_solver.cpp:138] Iteration 60, lr = 0.0005
I0628 16:43:44.733422 17458 solver.cpp:243] Iteration 70, loss = 9.23045
I0628 16:43:44.733444 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.47898 (* 1 = 7.47898 loss)
I0628 16:43:44.733469 17458 sgd_solver.cpp:138] Iteration 70, lr = 0.0005
I0628 16:43:53.876401 17458 solver.cpp:243] Iteration 80, loss = 7.4105
I0628 16:43:53.876541 17458 solver.cpp:259]     Train net output #0: mbox_loss = 11.2327 (* 1 = 11.2327 loss)
I0628 16:43:53.876550 17458 sgd_solver.cpp:138] Iteration 80, lr = 0.0005
I0628 16:44:02.999240 17458 solver.cpp:243] Iteration 90, loss = 7.403
I0628 16:44:02.999262 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.98666 (* 1 = 4.98666 loss)
I0628 16:44:02.999289 17458 sgd_solver.cpp:138] Iteration 90, lr = 0.0005
I0628 16:44:12.153184 17458 solver.cpp:243] Iteration 100, loss = 8.99032
I0628 16:44:12.153208 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.74639 (* 1 = 6.74639 loss)
I0628 16:44:12.153234 17458 sgd_solver.cpp:138] Iteration 100, lr = 0.0005
I0628 16:44:21.288693 17458 solver.cpp:243] Iteration 110, loss = 6.42696
I0628 16:44:21.288717 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.72458 (* 1 = 4.72458 loss)
I0628 16:44:21.288724 17458 sgd_solver.cpp:138] Iteration 110, lr = 0.0005
I0628 16:44:30.445778 17458 solver.cpp:243] Iteration 120, loss = 7.56844
I0628 16:44:30.445976 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.07124 (* 1 = 5.07124 loss)
I0628 16:44:30.445997 17458 sgd_solver.cpp:138] Iteration 120, lr = 0.0005
I0628 16:44:39.572949 17458 solver.cpp:243] Iteration 130, loss = 7.31929
I0628 16:44:39.572974 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.13749 (* 1 = 7.13749 loss)
I0628 16:44:39.573000 17458 sgd_solver.cpp:138] Iteration 130, lr = 0.0005
I0628 16:44:48.732182 17458 solver.cpp:243] Iteration 140, loss = 7.49222
I0628 16:44:48.732206 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.92535 (* 1 = 6.92535 loss)
I0628 16:44:48.732213 17458 sgd_solver.cpp:138] Iteration 140, lr = 0.0005
I0628 16:44:57.860517 17458 solver.cpp:243] Iteration 150, loss = 6.22666
I0628 16:44:57.860543 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.88585 (* 1 = 5.88585 loss)
I0628 16:44:57.860568 17458 sgd_solver.cpp:138] Iteration 150, lr = 0.0005
I0628 16:45:07.018312 17458 solver.cpp:243] Iteration 160, loss = 6.84599
I0628 16:45:07.018462 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.19675 (* 1 = 6.19675 loss)
I0628 16:45:07.018492 17458 sgd_solver.cpp:138] Iteration 160, lr = 0.0005
I0628 16:45:16.148866 17458 solver.cpp:243] Iteration 170, loss = 5.88521
I0628 16:45:16.148887 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.05242 (* 1 = 5.05242 loss)
I0628 16:45:16.148912 17458 sgd_solver.cpp:138] Iteration 170, lr = 0.0005
I0628 16:45:25.302314 17458 solver.cpp:243] Iteration 180, loss = 6.51088
I0628 16:45:25.302338 17458 solver.cpp:259]     Train net output #0: mbox_loss = 14.16 (* 1 = 14.16 loss)
I0628 16:45:25.302364 17458 sgd_solver.cpp:138] Iteration 180, lr = 0.0005
I0628 16:45:34.431430 17458 solver.cpp:243] Iteration 190, loss = 6.64805
I0628 16:45:34.431454 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.37974 (* 1 = 5.37974 loss)
I0628 16:45:34.431479 17458 sgd_solver.cpp:138] Iteration 190, lr = 0.0005
I0628 16:45:43.577558 17458 solver.cpp:243] Iteration 200, loss = 6.51442
I0628 16:45:43.577731 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.4747 (* 1 = 5.4747 loss)
I0628 16:45:43.577757 17458 sgd_solver.cpp:138] Iteration 200, lr = 0.0005
I0628 16:45:52.694177 17458 solver.cpp:243] Iteration 210, loss = 6.58803
I0628 16:45:52.694202 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.61107 (* 1 = 3.61107 loss)
I0628 16:45:52.694227 17458 sgd_solver.cpp:138] Iteration 210, lr = 0.0005
I0628 16:46:01.841184 17458 solver.cpp:243] Iteration 220, loss = 6.39141
I0628 16:46:01.841207 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.61353 (* 1 = 7.61353 loss)
I0628 16:46:01.841233 17458 sgd_solver.cpp:138] Iteration 220, lr = 0.0005
I0628 16:46:10.969914 17458 solver.cpp:243] Iteration 230, loss = 6.26832
I0628 16:46:10.969939 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.98478 (* 1 = 3.98478 loss)
I0628 16:46:10.969965 17458 sgd_solver.cpp:138] Iteration 230, lr = 0.0005
I0628 16:46:20.122565 17458 solver.cpp:243] Iteration 240, loss = 6.50152
I0628 16:46:20.122720 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.23496 (* 1 = 4.23496 loss)
I0628 16:46:20.122746 17458 sgd_solver.cpp:138] Iteration 240, lr = 0.0005
I0628 16:46:29.253657 17458 solver.cpp:243] Iteration 250, loss = 6.57851
I0628 16:46:29.253682 17458 solver.cpp:259]     Train net output #0: mbox_loss = 11.7834 (* 1 = 11.7834 loss)
I0628 16:46:29.253707 17458 sgd_solver.cpp:138] Iteration 250, lr = 0.0005
I0628 16:46:38.402027 17458 solver.cpp:243] Iteration 260, loss = 6.8111
I0628 16:46:38.402052 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.26494 (* 1 = 5.26494 loss)
I0628 16:46:38.402077 17458 sgd_solver.cpp:138] Iteration 260, lr = 0.0005
I0628 16:46:47.523816 17458 solver.cpp:243] Iteration 270, loss = 7.4314
I0628 16:46:47.523840 17458 solver.cpp:259]     Train net output #0: mbox_loss = 11.5957 (* 1 = 11.5957 loss)
I0628 16:46:47.523866 17458 sgd_solver.cpp:138] Iteration 270, lr = 0.0005
I0628 16:46:56.673274 17458 solver.cpp:243] Iteration 280, loss = 5.46059
I0628 16:46:56.673476 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.67643 (* 1 = 5.67643 loss)
I0628 16:46:56.673486 17458 sgd_solver.cpp:138] Iteration 280, lr = 0.0005
I0628 16:47:05.800995 17458 solver.cpp:243] Iteration 290, loss = 6.41604
I0628 16:47:05.801018 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.40219 (* 1 = 7.40219 loss)
I0628 16:47:05.801044 17458 sgd_solver.cpp:138] Iteration 290, lr = 0.0005
I0628 16:47:14.961562 17458 solver.cpp:243] Iteration 300, loss = 5.67126
I0628 16:47:14.961586 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.5135 (* 1 = 7.5135 loss)
I0628 16:47:14.961612 17458 sgd_solver.cpp:138] Iteration 300, lr = 0.0005
I0628 16:47:24.090930 17458 solver.cpp:243] Iteration 310, loss = 6.66302
I0628 16:47:24.090955 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.40942 (* 1 = 6.40942 loss)
I0628 16:47:24.090979 17458 sgd_solver.cpp:138] Iteration 310, lr = 0.0005
I0628 16:47:33.241158 17458 solver.cpp:243] Iteration 320, loss = 6.01767
I0628 16:47:33.241318 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.67459 (* 1 = 6.67459 loss)
I0628 16:47:33.241326 17458 sgd_solver.cpp:138] Iteration 320, lr = 0.0005
I0628 16:47:42.369869 17458 solver.cpp:243] Iteration 330, loss = 6.39355
I0628 16:47:42.369894 17458 solver.cpp:259]     Train net output #0: mbox_loss = 10.7729 (* 1 = 10.7729 loss)
I0628 16:47:42.369920 17458 sgd_solver.cpp:138] Iteration 330, lr = 0.0005
I0628 16:47:51.519286 17458 solver.cpp:243] Iteration 340, loss = 5.3683
I0628 16:47:51.519310 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.6149 (* 1 = 5.6149 loss)
I0628 16:47:51.519335 17458 sgd_solver.cpp:138] Iteration 340, lr = 0.0005
I0628 16:48:00.650507 17458 solver.cpp:243] Iteration 350, loss = 5.59316
I0628 16:48:00.650530 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.42782 (* 1 = 3.42782 loss)
I0628 16:48:00.650557 17458 sgd_solver.cpp:138] Iteration 350, lr = 0.0005
I0628 16:48:09.790549 17458 solver.cpp:243] Iteration 360, loss = 6.16408
I0628 16:48:09.790608 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.56653 (* 1 = 6.56653 loss)
I0628 16:48:09.790617 17458 sgd_solver.cpp:138] Iteration 360, lr = 0.0005
I0628 16:48:18.896205 17458 solver.cpp:243] Iteration 370, loss = 4.65762
I0628 16:48:18.896229 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.5818 (* 1 = 3.5818 loss)
I0628 16:48:18.896235 17458 sgd_solver.cpp:138] Iteration 370, lr = 0.0005
I0628 16:48:28.017644 17458 solver.cpp:243] Iteration 380, loss = 6.12447
I0628 16:48:28.017670 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.82269 (* 1 = 3.82269 loss)
I0628 16:48:28.017678 17458 sgd_solver.cpp:138] Iteration 380, lr = 0.0005
I0628 16:48:37.118865 17458 solver.cpp:243] Iteration 390, loss = 6.66048
I0628 16:48:37.118887 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.8873 (* 1 = 4.8873 loss)
I0628 16:48:37.118912 17458 sgd_solver.cpp:138] Iteration 390, lr = 0.0005
I0628 16:48:46.272401 17458 solver.cpp:243] Iteration 400, loss = 5.84995
I0628 16:48:46.272583 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.41894 (* 1 = 7.41894 loss)
I0628 16:48:46.272610 17458 sgd_solver.cpp:138] Iteration 400, lr = 0.0005
I0628 16:48:55.400005 17458 solver.cpp:243] Iteration 410, loss = 5.67335
I0628 16:48:55.400028 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.38642 (* 1 = 4.38642 loss)
I0628 16:48:55.400053 17458 sgd_solver.cpp:138] Iteration 410, lr = 0.0005
I0628 16:49:04.554126 17458 solver.cpp:243] Iteration 420, loss = 6.24863
I0628 16:49:04.554150 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.02266 (* 1 = 5.02266 loss)
I0628 16:49:04.554175 17458 sgd_solver.cpp:138] Iteration 420, lr = 0.0005
I0628 16:49:13.684937 17458 solver.cpp:243] Iteration 430, loss = 5.53841
I0628 16:49:13.684960 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.98066 (* 1 = 6.98066 loss)
I0628 16:49:13.684985 17458 sgd_solver.cpp:138] Iteration 430, lr = 0.0005
I0628 16:49:22.838651 17458 solver.cpp:243] Iteration 440, loss = 4.71214
I0628 16:49:22.838845 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.87357 (* 1 = 4.87357 loss)
I0628 16:49:22.838858 17458 sgd_solver.cpp:138] Iteration 440, lr = 0.0005
I0628 16:49:31.960847 17458 solver.cpp:243] Iteration 450, loss = 4.97035
I0628 16:49:31.960871 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.14166 (* 1 = 5.14166 loss)
I0628 16:49:31.960897 17458 sgd_solver.cpp:138] Iteration 450, lr = 0.0005
I0628 16:49:41.090309 17458 solver.cpp:243] Iteration 460, loss = 6.5112
I0628 16:49:41.090335 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.18683 (* 1 = 6.18683 loss)
I0628 16:49:41.090361 17458 sgd_solver.cpp:138] Iteration 460, lr = 0.0005
I0628 16:49:50.219583 17458 solver.cpp:243] Iteration 470, loss = 5.43312
I0628 16:49:50.219606 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.63467 (* 1 = 6.63467 loss)
I0628 16:49:50.219631 17458 sgd_solver.cpp:138] Iteration 470, lr = 0.0005
I0628 16:49:59.376842 17458 solver.cpp:243] Iteration 480, loss = 5.59898
I0628 16:49:59.377014 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.38781 (* 1 = 4.38781 loss)
I0628 16:49:59.377023 17458 sgd_solver.cpp:138] Iteration 480, lr = 0.0005
I0628 16:50:08.512022 17458 solver.cpp:243] Iteration 490, loss = 5.5212
I0628 16:50:08.512044 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.09807 (* 1 = 4.09807 loss)
I0628 16:50:08.512069 17458 sgd_solver.cpp:138] Iteration 490, lr = 0.0005
I0628 16:50:17.661955 17458 solver.cpp:243] Iteration 500, loss = 5.0473
I0628 16:50:17.661978 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.47497 (* 1 = 6.47497 loss)
I0628 16:50:17.662004 17458 sgd_solver.cpp:138] Iteration 500, lr = 0.0005
I0628 16:50:26.772153 17458 solver.cpp:243] Iteration 510, loss = 5.12045
I0628 16:50:26.772177 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.62707 (* 1 = 6.62707 loss)
I0628 16:50:26.772184 17458 sgd_solver.cpp:138] Iteration 510, lr = 0.0005
I0628 16:50:35.898798 17458 solver.cpp:243] Iteration 520, loss = 5.34105
I0628 16:50:35.898974 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.11332 (* 1 = 6.11332 loss)
I0628 16:50:35.898983 17458 sgd_solver.cpp:138] Iteration 520, lr = 0.0005
I0628 16:50:45.004467 17458 solver.cpp:243] Iteration 530, loss = 6.79704
I0628 16:50:45.004492 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.38446 (* 1 = 3.38446 loss)
I0628 16:50:45.004499 17458 sgd_solver.cpp:138] Iteration 530, lr = 0.0005
I0628 16:50:54.131500 17458 solver.cpp:243] Iteration 540, loss = 5.26291
I0628 16:50:54.131525 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.85968 (* 1 = 6.85968 loss)
I0628 16:50:54.131551 17458 sgd_solver.cpp:138] Iteration 540, lr = 0.0005
I0628 16:51:03.242255 17458 solver.cpp:243] Iteration 550, loss = 5.8285
I0628 16:51:03.242278 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.37593 (* 1 = 2.37593 loss)
I0628 16:51:03.242285 17458 sgd_solver.cpp:138] Iteration 550, lr = 0.0005
I0628 16:51:12.392303 17458 solver.cpp:243] Iteration 560, loss = 5.11302
I0628 16:51:12.392441 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.39685 (* 1 = 3.39685 loss)
I0628 16:51:12.392457 17458 sgd_solver.cpp:138] Iteration 560, lr = 0.0005
I0628 16:51:21.521067 17458 solver.cpp:243] Iteration 570, loss = 4.62196
I0628 16:51:21.521090 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.07441 (* 1 = 5.07441 loss)
I0628 16:51:21.521116 17458 sgd_solver.cpp:138] Iteration 570, lr = 0.0005
I0628 16:51:30.655464 17458 solver.cpp:243] Iteration 580, loss = 6.04502
I0628 16:51:30.655489 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.60797 (* 1 = 7.60797 loss)
I0628 16:51:30.655496 17458 sgd_solver.cpp:138] Iteration 580, lr = 0.0005
I0628 16:51:39.761198 17458 solver.cpp:243] Iteration 590, loss = 5.37337
I0628 16:51:39.761222 17458 solver.cpp:259]     Train net output #0: mbox_loss = 10.4337 (* 1 = 10.4337 loss)
I0628 16:51:39.761247 17458 sgd_solver.cpp:138] Iteration 590, lr = 0.0005
I0628 16:51:48.887035 17458 solver.cpp:243] Iteration 600, loss = 5.11884
I0628 16:51:48.887188 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.28655 (* 1 = 4.28655 loss)
I0628 16:51:48.887197 17458 sgd_solver.cpp:138] Iteration 600, lr = 0.0005
I0628 16:51:57.990234 17458 solver.cpp:243] Iteration 610, loss = 5.13744
I0628 16:51:57.990258 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.14388 (* 1 = 6.14388 loss)
I0628 16:51:57.990283 17458 sgd_solver.cpp:138] Iteration 610, lr = 0.0005
I0628 16:52:07.124843 17458 solver.cpp:243] Iteration 620, loss = 4.75376
I0628 16:52:07.124869 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.27879 (* 1 = 3.27879 loss)
I0628 16:52:07.124876 17458 sgd_solver.cpp:138] Iteration 620, lr = 0.0005
I0628 16:52:16.234516 17458 solver.cpp:243] Iteration 630, loss = 4.4797
I0628 16:52:16.234539 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.45481 (* 1 = 4.45481 loss)
I0628 16:52:16.234565 17458 sgd_solver.cpp:138] Iteration 630, lr = 0.0005
I0628 16:52:25.385031 17458 solver.cpp:243] Iteration 640, loss = 5.86578
I0628 16:52:25.385210 17458 solver.cpp:259]     Train net output #0: mbox_loss = 11.9489 (* 1 = 11.9489 loss)
I0628 16:52:25.385238 17458 sgd_solver.cpp:138] Iteration 640, lr = 0.0005
I0628 16:52:34.513453 17458 solver.cpp:243] Iteration 650, loss = 5.90016
I0628 16:52:34.513476 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.49432 (* 1 = 7.49432 loss)
I0628 16:52:34.513484 17458 sgd_solver.cpp:138] Iteration 650, lr = 0.0005
I0628 16:52:43.662925 17458 solver.cpp:243] Iteration 660, loss = 5.23974
I0628 16:52:43.662950 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.47999 (* 1 = 3.47999 loss)
I0628 16:52:43.662976 17458 sgd_solver.cpp:138] Iteration 660, lr = 0.0005
I0628 16:52:52.787122 17458 solver.cpp:243] Iteration 670, loss = 5.40543
I0628 16:52:52.787143 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.33967 (* 1 = 5.33967 loss)
I0628 16:52:52.787169 17458 sgd_solver.cpp:138] Iteration 670, lr = 0.0005
I0628 16:53:01.947365 17458 solver.cpp:243] Iteration 680, loss = 4.95043
I0628 16:53:01.947549 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.40558 (* 1 = 3.40558 loss)
I0628 16:53:01.947557 17458 sgd_solver.cpp:138] Iteration 680, lr = 0.0005
I0628 16:53:11.066306 17458 solver.cpp:243] Iteration 690, loss = 5.21251
I0628 16:53:11.066330 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.6704 (* 1 = 3.6704 loss)
I0628 16:53:11.066355 17458 sgd_solver.cpp:138] Iteration 690, lr = 0.0005
I0628 16:53:20.192420 17458 solver.cpp:243] Iteration 700, loss = 5.03823
I0628 16:53:20.192445 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.19139 (* 1 = 3.19139 loss)
I0628 16:53:20.192453 17458 sgd_solver.cpp:138] Iteration 700, lr = 0.0005
I0628 16:53:29.301801 17458 solver.cpp:243] Iteration 710, loss = 4.97674
I0628 16:53:29.301826 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.11558 (* 1 = 5.11558 loss)
I0628 16:53:29.301851 17458 sgd_solver.cpp:138] Iteration 710, lr = 0.0005
I0628 16:53:38.427021 17458 solver.cpp:243] Iteration 720, loss = 5.2738
I0628 16:53:38.427132 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.06891 (* 1 = 5.06891 loss)
I0628 16:53:38.427141 17458 sgd_solver.cpp:138] Iteration 720, lr = 0.0005
I0628 16:53:47.550149 17458 solver.cpp:243] Iteration 730, loss = 5.38736
I0628 16:53:47.550173 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.01236 (* 1 = 5.01236 loss)
I0628 16:53:47.550199 17458 sgd_solver.cpp:138] Iteration 730, lr = 0.0005
I0628 16:53:56.699224 17458 solver.cpp:243] Iteration 740, loss = 5.65276
I0628 16:53:56.699249 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.31387 (* 1 = 7.31387 loss)
I0628 16:53:56.699273 17458 sgd_solver.cpp:138] Iteration 740, lr = 0.0005
I0628 16:54:05.832029 17458 solver.cpp:243] Iteration 750, loss = 4.20982
I0628 16:54:05.832079 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.79417 (* 1 = 3.79417 loss)
I0628 16:54:05.832099 17458 sgd_solver.cpp:138] Iteration 750, lr = 0.0005
I0628 16:54:14.977501 17458 solver.cpp:243] Iteration 760, loss = 4.59357
I0628 16:54:14.977679 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.2737 (* 1 = 5.2737 loss)
I0628 16:54:14.977689 17458 sgd_solver.cpp:138] Iteration 760, lr = 0.0005
I0628 16:54:24.082353 17458 solver.cpp:243] Iteration 770, loss = 5.05418
I0628 16:54:24.082377 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.33722 (* 1 = 6.33722 loss)
I0628 16:54:24.082384 17458 sgd_solver.cpp:138] Iteration 770, lr = 0.0005
I0628 16:54:33.213454 17458 solver.cpp:243] Iteration 780, loss = 5.28251
I0628 16:54:33.213479 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.25438 (* 1 = 5.25438 loss)
I0628 16:54:33.213505 17458 sgd_solver.cpp:138] Iteration 780, lr = 0.0005
I0628 16:54:42.315847 17458 solver.cpp:243] Iteration 790, loss = 4.8613
I0628 16:54:42.315872 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.99926 (* 1 = 4.99926 loss)
I0628 16:54:42.315879 17458 sgd_solver.cpp:138] Iteration 790, lr = 0.0005
I0628 16:54:51.447170 17458 solver.cpp:243] Iteration 800, loss = 6.39529
I0628 16:54:51.447305 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.61885 (* 1 = 7.61885 loss)
I0628 16:54:51.447326 17458 sgd_solver.cpp:138] Iteration 800, lr = 0.0005
I0628 16:55:00.579941 17458 solver.cpp:243] Iteration 810, loss = 4.7553
I0628 16:55:00.579964 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.98513 (* 1 = 5.98513 loss)
I0628 16:55:00.579989 17458 sgd_solver.cpp:138] Iteration 810, lr = 0.0005
I0628 16:55:09.730859 17458 solver.cpp:243] Iteration 820, loss = 5.10498
I0628 16:55:09.730882 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.02513 (* 1 = 6.02513 loss)
I0628 16:55:09.730907 17458 sgd_solver.cpp:138] Iteration 820, lr = 0.0005
I0628 16:55:18.855360 17458 solver.cpp:243] Iteration 830, loss = 4.90425
I0628 16:55:18.855382 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.74178 (* 1 = 2.74178 loss)
I0628 16:55:18.855407 17458 sgd_solver.cpp:138] Iteration 830, lr = 0.0005
I0628 16:55:27.989562 17458 solver.cpp:243] Iteration 840, loss = 5.1
I0628 16:55:27.989725 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.12474 (* 1 = 5.12474 loss)
I0628 16:55:27.989734 17458 sgd_solver.cpp:138] Iteration 840, lr = 0.0005
I0628 16:55:37.106184 17458 solver.cpp:243] Iteration 850, loss = 5.49053
I0628 16:55:37.106209 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.02873 (* 1 = 4.02873 loss)
I0628 16:55:37.106235 17458 sgd_solver.cpp:138] Iteration 850, lr = 0.0005
I0628 16:55:46.257977 17458 solver.cpp:243] Iteration 860, loss = 5.13088
I0628 16:55:46.258002 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.73394 (* 1 = 3.73394 loss)
I0628 16:55:46.258026 17458 sgd_solver.cpp:138] Iteration 860, lr = 0.0005
I0628 16:55:55.386544 17458 solver.cpp:243] Iteration 870, loss = 5.63049
I0628 16:55:55.386569 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.44221 (* 1 = 2.44221 loss)
I0628 16:55:55.386593 17458 sgd_solver.cpp:138] Iteration 870, lr = 0.0005
I0628 16:56:04.535893 17458 solver.cpp:243] Iteration 880, loss = 3.64523
I0628 16:56:04.536041 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.29871 (* 1 = 3.29871 loss)
I0628 16:56:04.536049 17458 sgd_solver.cpp:138] Iteration 880, lr = 0.0005
I0628 16:56:13.642745 17458 solver.cpp:243] Iteration 890, loss = 4.76486
I0628 16:56:13.642769 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.61998 (* 1 = 4.61998 loss)
I0628 16:56:13.642794 17458 sgd_solver.cpp:138] Iteration 890, lr = 0.0005
I0628 16:56:22.767169 17458 solver.cpp:243] Iteration 900, loss = 5.07961
I0628 16:56:22.767215 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.06735 (* 1 = 6.06735 loss)
I0628 16:56:22.767222 17458 sgd_solver.cpp:138] Iteration 900, lr = 0.0005
I0628 16:56:31.867048 17458 solver.cpp:243] Iteration 910, loss = 5.77354
I0628 16:56:31.867070 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.12413 (* 1 = 7.12413 loss)
I0628 16:56:31.867077 17458 sgd_solver.cpp:138] Iteration 910, lr = 0.0005
I0628 16:56:40.983256 17458 solver.cpp:243] Iteration 920, loss = 5.03077
I0628 16:56:40.983480 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.63643 (* 1 = 3.63643 loss)
I0628 16:56:40.983489 17458 sgd_solver.cpp:138] Iteration 920, lr = 0.0005
I0628 16:56:50.090975 17458 solver.cpp:243] Iteration 930, loss = 5.12398
I0628 16:56:50.090997 17458 solver.cpp:259]     Train net output #0: mbox_loss = 8.47849 (* 1 = 8.47849 loss)
I0628 16:56:50.091023 17458 sgd_solver.cpp:138] Iteration 930, lr = 0.0005
I0628 16:56:59.240566 17458 solver.cpp:243] Iteration 940, loss = 4.03366
I0628 16:56:59.240589 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.68768 (* 1 = 4.68768 loss)
I0628 16:56:59.240614 17458 sgd_solver.cpp:138] Iteration 940, lr = 0.0005
I0628 16:57:08.375470 17458 solver.cpp:243] Iteration 950, loss = 4.61884
I0628 16:57:08.375494 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.82368 (* 1 = 3.82368 loss)
I0628 16:57:08.375519 17458 sgd_solver.cpp:138] Iteration 950, lr = 0.0005
I0628 16:57:17.508522 17458 solver.cpp:243] Iteration 960, loss = 5.04018
I0628 16:57:17.508668 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.74484 (* 1 = 4.74484 loss)
I0628 16:57:17.508677 17458 sgd_solver.cpp:138] Iteration 960, lr = 0.0005
I0628 16:57:26.616659 17458 solver.cpp:243] Iteration 970, loss = 4.49931
I0628 16:57:26.616683 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.27243 (* 1 = 7.27243 loss)
I0628 16:57:26.616689 17458 sgd_solver.cpp:138] Iteration 970, lr = 0.0005
I0628 16:57:35.737833 17458 solver.cpp:243] Iteration 980, loss = 5.16678
I0628 16:57:35.737857 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.15642 (* 1 = 5.15642 loss)
I0628 16:57:35.737864 17458 sgd_solver.cpp:138] Iteration 980, lr = 0.0005
I0628 16:57:44.864650 17458 solver.cpp:243] Iteration 990, loss = 4.10396
I0628 16:57:44.864675 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.77834 (* 1 = 5.77834 loss)
I0628 16:57:44.864681 17458 sgd_solver.cpp:138] Iteration 990, lr = 0.0005
I0628 16:57:53.261229 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_1000.caffemodel
I0628 16:57:53.358088 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_1000.solverstate
I0628 16:57:53.390445 17458 solver.cpp:433] Iteration 1000, Testing net (#0)
I0628 16:57:53.397137 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 17:00:58.450193 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.10212
I0628 17:00:59.237877 17458 solver.cpp:243] Iteration 1000, loss = 4.75086
I0628 17:00:59.237900 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.39985 (* 1 = 3.39985 loss)
I0628 17:00:59.237941 17458 sgd_solver.cpp:138] Iteration 1000, lr = 0.0005
I0628 17:01:08.362088 17458 solver.cpp:243] Iteration 1010, loss = 4.86249
I0628 17:01:08.362116 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.69135 (* 1 = 2.69135 loss)
I0628 17:01:08.362125 17458 sgd_solver.cpp:138] Iteration 1010, lr = 0.0005
I0628 17:01:17.472828 17458 solver.cpp:243] Iteration 1020, loss = 5.29035
I0628 17:01:17.472851 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.00094 (* 1 = 6.00094 loss)
I0628 17:01:17.472858 17458 sgd_solver.cpp:138] Iteration 1020, lr = 0.0005
I0628 17:01:26.610803 17458 solver.cpp:243] Iteration 1030, loss = 4.83578
I0628 17:01:26.610827 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.21039 (* 1 = 5.21039 loss)
I0628 17:01:26.610834 17458 sgd_solver.cpp:138] Iteration 1030, lr = 0.0005
I0628 17:01:35.720737 17458 solver.cpp:243] Iteration 1040, loss = 4.89815
I0628 17:01:35.720885 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.77808 (* 1 = 6.77808 loss)
I0628 17:01:35.720894 17458 sgd_solver.cpp:138] Iteration 1040, lr = 0.0005
I0628 17:01:44.838002 17458 solver.cpp:243] Iteration 1050, loss = 4.90172
I0628 17:01:44.838028 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.99357 (* 1 = 6.99357 loss)
I0628 17:01:44.838035 17458 sgd_solver.cpp:138] Iteration 1050, lr = 0.0005
I0628 17:01:53.956301 17458 solver.cpp:243] Iteration 1060, loss = 4.93087
I0628 17:01:53.956326 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.30927 (* 1 = 5.30927 loss)
I0628 17:01:53.956332 17458 sgd_solver.cpp:138] Iteration 1060, lr = 0.0005
I0628 17:02:03.097752 17458 solver.cpp:243] Iteration 1070, loss = 4.74778
I0628 17:02:03.097777 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.57873 (* 1 = 7.57873 loss)
I0628 17:02:03.097785 17458 sgd_solver.cpp:138] Iteration 1070, lr = 0.0005
I0628 17:02:12.193816 17458 solver.cpp:243] Iteration 1080, loss = 4.37405
I0628 17:02:12.193964 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.30752 (* 1 = 4.30752 loss)
I0628 17:02:12.193974 17458 sgd_solver.cpp:138] Iteration 1080, lr = 0.0005
I0628 17:02:21.337066 17458 solver.cpp:243] Iteration 1090, loss = 4.32711
I0628 17:02:21.337090 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.77663 (* 1 = 5.77663 loss)
I0628 17:02:21.337097 17458 sgd_solver.cpp:138] Iteration 1090, lr = 0.0005
I0628 17:02:30.456166 17458 solver.cpp:243] Iteration 1100, loss = 5.27951
I0628 17:02:30.456189 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.92867 (* 1 = 4.92867 loss)
I0628 17:02:30.456197 17458 sgd_solver.cpp:138] Iteration 1100, lr = 0.0005
I0628 17:02:39.576985 17458 solver.cpp:243] Iteration 1110, loss = 4.10358
I0628 17:02:39.577011 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.87026 (* 1 = 3.87026 loss)
I0628 17:02:39.577019 17458 sgd_solver.cpp:138] Iteration 1110, lr = 0.0005
I0628 17:02:48.678948 17458 solver.cpp:243] Iteration 1120, loss = 5.2004
I0628 17:02:48.679138 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.75785 (* 1 = 6.75785 loss)
I0628 17:02:48.679165 17458 sgd_solver.cpp:138] Iteration 1120, lr = 0.0005
I0628 17:02:57.823056 17458 solver.cpp:243] Iteration 1130, loss = 4.62399
I0628 17:02:57.823082 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.21023 (* 1 = 5.21023 loss)
I0628 17:02:57.823089 17458 sgd_solver.cpp:138] Iteration 1130, lr = 0.0005
I0628 17:03:06.939556 17458 solver.cpp:243] Iteration 1140, loss = 4.61501
I0628 17:03:06.939580 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.82743 (* 1 = 4.82743 loss)
I0628 17:03:06.939589 17458 sgd_solver.cpp:138] Iteration 1140, lr = 0.0005
I0628 17:03:16.058243 17458 solver.cpp:243] Iteration 1150, loss = 4.39328
I0628 17:03:16.058266 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.10806 (* 1 = 4.10806 loss)
I0628 17:03:16.058291 17458 sgd_solver.cpp:138] Iteration 1150, lr = 0.0005
I0628 17:03:25.183135 17458 solver.cpp:243] Iteration 1160, loss = 5.40297
I0628 17:03:25.183246 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.90948 (* 1 = 4.90948 loss)
I0628 17:03:25.183257 17458 sgd_solver.cpp:138] Iteration 1160, lr = 0.0005
I0628 17:03:34.334594 17458 solver.cpp:243] Iteration 1170, loss = 5.26138
I0628 17:03:34.334621 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.41637 (* 1 = 3.41637 loss)
I0628 17:03:34.334630 17458 sgd_solver.cpp:138] Iteration 1170, lr = 0.0005
I0628 17:03:43.437460 17458 solver.cpp:243] Iteration 1180, loss = 4.31852
I0628 17:03:43.437484 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.04809 (* 1 = 4.04809 loss)
I0628 17:03:43.437494 17458 sgd_solver.cpp:138] Iteration 1180, lr = 0.0005
I0628 17:03:52.569706 17458 solver.cpp:243] Iteration 1190, loss = 4.95145
I0628 17:03:52.569733 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.24297 (* 1 = 2.24297 loss)
I0628 17:03:52.569744 17458 sgd_solver.cpp:138] Iteration 1190, lr = 0.0005
I0628 17:04:01.677508 17458 solver.cpp:243] Iteration 1200, loss = 4.51261
I0628 17:04:01.677680 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.78248 (* 1 = 2.78248 loss)
I0628 17:04:01.677691 17458 sgd_solver.cpp:138] Iteration 1200, lr = 0.0005
I0628 17:04:10.804472 17458 solver.cpp:243] Iteration 1210, loss = 4.57068
I0628 17:04:10.804502 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.3717 (* 1 = 5.3717 loss)
I0628 17:04:10.804510 17458 sgd_solver.cpp:138] Iteration 1210, lr = 0.0005
I0628 17:04:19.919106 17458 solver.cpp:243] Iteration 1220, loss = 4.71852
I0628 17:04:19.919131 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.0946 (* 1 = 5.0946 loss)
I0628 17:04:19.919142 17458 sgd_solver.cpp:138] Iteration 1220, lr = 0.0005
I0628 17:04:29.068002 17458 solver.cpp:243] Iteration 1230, loss = 4.60364
I0628 17:04:29.068030 17458 solver.cpp:259]     Train net output #0: mbox_loss = 8.63961 (* 1 = 8.63961 loss)
I0628 17:04:29.068040 17458 sgd_solver.cpp:138] Iteration 1230, lr = 0.0005
I0628 17:04:38.185518 17458 solver.cpp:243] Iteration 1240, loss = 4.37654
I0628 17:04:38.185674 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.33882 (* 1 = 4.33882 loss)
I0628 17:04:38.185688 17458 sgd_solver.cpp:138] Iteration 1240, lr = 0.0005
I0628 17:04:47.317972 17458 solver.cpp:243] Iteration 1250, loss = 5.17174
I0628 17:04:47.318001 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.55135 (* 1 = 6.55135 loss)
I0628 17:04:47.318011 17458 sgd_solver.cpp:138] Iteration 1250, lr = 0.0005
I0628 17:04:56.427541 17458 solver.cpp:243] Iteration 1260, loss = 3.98556
I0628 17:04:56.427568 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.39728 (* 1 = 2.39728 loss)
I0628 17:04:56.427578 17458 sgd_solver.cpp:138] Iteration 1260, lr = 0.0005
I0628 17:05:05.560065 17458 solver.cpp:243] Iteration 1270, loss = 3.96023
I0628 17:05:05.560092 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.22453 (* 1 = 2.22453 loss)
I0628 17:05:05.560101 17458 sgd_solver.cpp:138] Iteration 1270, lr = 0.0005
I0628 17:05:14.669785 17458 solver.cpp:243] Iteration 1280, loss = 5.23495
I0628 17:05:14.669893 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.95788 (* 1 = 4.95788 loss)
I0628 17:05:14.669904 17458 sgd_solver.cpp:138] Iteration 1280, lr = 0.0005
I0628 17:05:23.798981 17458 solver.cpp:243] Iteration 1290, loss = 5.34197
I0628 17:05:23.799008 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.27469 (* 1 = 4.27469 loss)
I0628 17:05:23.799017 17458 sgd_solver.cpp:138] Iteration 1290, lr = 0.0005
I0628 17:05:32.907800 17458 solver.cpp:243] Iteration 1300, loss = 4.57176
I0628 17:05:32.907827 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.89434 (* 1 = 2.89434 loss)
I0628 17:05:32.907837 17458 sgd_solver.cpp:138] Iteration 1300, lr = 0.0005
I0628 17:05:42.039892 17458 solver.cpp:243] Iteration 1310, loss = 5.19456
I0628 17:05:42.039919 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.70571 (* 1 = 6.70571 loss)
I0628 17:05:42.039929 17458 sgd_solver.cpp:138] Iteration 1310, lr = 0.0005
I0628 17:05:51.166716 17458 solver.cpp:243] Iteration 1320, loss = 4.44692
I0628 17:05:51.166869 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.8183 (* 1 = 2.8183 loss)
I0628 17:05:51.166880 17458 sgd_solver.cpp:138] Iteration 1320, lr = 0.0005
I0628 17:06:00.318542 17458 solver.cpp:243] Iteration 1330, loss = 4.32404
I0628 17:06:00.318568 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.11311 (* 1 = 3.11311 loss)
I0628 17:06:00.318578 17458 sgd_solver.cpp:138] Iteration 1330, lr = 0.0005
I0628 17:06:09.441334 17458 solver.cpp:243] Iteration 1340, loss = 4.32333
I0628 17:06:09.441360 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.89286 (* 1 = 2.89286 loss)
I0628 17:06:09.441370 17458 sgd_solver.cpp:138] Iteration 1340, lr = 0.0005
I0628 17:06:18.591369 17458 solver.cpp:243] Iteration 1350, loss = 4.94441
I0628 17:06:18.591399 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.15744 (* 1 = 7.15744 loss)
I0628 17:06:18.591410 17458 sgd_solver.cpp:138] Iteration 1350, lr = 0.0005
I0628 17:06:27.717147 17458 solver.cpp:243] Iteration 1360, loss = 4.6129
I0628 17:06:27.717322 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.19676 (* 1 = 4.19676 loss)
I0628 17:06:27.717362 17458 sgd_solver.cpp:138] Iteration 1360, lr = 0.0005
I0628 17:06:36.850355 17458 solver.cpp:243] Iteration 1370, loss = 4.10265
I0628 17:06:36.850384 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.61836 (* 1 = 3.61836 loss)
I0628 17:06:36.850395 17458 sgd_solver.cpp:138] Iteration 1370, lr = 0.0005
I0628 17:06:45.958454 17458 solver.cpp:243] Iteration 1380, loss = 5.71065
I0628 17:06:45.958478 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.8928 (* 1 = 3.8928 loss)
I0628 17:06:45.958488 17458 sgd_solver.cpp:138] Iteration 1380, lr = 0.0005
I0628 17:06:55.093768 17458 solver.cpp:243] Iteration 1390, loss = 3.96925
I0628 17:06:55.093796 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.20017 (* 1 = 5.20017 loss)
I0628 17:06:55.093806 17458 sgd_solver.cpp:138] Iteration 1390, lr = 0.0005
I0628 17:07:04.200374 17458 solver.cpp:243] Iteration 1400, loss = 4.49316
I0628 17:07:04.200511 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.3157 (* 1 = 6.3157 loss)
I0628 17:07:04.200523 17458 sgd_solver.cpp:138] Iteration 1400, lr = 0.0005
I0628 17:07:13.339336 17458 solver.cpp:243] Iteration 1410, loss = 3.96927
I0628 17:07:13.339365 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.25101 (* 1 = 5.25101 loss)
I0628 17:07:13.339375 17458 sgd_solver.cpp:138] Iteration 1410, lr = 0.0005
I0628 17:07:22.463966 17458 solver.cpp:243] Iteration 1420, loss = 5.06993
I0628 17:07:22.463992 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.27851 (* 1 = 4.27851 loss)
I0628 17:07:22.464001 17458 sgd_solver.cpp:138] Iteration 1420, lr = 0.0005
I0628 17:07:31.616535 17458 solver.cpp:243] Iteration 1430, loss = 5.04026
I0628 17:07:31.616566 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.8508 (* 1 = 2.8508 loss)
I0628 17:07:31.616577 17458 sgd_solver.cpp:138] Iteration 1430, lr = 0.0005
I0628 17:07:40.742211 17458 solver.cpp:243] Iteration 1440, loss = 4.34136
I0628 17:07:40.742358 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.60111 (* 1 = 4.60111 loss)
I0628 17:07:40.742372 17458 sgd_solver.cpp:138] Iteration 1440, lr = 0.0005
I0628 17:07:49.898465 17458 solver.cpp:243] Iteration 1450, loss = 4.06476
I0628 17:07:49.898492 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.17726 (* 1 = 5.17726 loss)
I0628 17:07:49.898501 17458 sgd_solver.cpp:138] Iteration 1450, lr = 0.0005
I0628 17:07:59.028986 17458 solver.cpp:243] Iteration 1460, loss = 4.14492
I0628 17:07:59.029016 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.79854 (* 1 = 4.79854 loss)
I0628 17:07:59.029028 17458 sgd_solver.cpp:138] Iteration 1460, lr = 0.0005
I0628 17:08:08.167837 17458 solver.cpp:243] Iteration 1470, loss = 4.4867
I0628 17:08:08.167870 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.11121 (* 1 = 5.11121 loss)
I0628 17:08:08.167881 17458 sgd_solver.cpp:138] Iteration 1470, lr = 0.0005
I0628 17:08:17.279263 17458 solver.cpp:243] Iteration 1480, loss = 5.12602
I0628 17:08:17.279414 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.10181 (* 1 = 3.10181 loss)
I0628 17:08:17.279444 17458 sgd_solver.cpp:138] Iteration 1480, lr = 0.0005
I0628 17:08:26.413825 17458 solver.cpp:243] Iteration 1490, loss = 4.53963
I0628 17:08:26.413853 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.04595 (* 1 = 3.04595 loss)
I0628 17:08:26.413863 17458 sgd_solver.cpp:138] Iteration 1490, lr = 0.0005
I0628 17:08:35.544236 17458 solver.cpp:243] Iteration 1500, loss = 4.54347
I0628 17:08:35.544262 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.25047 (* 1 = 5.25047 loss)
I0628 17:08:35.544272 17458 sgd_solver.cpp:138] Iteration 1500, lr = 0.0005
I0628 17:08:44.703663 17458 solver.cpp:243] Iteration 1510, loss = 5.16219
I0628 17:08:44.703694 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.43839 (* 1 = 2.43839 loss)
I0628 17:08:44.703706 17458 sgd_solver.cpp:138] Iteration 1510, lr = 0.0005
I0628 17:08:53.837867 17458 solver.cpp:243] Iteration 1520, loss = 3.80611
I0628 17:08:53.838032 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.8252 (* 1 = 3.8252 loss)
I0628 17:08:53.838044 17458 sgd_solver.cpp:138] Iteration 1520, lr = 0.0005
I0628 17:09:02.969489 17458 solver.cpp:243] Iteration 1530, loss = 4.11816
I0628 17:09:02.969516 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.23596 (* 1 = 4.23596 loss)
I0628 17:09:02.969532 17458 sgd_solver.cpp:138] Iteration 1530, lr = 0.0005
I0628 17:09:12.081856 17458 solver.cpp:243] Iteration 1540, loss = 4.47742
I0628 17:09:12.081882 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.5715 (* 1 = 5.5715 loss)
I0628 17:09:12.081892 17458 sgd_solver.cpp:138] Iteration 1540, lr = 0.0005
I0628 17:09:21.217514 17458 solver.cpp:243] Iteration 1550, loss = 4.18274
I0628 17:09:21.217540 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.80104 (* 1 = 5.80104 loss)
I0628 17:09:21.217548 17458 sgd_solver.cpp:138] Iteration 1550, lr = 0.0005
I0628 17:09:30.326882 17458 solver.cpp:243] Iteration 1560, loss = 4.01089
I0628 17:09:30.327142 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.41897 (* 1 = 4.41897 loss)
I0628 17:09:30.327153 17458 sgd_solver.cpp:138] Iteration 1560, lr = 0.0005
I0628 17:09:39.462797 17458 solver.cpp:243] Iteration 1570, loss = 6.27642
I0628 17:09:39.462824 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.0793 (* 1 = 5.0793 loss)
I0628 17:09:39.462833 17458 sgd_solver.cpp:138] Iteration 1570, lr = 0.0005
I0628 17:09:48.600113 17458 solver.cpp:243] Iteration 1580, loss = 3.55973
I0628 17:09:48.600144 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.8806 (* 1 = 2.8806 loss)
I0628 17:09:48.600155 17458 sgd_solver.cpp:138] Iteration 1580, lr = 0.0005
I0628 17:09:57.755568 17458 solver.cpp:243] Iteration 1590, loss = 3.71826
I0628 17:09:57.755595 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.48774 (* 1 = 5.48774 loss)
I0628 17:09:57.755604 17458 sgd_solver.cpp:138] Iteration 1590, lr = 0.0005
I0628 17:10:06.889290 17458 solver.cpp:243] Iteration 1600, loss = 4.37154
I0628 17:10:06.889413 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25556 (* 1 = 3.25556 loss)
I0628 17:10:06.889425 17458 sgd_solver.cpp:138] Iteration 1600, lr = 0.0005
I0628 17:10:16.047833 17458 solver.cpp:243] Iteration 1610, loss = 4.59393
I0628 17:10:16.047861 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.47032 (* 1 = 5.47032 loss)
I0628 17:10:16.047870 17458 sgd_solver.cpp:138] Iteration 1610, lr = 0.0005
I0628 17:10:25.171938 17458 solver.cpp:243] Iteration 1620, loss = 4.56418
I0628 17:10:25.171972 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.97969 (* 1 = 4.97969 loss)
I0628 17:10:25.171981 17458 sgd_solver.cpp:138] Iteration 1620, lr = 0.0005
I0628 17:10:34.330005 17458 solver.cpp:243] Iteration 1630, loss = 4.16027
I0628 17:10:34.330032 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.22989 (* 1 = 4.22989 loss)
I0628 17:10:34.330041 17458 sgd_solver.cpp:138] Iteration 1630, lr = 0.0005
I0628 17:10:43.455850 17458 solver.cpp:243] Iteration 1640, loss = 4.76835
I0628 17:10:43.456010 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.08712 (* 1 = 2.08712 loss)
I0628 17:10:43.456022 17458 sgd_solver.cpp:138] Iteration 1640, lr = 0.0005
I0628 17:10:52.589143 17458 solver.cpp:243] Iteration 1650, loss = 4.13504
I0628 17:10:52.589171 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.15447 (* 1 = 2.15447 loss)
I0628 17:10:52.589180 17458 sgd_solver.cpp:138] Iteration 1650, lr = 0.0005
I0628 17:11:01.694578 17458 solver.cpp:243] Iteration 1660, loss = 4.15293
I0628 17:11:01.694605 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.9892 (* 1 = 4.9892 loss)
I0628 17:11:01.694614 17458 sgd_solver.cpp:138] Iteration 1660, lr = 0.0005
I0628 17:11:10.831661 17458 solver.cpp:243] Iteration 1670, loss = 4.51436
I0628 17:11:10.831691 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.41276 (* 1 = 5.41276 loss)
I0628 17:11:10.831701 17458 sgd_solver.cpp:138] Iteration 1670, lr = 0.0005
I0628 17:11:19.939795 17458 solver.cpp:243] Iteration 1680, loss = 4.2773
I0628 17:11:19.939934 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.80938 (* 1 = 4.80938 loss)
I0628 17:11:19.939945 17458 sgd_solver.cpp:138] Iteration 1680, lr = 0.0005
I0628 17:11:29.079161 17458 solver.cpp:243] Iteration 1690, loss = 3.43491
I0628 17:11:29.079188 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.18097 (* 1 = 3.18097 loss)
I0628 17:11:29.079197 17458 sgd_solver.cpp:138] Iteration 1690, lr = 0.0005
I0628 17:11:38.190901 17458 solver.cpp:243] Iteration 1700, loss = 4.46546
I0628 17:11:38.190927 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.6863 (* 1 = 4.6863 loss)
I0628 17:11:38.190937 17458 sgd_solver.cpp:138] Iteration 1700, lr = 0.0005
I0628 17:11:47.326303 17458 solver.cpp:243] Iteration 1710, loss = 4.03799
I0628 17:11:47.326331 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.34377 (* 1 = 4.34377 loss)
I0628 17:11:47.326340 17458 sgd_solver.cpp:138] Iteration 1710, lr = 0.0005
I0628 17:11:56.435583 17458 solver.cpp:243] Iteration 1720, loss = 3.60617
I0628 17:11:56.435737 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.55929 (* 1 = 2.55929 loss)
I0628 17:11:56.435748 17458 sgd_solver.cpp:138] Iteration 1720, lr = 0.0005
I0628 17:12:05.578744 17458 solver.cpp:243] Iteration 1730, loss = 3.98548
I0628 17:12:05.578771 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.33451 (* 1 = 4.33451 loss)
I0628 17:12:05.578780 17458 sgd_solver.cpp:138] Iteration 1730, lr = 0.0005
I0628 17:12:14.711997 17458 solver.cpp:243] Iteration 1740, loss = 4.2541
I0628 17:12:14.712025 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.34864 (* 1 = 4.34864 loss)
I0628 17:12:14.712038 17458 sgd_solver.cpp:138] Iteration 1740, lr = 0.0005
I0628 17:12:23.856983 17458 solver.cpp:243] Iteration 1750, loss = 4.28765
I0628 17:12:23.857014 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.63336 (* 1 = 5.63336 loss)
I0628 17:12:23.857028 17458 sgd_solver.cpp:138] Iteration 1750, lr = 0.0005
I0628 17:12:32.964705 17458 solver.cpp:243] Iteration 1760, loss = 4.67552
I0628 17:12:32.964844 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.17421 (* 1 = 6.17421 loss)
I0628 17:12:32.964875 17458 sgd_solver.cpp:138] Iteration 1760, lr = 0.0005
I0628 17:12:42.101881 17458 solver.cpp:243] Iteration 1770, loss = 3.76687
I0628 17:12:42.101907 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.82969 (* 1 = 3.82969 loss)
I0628 17:12:42.101914 17458 sgd_solver.cpp:138] Iteration 1770, lr = 0.0005
I0628 17:12:51.213605 17458 solver.cpp:243] Iteration 1780, loss = 4.12775
I0628 17:12:51.213634 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.96 (* 1 = 2.96 loss)
I0628 17:12:51.213646 17458 sgd_solver.cpp:138] Iteration 1780, lr = 0.0005
I0628 17:13:00.341627 17458 solver.cpp:243] Iteration 1790, loss = 3.92168
I0628 17:13:00.341653 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.8342 (* 1 = 2.8342 loss)
I0628 17:13:00.341662 17458 sgd_solver.cpp:138] Iteration 1790, lr = 0.0005
I0628 17:13:09.461549 17458 solver.cpp:243] Iteration 1800, loss = 4.4637
I0628 17:13:09.461714 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.38316 (* 1 = 4.38316 loss)
I0628 17:13:09.461724 17458 sgd_solver.cpp:138] Iteration 1800, lr = 0.0005
I0628 17:13:18.617280 17458 solver.cpp:243] Iteration 1810, loss = 4.35371
I0628 17:13:18.617311 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.39617 (* 1 = 3.39617 loss)
I0628 17:13:18.617322 17458 sgd_solver.cpp:138] Iteration 1810, lr = 0.0005
I0628 17:13:27.738348 17458 solver.cpp:243] Iteration 1820, loss = 3.72816
I0628 17:13:27.738374 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.31633 (* 1 = 2.31633 loss)
I0628 17:13:27.738384 17458 sgd_solver.cpp:138] Iteration 1820, lr = 0.0005
I0628 17:13:36.874101 17458 solver.cpp:243] Iteration 1830, loss = 4.66892
I0628 17:13:36.874130 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.94603 (* 1 = 1.94603 loss)
I0628 17:13:36.874140 17458 sgd_solver.cpp:138] Iteration 1830, lr = 0.0005
I0628 17:13:45.980268 17458 solver.cpp:243] Iteration 1840, loss = 4.18018
I0628 17:13:45.980422 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.61851 (* 1 = 5.61851 loss)
I0628 17:13:45.980432 17458 sgd_solver.cpp:138] Iteration 1840, lr = 0.0005
I0628 17:13:55.114922 17458 solver.cpp:243] Iteration 1850, loss = 4.10355
I0628 17:13:55.114949 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.87538 (* 1 = 5.87538 loss)
I0628 17:13:55.114959 17458 sgd_solver.cpp:138] Iteration 1850, lr = 0.0005
I0628 17:14:04.223603 17458 solver.cpp:243] Iteration 1860, loss = 4.39421
I0628 17:14:04.223628 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.27336 (* 1 = 5.27336 loss)
I0628 17:14:04.223637 17458 sgd_solver.cpp:138] Iteration 1860, lr = 0.0005
I0628 17:14:13.357336 17458 solver.cpp:243] Iteration 1870, loss = 4.31534
I0628 17:14:13.357362 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.71046 (* 1 = 5.71046 loss)
I0628 17:14:13.357372 17458 sgd_solver.cpp:138] Iteration 1870, lr = 0.0005
I0628 17:14:22.463451 17458 solver.cpp:243] Iteration 1880, loss = 3.64129
I0628 17:14:22.463582 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.62225 (* 1 = 4.62225 loss)
I0628 17:14:22.463609 17458 sgd_solver.cpp:138] Iteration 1880, lr = 0.0005
I0628 17:14:31.609660 17458 solver.cpp:243] Iteration 1890, loss = 4.6037
I0628 17:14:31.609686 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.55703 (* 1 = 5.55703 loss)
I0628 17:14:31.609695 17458 sgd_solver.cpp:138] Iteration 1890, lr = 0.0005
I0628 17:14:40.738735 17458 solver.cpp:243] Iteration 1900, loss = 3.82318
I0628 17:14:40.738763 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.34448 (* 1 = 3.34448 loss)
I0628 17:14:40.738773 17458 sgd_solver.cpp:138] Iteration 1900, lr = 0.0005
I0628 17:14:49.883554 17458 solver.cpp:243] Iteration 1910, loss = 3.46973
I0628 17:14:49.883582 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.02746 (* 1 = 4.02746 loss)
I0628 17:14:49.883594 17458 sgd_solver.cpp:138] Iteration 1910, lr = 0.0005
I0628 17:14:58.990588 17458 solver.cpp:243] Iteration 1920, loss = 3.79566
I0628 17:14:58.990751 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.07888 (* 1 = 5.07888 loss)
I0628 17:14:58.990761 17458 sgd_solver.cpp:138] Iteration 1920, lr = 0.0005
I0628 17:15:08.125180 17458 solver.cpp:243] Iteration 1930, loss = 4.3131
I0628 17:15:08.125210 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.8051 (* 1 = 4.8051 loss)
I0628 17:15:08.125219 17458 sgd_solver.cpp:138] Iteration 1930, lr = 0.0005
I0628 17:15:17.235981 17458 solver.cpp:243] Iteration 1940, loss = 4.68563
I0628 17:15:17.236008 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.41112 (* 1 = 5.41112 loss)
I0628 17:15:17.236017 17458 sgd_solver.cpp:138] Iteration 1940, lr = 0.0005
I0628 17:15:26.362587 17458 solver.cpp:243] Iteration 1950, loss = 4.76889
I0628 17:15:26.362613 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53522 (* 1 = 3.53522 loss)
I0628 17:15:26.362622 17458 sgd_solver.cpp:138] Iteration 1950, lr = 0.0005
I0628 17:15:35.477336 17458 solver.cpp:243] Iteration 1960, loss = 4.17777
I0628 17:15:35.477485 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.69081 (* 1 = 3.69081 loss)
I0628 17:15:35.477497 17458 sgd_solver.cpp:138] Iteration 1960, lr = 0.0005
I0628 17:15:44.622831 17458 solver.cpp:243] Iteration 1970, loss = 3.80686
I0628 17:15:44.622857 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.18176 (* 1 = 3.18176 loss)
I0628 17:15:44.622867 17458 sgd_solver.cpp:138] Iteration 1970, lr = 0.0005
I0628 17:15:53.751534 17458 solver.cpp:243] Iteration 1980, loss = 4.25769
I0628 17:15:53.751565 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.22094 (* 1 = 4.22094 loss)
I0628 17:15:53.751577 17458 sgd_solver.cpp:138] Iteration 1980, lr = 0.0005
I0628 17:16:02.891427 17458 solver.cpp:243] Iteration 1990, loss = 4.6678
I0628 17:16:02.891453 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.76488 (* 1 = 5.76488 loss)
I0628 17:16:02.891463 17458 sgd_solver.cpp:138] Iteration 1990, lr = 0.0005
I0628 17:16:11.248414 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_2000.caffemodel
I0628 17:16:11.330262 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_2000.solverstate
I0628 17:16:11.362190 17458 solver.cpp:433] Iteration 2000, Testing net (#0)
I0628 17:16:11.362365 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 17:19:16.545682 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.164686
I0628 17:19:17.335418 17458 solver.cpp:243] Iteration 2000, loss = 3.9749
I0628 17:19:17.335443 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.5954 (* 1 = 4.5954 loss)
I0628 17:19:17.335469 17458 sgd_solver.cpp:138] Iteration 2000, lr = 0.0005
I0628 17:19:26.467959 17458 solver.cpp:243] Iteration 2010, loss = 3.48171
I0628 17:19:26.467983 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.96189 (* 1 = 5.96189 loss)
I0628 17:19:26.467991 17458 sgd_solver.cpp:138] Iteration 2010, lr = 0.0005
I0628 17:19:35.605010 17458 solver.cpp:243] Iteration 2020, loss = 3.98284
I0628 17:19:35.605034 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.89241 (* 1 = 2.89241 loss)
I0628 17:19:35.605059 17458 sgd_solver.cpp:138] Iteration 2020, lr = 0.0005
I0628 17:19:44.771737 17458 solver.cpp:243] Iteration 2030, loss = 4.09856
I0628 17:19:44.771761 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.88373 (* 1 = 1.88373 loss)
I0628 17:19:44.771787 17458 sgd_solver.cpp:138] Iteration 2030, lr = 0.0005
I0628 17:19:53.912895 17458 solver.cpp:243] Iteration 2040, loss = 3.52983
I0628 17:19:53.913069 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.31692 (* 1 = 4.31692 loss)
I0628 17:19:53.913076 17458 sgd_solver.cpp:138] Iteration 2040, lr = 0.0005
I0628 17:20:03.075103 17458 solver.cpp:243] Iteration 2050, loss = 3.75281
I0628 17:20:03.075126 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.29813 (* 1 = 4.29813 loss)
I0628 17:20:03.075151 17458 sgd_solver.cpp:138] Iteration 2050, lr = 0.0005
I0628 17:20:12.202034 17458 solver.cpp:243] Iteration 2060, loss = 4.03873
I0628 17:20:12.202075 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.34032 (* 1 = 3.34032 loss)
I0628 17:20:12.202100 17458 sgd_solver.cpp:138] Iteration 2060, lr = 0.0005
I0628 17:20:21.361465 17458 solver.cpp:243] Iteration 2070, loss = 4.04219
I0628 17:20:21.361490 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.00682 (* 1 = 4.00682 loss)
I0628 17:20:21.361515 17458 sgd_solver.cpp:138] Iteration 2070, lr = 0.0005
I0628 17:20:30.500389 17458 solver.cpp:243] Iteration 2080, loss = 3.9265
I0628 17:20:30.500532 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.84843 (* 1 = 4.84843 loss)
I0628 17:20:30.500541 17458 sgd_solver.cpp:138] Iteration 2080, lr = 0.0005
I0628 17:20:39.668135 17458 solver.cpp:243] Iteration 2090, loss = 3.88168
I0628 17:20:39.668160 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.44418 (* 1 = 4.44418 loss)
I0628 17:20:39.668186 17458 sgd_solver.cpp:138] Iteration 2090, lr = 0.0005
I0628 17:20:48.808722 17458 solver.cpp:243] Iteration 2100, loss = 4.1145
I0628 17:20:48.808789 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.43897 (* 1 = 2.43897 loss)
I0628 17:20:48.808811 17458 sgd_solver.cpp:138] Iteration 2100, lr = 0.0005
I0628 17:20:57.967779 17458 solver.cpp:243] Iteration 2110, loss = 4.35818
I0628 17:20:57.967820 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.70598 (* 1 = 3.70598 loss)
I0628 17:20:57.967845 17458 sgd_solver.cpp:138] Iteration 2110, lr = 0.0005
I0628 17:21:07.111527 17458 solver.cpp:243] Iteration 2120, loss = 4.88021
I0628 17:21:07.111685 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.64956 (* 1 = 4.64956 loss)
I0628 17:21:07.111692 17458 sgd_solver.cpp:138] Iteration 2120, lr = 0.0005
I0628 17:21:16.271915 17458 solver.cpp:243] Iteration 2130, loss = 4.13468
I0628 17:21:16.271939 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.19517 (* 1 = 2.19517 loss)
I0628 17:21:16.271965 17458 sgd_solver.cpp:138] Iteration 2130, lr = 0.0005
I0628 17:21:25.403076 17458 solver.cpp:243] Iteration 2140, loss = 4.0731
I0628 17:21:25.403101 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.74371 (* 1 = 6.74371 loss)
I0628 17:21:25.403126 17458 sgd_solver.cpp:138] Iteration 2140, lr = 0.0005
I0628 17:21:34.561417 17458 solver.cpp:243] Iteration 2150, loss = 4.45394
I0628 17:21:34.561441 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.96923 (* 1 = 2.96923 loss)
I0628 17:21:34.561466 17458 sgd_solver.cpp:138] Iteration 2150, lr = 0.0005
I0628 17:21:43.702952 17458 solver.cpp:243] Iteration 2160, loss = 3.89093
I0628 17:21:43.703138 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.50168 (* 1 = 2.50168 loss)
I0628 17:21:43.703152 17458 sgd_solver.cpp:138] Iteration 2160, lr = 0.0005
I0628 17:21:52.865588 17458 solver.cpp:243] Iteration 2170, loss = 4.01373
I0628 17:21:52.865612 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.53344 (* 1 = 2.53344 loss)
I0628 17:21:52.865638 17458 sgd_solver.cpp:138] Iteration 2170, lr = 0.0005
I0628 17:22:01.999845 17458 solver.cpp:243] Iteration 2180, loss = 4.00434
I0628 17:22:01.999868 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.17348 (* 1 = 3.17348 loss)
I0628 17:22:01.999876 17458 sgd_solver.cpp:138] Iteration 2180, lr = 0.0005
I0628 17:22:11.149118 17458 solver.cpp:243] Iteration 2190, loss = 3.88946
I0628 17:22:11.149143 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.51487 (* 1 = 5.51487 loss)
I0628 17:22:11.149169 17458 sgd_solver.cpp:138] Iteration 2190, lr = 0.0005
I0628 17:22:20.272636 17458 solver.cpp:243] Iteration 2200, loss = 3.82965
I0628 17:22:20.272790 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.9747 (* 1 = 3.9747 loss)
I0628 17:22:20.272815 17458 sgd_solver.cpp:138] Iteration 2200, lr = 0.0005
I0628 17:22:29.416188 17458 solver.cpp:243] Iteration 2210, loss = 5.01928
I0628 17:22:29.416210 17458 solver.cpp:259]     Train net output #0: mbox_loss = 8.32147 (* 1 = 8.32147 loss)
I0628 17:22:29.416218 17458 sgd_solver.cpp:138] Iteration 2210, lr = 0.0005
I0628 17:22:38.534782 17458 solver.cpp:243] Iteration 2220, loss = 3.48707
I0628 17:22:38.534806 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.57683 (* 1 = 3.57683 loss)
I0628 17:22:38.534831 17458 sgd_solver.cpp:138] Iteration 2220, lr = 0.0005
I0628 17:22:47.694571 17458 solver.cpp:243] Iteration 2230, loss = 3.85373
I0628 17:22:47.694595 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.50072 (* 1 = 3.50072 loss)
I0628 17:22:47.694622 17458 sgd_solver.cpp:138] Iteration 2230, lr = 0.0005
I0628 17:22:56.828094 17458 solver.cpp:243] Iteration 2240, loss = 3.92619
I0628 17:22:56.828258 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.88298 (* 1 = 4.88298 loss)
I0628 17:22:56.828267 17458 sgd_solver.cpp:138] Iteration 2240, lr = 0.0005
I0628 17:23:05.992221 17458 solver.cpp:243] Iteration 2250, loss = 3.82442
I0628 17:23:05.992245 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.30012 (* 1 = 5.30012 loss)
I0628 17:23:05.992270 17458 sgd_solver.cpp:138] Iteration 2250, lr = 0.0005
I0628 17:23:15.123754 17458 solver.cpp:243] Iteration 2260, loss = 3.75599
I0628 17:23:15.123776 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.06787 (* 1 = 4.06787 loss)
I0628 17:23:15.123802 17458 sgd_solver.cpp:138] Iteration 2260, lr = 0.0005
I0628 17:23:24.269301 17458 solver.cpp:243] Iteration 2270, loss = 3.70741
I0628 17:23:24.269331 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.16167 (* 1 = 3.16167 loss)
I0628 17:23:24.269340 17458 sgd_solver.cpp:138] Iteration 2270, lr = 0.0005
I0628 17:23:33.377178 17458 solver.cpp:243] Iteration 2280, loss = 4.44937
I0628 17:23:33.377353 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.03645 (* 1 = 5.03645 loss)
I0628 17:23:33.377363 17458 sgd_solver.cpp:138] Iteration 2280, lr = 0.0005
I0628 17:23:42.502931 17458 solver.cpp:243] Iteration 2290, loss = 3.83954
I0628 17:23:42.502959 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.50837 (* 1 = 2.50837 loss)
I0628 17:23:42.502965 17458 sgd_solver.cpp:138] Iteration 2290, lr = 0.0005
I0628 17:23:51.619676 17458 solver.cpp:243] Iteration 2300, loss = 3.44012
I0628 17:23:51.619701 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.28389 (* 1 = 4.28389 loss)
I0628 17:23:51.619709 17458 sgd_solver.cpp:138] Iteration 2300, lr = 0.0005
I0628 17:24:00.755604 17458 solver.cpp:243] Iteration 2310, loss = 4.23685
I0628 17:24:00.755630 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.74125 (* 1 = 4.74125 loss)
I0628 17:24:00.755636 17458 sgd_solver.cpp:138] Iteration 2310, lr = 0.0005
I0628 17:24:09.853523 17458 solver.cpp:243] Iteration 2320, loss = 4.22832
I0628 17:24:09.853657 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.0905 (* 1 = 5.0905 loss)
I0628 17:24:09.853665 17458 sgd_solver.cpp:138] Iteration 2320, lr = 0.0005
I0628 17:24:18.991286 17458 solver.cpp:243] Iteration 2330, loss = 3.72876
I0628 17:24:18.991312 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.43883 (* 1 = 2.43883 loss)
I0628 17:24:18.991320 17458 sgd_solver.cpp:138] Iteration 2330, lr = 0.0005
I0628 17:24:28.110700 17458 solver.cpp:243] Iteration 2340, loss = 4.43914
I0628 17:24:28.110723 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.50704 (* 1 = 4.50704 loss)
I0628 17:24:28.110747 17458 sgd_solver.cpp:138] Iteration 2340, lr = 0.0005
I0628 17:24:37.254220 17458 solver.cpp:243] Iteration 2350, loss = 3.65718
I0628 17:24:37.254245 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.09329 (* 1 = 2.09329 loss)
I0628 17:24:37.254271 17458 sgd_solver.cpp:138] Iteration 2350, lr = 0.0005
I0628 17:24:46.389863 17458 solver.cpp:243] Iteration 2360, loss = 3.753
I0628 17:24:46.390007 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.49345 (* 1 = 3.49345 loss)
I0628 17:24:46.390031 17458 sgd_solver.cpp:138] Iteration 2360, lr = 0.0005
I0628 17:24:55.557029 17458 solver.cpp:243] Iteration 2370, loss = 3.86174
I0628 17:24:55.557054 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.84345 (* 1 = 4.84345 loss)
I0628 17:24:55.557080 17458 sgd_solver.cpp:138] Iteration 2370, lr = 0.0005
I0628 17:25:04.700047 17458 solver.cpp:243] Iteration 2380, loss = 4.30784
I0628 17:25:04.700071 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.84368 (* 1 = 3.84368 loss)
I0628 17:25:04.700098 17458 sgd_solver.cpp:138] Iteration 2380, lr = 0.0005
I0628 17:25:13.859067 17458 solver.cpp:243] Iteration 2390, loss = 4.08098
I0628 17:25:13.859093 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.19783 (* 1 = 4.19783 loss)
I0628 17:25:13.859119 17458 sgd_solver.cpp:138] Iteration 2390, lr = 0.0005
I0628 17:25:23.001224 17458 solver.cpp:243] Iteration 2400, loss = 4.31239
I0628 17:25:23.001417 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.19557 (* 1 = 5.19557 loss)
I0628 17:25:23.001426 17458 sgd_solver.cpp:138] Iteration 2400, lr = 0.0005
I0628 17:25:32.166688 17458 solver.cpp:243] Iteration 2410, loss = 4.34841
I0628 17:25:32.166712 17458 solver.cpp:259]     Train net output #0: mbox_loss = 9.97307 (* 1 = 9.97307 loss)
I0628 17:25:32.166738 17458 sgd_solver.cpp:138] Iteration 2410, lr = 0.0005
I0628 17:25:41.307706 17458 solver.cpp:243] Iteration 2420, loss = 3.25015
I0628 17:25:41.307729 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.84689 (* 1 = 2.84689 loss)
I0628 17:25:41.307755 17458 sgd_solver.cpp:138] Iteration 2420, lr = 0.0005
I0628 17:25:50.473042 17458 solver.cpp:243] Iteration 2430, loss = 3.72525
I0628 17:25:50.473065 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.90596 (* 1 = 3.90596 loss)
I0628 17:25:50.473073 17458 sgd_solver.cpp:138] Iteration 2430, lr = 0.0005
I0628 17:25:59.613835 17458 solver.cpp:243] Iteration 2440, loss = 4.86042
I0628 17:25:59.614020 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.03131 (* 1 = 5.03131 loss)
I0628 17:25:59.614068 17458 sgd_solver.cpp:138] Iteration 2440, lr = 0.0005
I0628 17:26:08.763236 17458 solver.cpp:243] Iteration 2450, loss = 4.43045
I0628 17:26:08.763262 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.96137 (* 1 = 4.96137 loss)
I0628 17:26:08.763268 17458 sgd_solver.cpp:138] Iteration 2450, lr = 0.0005
I0628 17:26:17.892029 17458 solver.cpp:243] Iteration 2460, loss = 3.78806
I0628 17:26:17.892053 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.8921 (* 1 = 2.8921 loss)
I0628 17:26:17.892078 17458 sgd_solver.cpp:138] Iteration 2460, lr = 0.0005
I0628 17:26:27.060329 17458 solver.cpp:243] Iteration 2470, loss = 3.93176
I0628 17:26:27.060353 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.24146 (* 1 = 2.24146 loss)
I0628 17:26:27.060379 17458 sgd_solver.cpp:138] Iteration 2470, lr = 0.0005
I0628 17:26:36.197496 17458 solver.cpp:243] Iteration 2480, loss = 3.90562
I0628 17:26:36.197652 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.28728 (* 1 = 2.28728 loss)
I0628 17:26:36.197682 17458 sgd_solver.cpp:138] Iteration 2480, lr = 0.0005
I0628 17:26:45.356235 17458 solver.cpp:243] Iteration 2490, loss = 3.78102
I0628 17:26:45.356258 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.47219 (* 1 = 4.47219 loss)
I0628 17:26:45.356284 17458 sgd_solver.cpp:138] Iteration 2490, lr = 0.0005
I0628 17:26:54.490895 17458 solver.cpp:243] Iteration 2500, loss = 4.81622
I0628 17:26:54.490918 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.25107 (* 1 = 5.25107 loss)
I0628 17:26:54.490943 17458 sgd_solver.cpp:138] Iteration 2500, lr = 0.0005
I0628 17:27:03.648197 17458 solver.cpp:243] Iteration 2510, loss = 4.13016
I0628 17:27:03.648222 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.27882 (* 1 = 5.27882 loss)
I0628 17:27:03.648248 17458 sgd_solver.cpp:138] Iteration 2510, lr = 0.0005
I0628 17:27:12.783085 17458 solver.cpp:243] Iteration 2520, loss = 3.6097
I0628 17:27:12.783228 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.02833 (* 1 = 5.02833 loss)
I0628 17:27:12.783254 17458 sgd_solver.cpp:138] Iteration 2520, lr = 0.0005
I0628 17:27:21.942114 17458 solver.cpp:243] Iteration 2530, loss = 4.09849
I0628 17:27:21.942140 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.98601 (* 1 = 6.98601 loss)
I0628 17:27:21.942165 17458 sgd_solver.cpp:138] Iteration 2530, lr = 0.0005
I0628 17:27:31.084828 17458 solver.cpp:243] Iteration 2540, loss = 4.11389
I0628 17:27:31.084851 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.94833 (* 1 = 3.94833 loss)
I0628 17:27:31.084903 17458 sgd_solver.cpp:138] Iteration 2540, lr = 0.0005
I0628 17:27:40.246398 17458 solver.cpp:243] Iteration 2550, loss = 2.95057
I0628 17:27:40.246421 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.55466 (* 1 = 3.55466 loss)
I0628 17:27:40.246448 17458 sgd_solver.cpp:138] Iteration 2550, lr = 0.0005
I0628 17:27:49.377811 17458 solver.cpp:243] Iteration 2560, loss = 3.89304
I0628 17:27:49.377995 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.20058 (* 1 = 4.20058 loss)
I0628 17:27:49.378003 17458 sgd_solver.cpp:138] Iteration 2560, lr = 0.0005
I0628 17:27:58.535611 17458 solver.cpp:243] Iteration 2570, loss = 3.89353
I0628 17:27:58.535635 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.69877 (* 1 = 4.69877 loss)
I0628 17:27:58.535660 17458 sgd_solver.cpp:138] Iteration 2570, lr = 0.0005
I0628 17:28:07.670969 17458 solver.cpp:243] Iteration 2580, loss = 3.36805
I0628 17:28:07.670991 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.68974 (* 1 = 1.68974 loss)
I0628 17:28:07.671017 17458 sgd_solver.cpp:138] Iteration 2580, lr = 0.0005
I0628 17:28:16.827071 17458 solver.cpp:243] Iteration 2590, loss = 3.67046
I0628 17:28:16.827095 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.90863 (* 1 = 3.90863 loss)
I0628 17:28:16.827121 17458 sgd_solver.cpp:138] Iteration 2590, lr = 0.0005
I0628 17:28:25.963871 17458 solver.cpp:243] Iteration 2600, loss = 3.81301
I0628 17:28:25.964094 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.17528 (* 1 = 5.17528 loss)
I0628 17:28:25.964103 17458 sgd_solver.cpp:138] Iteration 2600, lr = 0.0005
I0628 17:28:35.116923 17458 solver.cpp:243] Iteration 2610, loss = 3.7991
I0628 17:28:35.116948 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.14973 (* 1 = 2.14973 loss)
I0628 17:28:35.116955 17458 sgd_solver.cpp:138] Iteration 2610, lr = 0.0005
I0628 17:28:44.254699 17458 solver.cpp:243] Iteration 2620, loss = 3.62441
I0628 17:28:44.254724 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.49423 (* 1 = 2.49423 loss)
I0628 17:28:44.254750 17458 sgd_solver.cpp:138] Iteration 2620, lr = 0.0005
I0628 17:28:53.410101 17458 solver.cpp:243] Iteration 2630, loss = 4.45826
I0628 17:28:53.410126 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.59169 (* 1 = 4.59169 loss)
I0628 17:28:53.410152 17458 sgd_solver.cpp:138] Iteration 2630, lr = 0.0005
I0628 17:29:02.549369 17458 solver.cpp:243] Iteration 2640, loss = 4.68024
I0628 17:29:02.549544 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.15732 (* 1 = 5.15732 loss)
I0628 17:29:02.549552 17458 sgd_solver.cpp:138] Iteration 2640, lr = 0.0005
I0628 17:29:11.707080 17458 solver.cpp:243] Iteration 2650, loss = 3.43185
I0628 17:29:11.707106 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.0139 (* 1 = 5.0139 loss)
I0628 17:29:11.707132 17458 sgd_solver.cpp:138] Iteration 2650, lr = 0.0005
I0628 17:29:20.843048 17458 solver.cpp:243] Iteration 2660, loss = 4.3854
I0628 17:29:20.843072 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.06067 (* 1 = 3.06067 loss)
I0628 17:29:20.843098 17458 sgd_solver.cpp:138] Iteration 2660, lr = 0.0005
I0628 17:29:30.006171 17458 solver.cpp:243] Iteration 2670, loss = 3.4524
I0628 17:29:30.006197 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.08017 (* 1 = 3.08017 loss)
I0628 17:29:30.006223 17458 sgd_solver.cpp:138] Iteration 2670, lr = 0.0005
I0628 17:29:39.128139 17458 solver.cpp:243] Iteration 2680, loss = 4.04146
I0628 17:29:39.128314 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.30932 (* 1 = 4.30932 loss)
I0628 17:29:39.128322 17458 sgd_solver.cpp:138] Iteration 2680, lr = 0.0005
I0628 17:29:48.265467 17458 solver.cpp:243] Iteration 2690, loss = 3.93015
I0628 17:29:48.265492 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.5152 (* 1 = 4.5152 loss)
I0628 17:29:48.265517 17458 sgd_solver.cpp:138] Iteration 2690, lr = 0.0005
I0628 17:29:57.399945 17458 solver.cpp:243] Iteration 2700, loss = 4.13664
I0628 17:29:57.399969 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.007 (* 1 = 4.007 loss)
I0628 17:29:57.399997 17458 sgd_solver.cpp:138] Iteration 2700, lr = 0.0005
I0628 17:30:06.558290 17458 solver.cpp:243] Iteration 2710, loss = 4.06841
I0628 17:30:06.558313 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.44344 (* 1 = 4.44344 loss)
I0628 17:30:06.558339 17458 sgd_solver.cpp:138] Iteration 2710, lr = 0.0005
I0628 17:30:15.695235 17458 solver.cpp:243] Iteration 2720, loss = 4.0752
I0628 17:30:15.695389 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.14019 (* 1 = 3.14019 loss)
I0628 17:30:15.695399 17458 sgd_solver.cpp:138] Iteration 2720, lr = 0.0005
I0628 17:30:24.856633 17458 solver.cpp:243] Iteration 2730, loss = 4.06073
I0628 17:30:24.856658 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.36458 (* 1 = 6.36458 loss)
I0628 17:30:24.856683 17458 sgd_solver.cpp:138] Iteration 2730, lr = 0.0005
I0628 17:30:33.986811 17458 solver.cpp:243] Iteration 2740, loss = 4.36913
I0628 17:30:33.986836 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.84491 (* 1 = 4.84491 loss)
I0628 17:30:33.986862 17458 sgd_solver.cpp:138] Iteration 2740, lr = 0.0005
I0628 17:30:43.143410 17458 solver.cpp:243] Iteration 2750, loss = 3.44317
I0628 17:30:43.143435 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.2584 (* 1 = 3.2584 loss)
I0628 17:30:43.143460 17458 sgd_solver.cpp:138] Iteration 2750, lr = 0.0005
I0628 17:30:52.278820 17458 solver.cpp:243] Iteration 2760, loss = 4.45949
I0628 17:30:52.279052 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.63735 (* 1 = 4.63735 loss)
I0628 17:30:52.279062 17458 sgd_solver.cpp:138] Iteration 2760, lr = 0.0005
I0628 17:31:01.430536 17458 solver.cpp:243] Iteration 2770, loss = 3.45125
I0628 17:31:01.430562 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.76823 (* 1 = 2.76823 loss)
I0628 17:31:01.430569 17458 sgd_solver.cpp:138] Iteration 2770, lr = 0.0005
I0628 17:31:10.555819 17458 solver.cpp:243] Iteration 2780, loss = 3.85099
I0628 17:31:10.555841 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.84867 (* 1 = 2.84867 loss)
I0628 17:31:10.555867 17458 sgd_solver.cpp:138] Iteration 2780, lr = 0.0005
I0628 17:31:19.715929 17458 solver.cpp:243] Iteration 2790, loss = 3.99522
I0628 17:31:19.715951 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.51019 (* 1 = 1.51019 loss)
I0628 17:31:19.715977 17458 sgd_solver.cpp:138] Iteration 2790, lr = 0.0005
I0628 17:31:28.845324 17458 solver.cpp:243] Iteration 2800, loss = 3.77179
I0628 17:31:28.845474 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.36043 (* 1 = 2.36043 loss)
I0628 17:31:28.845499 17458 sgd_solver.cpp:138] Iteration 2800, lr = 0.0005
I0628 17:31:38.004407 17458 solver.cpp:243] Iteration 2810, loss = 3.49546
I0628 17:31:38.004433 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.99801 (* 1 = 3.99801 loss)
I0628 17:31:38.004458 17458 sgd_solver.cpp:138] Iteration 2810, lr = 0.0005
I0628 17:31:47.138339 17458 solver.cpp:243] Iteration 2820, loss = 4.20463
I0628 17:31:47.138363 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.58962 (* 1 = 4.58962 loss)
I0628 17:31:47.138389 17458 sgd_solver.cpp:138] Iteration 2820, lr = 0.0005
I0628 17:31:56.296115 17458 solver.cpp:243] Iteration 2830, loss = 4.35222
I0628 17:31:56.296140 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.20814 (* 1 = 5.20814 loss)
I0628 17:31:56.296166 17458 sgd_solver.cpp:138] Iteration 2830, lr = 0.0005
I0628 17:32:05.424741 17458 solver.cpp:243] Iteration 2840, loss = 3.38378
I0628 17:32:05.424883 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3847 (* 1 = 3.3847 loss)
I0628 17:32:05.424908 17458 sgd_solver.cpp:138] Iteration 2840, lr = 0.0005
I0628 17:32:14.558080 17458 solver.cpp:243] Iteration 2850, loss = 4.67099
I0628 17:32:14.558106 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.56364 (* 1 = 4.56364 loss)
I0628 17:32:14.558113 17458 sgd_solver.cpp:138] Iteration 2850, lr = 0.0005
I0628 17:32:23.681435 17458 solver.cpp:243] Iteration 2860, loss = 3.2167
I0628 17:32:23.681459 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.38668 (* 1 = 3.38668 loss)
I0628 17:32:23.681466 17458 sgd_solver.cpp:138] Iteration 2860, lr = 0.0005
I0628 17:32:32.846698 17458 solver.cpp:243] Iteration 2870, loss = 3.26767
I0628 17:32:32.846722 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.99564 (* 1 = 2.99564 loss)
I0628 17:32:32.846747 17458 sgd_solver.cpp:138] Iteration 2870, lr = 0.0005
I0628 17:32:41.983721 17458 solver.cpp:243] Iteration 2880, loss = 4.11522
I0628 17:32:41.983901 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.48515 (* 1 = 3.48515 loss)
I0628 17:32:41.983909 17458 sgd_solver.cpp:138] Iteration 2880, lr = 0.0005
I0628 17:32:51.143671 17458 solver.cpp:243] Iteration 2890, loss = 4.22402
I0628 17:32:51.143697 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.52902 (* 1 = 5.52902 loss)
I0628 17:32:51.143723 17458 sgd_solver.cpp:138] Iteration 2890, lr = 0.0005
I0628 17:33:00.275835 17458 solver.cpp:243] Iteration 2900, loss = 3.65186
I0628 17:33:00.275861 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.0153 (* 1 = 3.0153 loss)
I0628 17:33:00.275885 17458 sgd_solver.cpp:138] Iteration 2900, lr = 0.0005
I0628 17:33:09.430891 17458 solver.cpp:243] Iteration 2910, loss = 3.95211
I0628 17:33:09.430945 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25656 (* 1 = 3.25656 loss)
I0628 17:33:09.430971 17458 sgd_solver.cpp:138] Iteration 2910, lr = 0.0005
I0628 17:33:18.568966 17458 solver.cpp:243] Iteration 2920, loss = 4.10042
I0628 17:33:18.569108 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.53447 (* 1 = 2.53447 loss)
I0628 17:33:18.569130 17458 sgd_solver.cpp:138] Iteration 2920, lr = 0.0005
I0628 17:33:27.725147 17458 solver.cpp:243] Iteration 2930, loss = 3.1074
I0628 17:33:27.725172 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.68297 (* 1 = 2.68297 loss)
I0628 17:33:27.725178 17458 sgd_solver.cpp:138] Iteration 2930, lr = 0.0005
I0628 17:33:36.836233 17458 solver.cpp:243] Iteration 2940, loss = 4.05676
I0628 17:33:36.836256 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.21406 (* 1 = 4.21406 loss)
I0628 17:33:36.836282 17458 sgd_solver.cpp:138] Iteration 2940, lr = 0.0005
I0628 17:33:45.966224 17458 solver.cpp:243] Iteration 2950, loss = 4.00721
I0628 17:33:45.966249 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.55341 (* 1 = 3.55341 loss)
I0628 17:33:45.966274 17458 sgd_solver.cpp:138] Iteration 2950, lr = 0.0005
I0628 17:33:55.095084 17458 solver.cpp:243] Iteration 2960, loss = 3.96899
I0628 17:33:55.095274 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.7434 (* 1 = 3.7434 loss)
I0628 17:33:55.095296 17458 sgd_solver.cpp:138] Iteration 2960, lr = 0.0005
I0628 17:34:04.249961 17458 solver.cpp:243] Iteration 2970, loss = 3.31587
I0628 17:34:04.249985 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.08718 (* 1 = 2.08718 loss)
I0628 17:34:04.250010 17458 sgd_solver.cpp:138] Iteration 2970, lr = 0.0005
I0628 17:34:13.379920 17458 solver.cpp:243] Iteration 2980, loss = 4.46562
I0628 17:34:13.379943 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.68299 (* 1 = 3.68299 loss)
I0628 17:34:13.379968 17458 sgd_solver.cpp:138] Iteration 2980, lr = 0.0005
I0628 17:34:22.542734 17458 solver.cpp:243] Iteration 2990, loss = 3.5494
I0628 17:34:22.542759 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.61301 (* 1 = 2.61301 loss)
I0628 17:34:22.542784 17458 sgd_solver.cpp:138] Iteration 2990, lr = 0.0005
I0628 17:34:30.922125 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_3000.caffemodel
I0628 17:34:31.004050 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_3000.solverstate
I0628 17:34:31.036098 17458 solver.cpp:433] Iteration 3000, Testing net (#0)
I0628 17:34:31.036255 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 17:37:36.048702 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.248812
I0628 17:37:36.833165 17458 solver.cpp:243] Iteration 3000, loss = 3.18992
I0628 17:37:36.833190 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.93678 (* 1 = 4.93678 loss)
I0628 17:37:36.833197 17458 sgd_solver.cpp:47] MultiStep Status: Iteration 3000, step = 1
I0628 17:37:36.833201 17458 sgd_solver.cpp:138] Iteration 3000, lr = 0.00025
I0628 17:37:45.995965 17458 solver.cpp:243] Iteration 3010, loss = 2.90137
I0628 17:37:45.995987 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.18549 (* 1 = 4.18549 loss)
I0628 17:37:45.996013 17458 sgd_solver.cpp:138] Iteration 3010, lr = 0.00025
I0628 17:37:55.129554 17458 solver.cpp:243] Iteration 3020, loss = 3.41229
I0628 17:37:55.129577 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.41604 (* 1 = 3.41604 loss)
I0628 17:37:55.129602 17458 sgd_solver.cpp:138] Iteration 3020, lr = 0.00025
I0628 17:38:04.289283 17458 solver.cpp:243] Iteration 3030, loss = 4.44299
I0628 17:38:04.289331 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.6577 (* 1 = 4.6577 loss)
I0628 17:38:04.289340 17458 sgd_solver.cpp:138] Iteration 3030, lr = 0.00025
I0628 17:38:13.424046 17458 solver.cpp:243] Iteration 3040, loss = 4.66577
I0628 17:38:13.424187 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.35945 (* 1 = 4.35945 loss)
I0628 17:38:13.424196 17458 sgd_solver.cpp:138] Iteration 3040, lr = 0.00025
I0628 17:38:22.586791 17458 solver.cpp:243] Iteration 3050, loss = 4.04786
I0628 17:38:22.586817 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.97016 (* 1 = 3.97016 loss)
I0628 17:38:22.586841 17458 sgd_solver.cpp:138] Iteration 3050, lr = 0.00025
I0628 17:38:31.720510 17458 solver.cpp:243] Iteration 3060, loss = 3.53285
I0628 17:38:31.720533 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.10388 (* 1 = 3.10388 loss)
I0628 17:38:31.720558 17458 sgd_solver.cpp:138] Iteration 3060, lr = 0.00025
I0628 17:38:40.876813 17458 solver.cpp:243] Iteration 3070, loss = 3.46762
I0628 17:38:40.876838 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.88624 (* 1 = 3.88624 loss)
I0628 17:38:40.876845 17458 sgd_solver.cpp:138] Iteration 3070, lr = 0.00025
I0628 17:38:50.016757 17458 solver.cpp:243] Iteration 3080, loss = 4.731
I0628 17:38:50.016983 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.74617 (* 1 = 2.74617 loss)
I0628 17:38:50.016991 17458 sgd_solver.cpp:138] Iteration 3080, lr = 0.00025
I0628 17:38:59.174226 17458 solver.cpp:243] Iteration 3090, loss = 4.15018
I0628 17:38:59.174248 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.33912 (* 1 = 2.33912 loss)
I0628 17:38:59.174274 17458 sgd_solver.cpp:138] Iteration 3090, lr = 0.00025
I0628 17:39:08.314395 17458 solver.cpp:243] Iteration 3100, loss = 3.03295
I0628 17:39:08.314419 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.58323 (* 1 = 3.58323 loss)
I0628 17:39:08.314443 17458 sgd_solver.cpp:138] Iteration 3100, lr = 0.00025
I0628 17:39:17.476019 17458 solver.cpp:243] Iteration 3110, loss = 4.06162
I0628 17:39:17.476043 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.16903 (* 1 = 2.16903 loss)
I0628 17:39:17.476068 17458 sgd_solver.cpp:138] Iteration 3110, lr = 0.00025
I0628 17:39:26.608698 17458 solver.cpp:243] Iteration 3120, loss = 3.94829
I0628 17:39:26.608870 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.43556 (* 1 = 4.43556 loss)
I0628 17:39:26.608897 17458 sgd_solver.cpp:138] Iteration 3120, lr = 0.00025
I0628 17:39:35.758869 17458 solver.cpp:243] Iteration 3130, loss = 3.42435
I0628 17:39:35.758893 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.87566 (* 1 = 3.87566 loss)
I0628 17:39:35.758919 17458 sgd_solver.cpp:138] Iteration 3130, lr = 0.00025
I0628 17:39:44.893925 17458 solver.cpp:243] Iteration 3140, loss = 3.26683
I0628 17:39:44.893949 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.81757 (* 1 = 3.81757 loss)
I0628 17:39:44.893975 17458 sgd_solver.cpp:138] Iteration 3140, lr = 0.00025
I0628 17:39:54.057096 17458 solver.cpp:243] Iteration 3150, loss = 4.37653
I0628 17:39:54.057121 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.3744 (* 1 = 5.3744 loss)
I0628 17:39:54.057145 17458 sgd_solver.cpp:138] Iteration 3150, lr = 0.00025
I0628 17:40:03.193239 17458 solver.cpp:243] Iteration 3160, loss = 2.94691
I0628 17:40:03.193413 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.08168 (* 1 = 3.08168 loss)
I0628 17:40:03.193421 17458 sgd_solver.cpp:138] Iteration 3160, lr = 0.00025
I0628 17:40:12.348142 17458 solver.cpp:243] Iteration 3170, loss = 3.86852
I0628 17:40:12.348166 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.78571 (* 1 = 4.78571 loss)
I0628 17:40:12.348191 17458 sgd_solver.cpp:138] Iteration 3170, lr = 0.00025
I0628 17:40:21.483767 17458 solver.cpp:243] Iteration 3180, loss = 3.49341
I0628 17:40:21.483789 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.10158 (* 1 = 3.10158 loss)
I0628 17:40:21.483814 17458 sgd_solver.cpp:138] Iteration 3180, lr = 0.00025
I0628 17:40:30.638162 17458 solver.cpp:243] Iteration 3190, loss = 3.36918
I0628 17:40:30.638186 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.07597 (* 1 = 3.07597 loss)
I0628 17:40:30.638212 17458 sgd_solver.cpp:138] Iteration 3190, lr = 0.00025
I0628 17:40:39.770959 17458 solver.cpp:243] Iteration 3200, loss = 3.83096
I0628 17:40:39.771121 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.5536 (* 1 = 4.5536 loss)
I0628 17:40:39.771173 17458 sgd_solver.cpp:138] Iteration 3200, lr = 0.00025
I0628 17:40:48.934293 17458 solver.cpp:243] Iteration 3210, loss = 4.07624
I0628 17:40:48.934319 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.98856 (* 1 = 4.98856 loss)
I0628 17:40:48.934343 17458 sgd_solver.cpp:138] Iteration 3210, lr = 0.00025
I0628 17:40:58.066077 17458 solver.cpp:243] Iteration 3220, loss = 4.38774
I0628 17:40:58.066100 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.65724 (* 1 = 4.65724 loss)
I0628 17:40:58.066107 17458 sgd_solver.cpp:138] Iteration 3220, lr = 0.00025
I0628 17:41:07.228068 17458 solver.cpp:243] Iteration 3230, loss = 3.71252
I0628 17:41:07.228092 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.56279 (* 1 = 4.56279 loss)
I0628 17:41:07.228118 17458 sgd_solver.cpp:138] Iteration 3230, lr = 0.00025
I0628 17:41:16.371686 17458 solver.cpp:243] Iteration 3240, loss = 3.58192
I0628 17:41:16.371840 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.99442 (* 1 = 1.99442 loss)
I0628 17:41:16.371847 17458 sgd_solver.cpp:138] Iteration 3240, lr = 0.00025
I0628 17:41:25.532922 17458 solver.cpp:243] Iteration 3250, loss = 2.90853
I0628 17:41:25.532944 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.62854 (* 1 = 1.62854 loss)
I0628 17:41:25.532950 17458 sgd_solver.cpp:138] Iteration 3250, lr = 0.00025
I0628 17:41:34.668819 17458 solver.cpp:243] Iteration 3260, loss = 4.03116
I0628 17:41:34.668840 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.47246 (* 1 = 2.47246 loss)
I0628 17:41:34.668866 17458 sgd_solver.cpp:138] Iteration 3260, lr = 0.00025
I0628 17:41:43.834108 17458 solver.cpp:243] Iteration 3270, loss = 3.98098
I0628 17:41:43.834132 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.31616 (* 1 = 4.31616 loss)
I0628 17:41:43.834157 17458 sgd_solver.cpp:138] Iteration 3270, lr = 0.00025
I0628 17:41:52.968242 17458 solver.cpp:243] Iteration 3280, loss = 4.12967
I0628 17:41:52.968382 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.60668 (* 1 = 3.60668 loss)
I0628 17:41:52.968390 17458 sgd_solver.cpp:138] Iteration 3280, lr = 0.00025
I0628 17:42:02.128168 17458 solver.cpp:243] Iteration 3290, loss = 3.49412
I0628 17:42:02.128192 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.93179 (* 1 = 4.93179 loss)
I0628 17:42:02.128217 17458 sgd_solver.cpp:138] Iteration 3290, lr = 0.00025
I0628 17:42:11.271739 17458 solver.cpp:243] Iteration 3300, loss = 3.9183
I0628 17:42:11.271762 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.73373 (* 1 = 3.73373 loss)
I0628 17:42:11.271788 17458 sgd_solver.cpp:138] Iteration 3300, lr = 0.00025
I0628 17:42:20.436342 17458 solver.cpp:243] Iteration 3310, loss = 3.07005
I0628 17:42:20.436367 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.16813 (* 1 = 3.16813 loss)
I0628 17:42:20.436391 17458 sgd_solver.cpp:138] Iteration 3310, lr = 0.00025
I0628 17:42:29.577616 17458 solver.cpp:243] Iteration 3320, loss = 3.24648
I0628 17:42:29.577770 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.38767 (* 1 = 3.38767 loss)
I0628 17:42:29.577780 17458 sgd_solver.cpp:138] Iteration 3320, lr = 0.00025
I0628 17:42:38.737862 17458 solver.cpp:243] Iteration 3330, loss = 3.91649
I0628 17:42:38.737886 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.8665 (* 1 = 3.8665 loss)
I0628 17:42:38.737911 17458 sgd_solver.cpp:138] Iteration 3330, lr = 0.00025
I0628 17:42:47.874040 17458 solver.cpp:243] Iteration 3340, loss = 3.47366
I0628 17:42:47.874063 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.4257 (* 1 = 3.4257 loss)
I0628 17:42:47.874089 17458 sgd_solver.cpp:138] Iteration 3340, lr = 0.00025
I0628 17:42:57.018082 17458 solver.cpp:243] Iteration 3350, loss = 3.38856
I0628 17:42:57.018110 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.58461 (* 1 = 4.58461 loss)
I0628 17:42:57.018116 17458 sgd_solver.cpp:138] Iteration 3350, lr = 0.00025
I0628 17:43:06.142195 17458 solver.cpp:243] Iteration 3360, loss = 4.24711
I0628 17:43:06.142416 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.23836 (* 1 = 4.23836 loss)
I0628 17:43:06.142424 17458 sgd_solver.cpp:138] Iteration 3360, lr = 0.00025
I0628 17:43:15.307303 17458 solver.cpp:243] Iteration 3370, loss = 3.22355
I0628 17:43:15.307329 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.84654 (* 1 = 1.84654 loss)
I0628 17:43:15.307354 17458 sgd_solver.cpp:138] Iteration 3370, lr = 0.00025
I0628 17:43:24.439465 17458 solver.cpp:243] Iteration 3380, loss = 3.44483
I0628 17:43:24.439488 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.25599 (* 1 = 5.25599 loss)
I0628 17:43:24.439513 17458 sgd_solver.cpp:138] Iteration 3380, lr = 0.00025
I0628 17:43:33.601620 17458 solver.cpp:243] Iteration 3390, loss = 3.9027
I0628 17:43:33.601642 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.24738 (* 1 = 4.24738 loss)
I0628 17:43:33.601667 17458 sgd_solver.cpp:138] Iteration 3390, lr = 0.00025
I0628 17:43:42.737761 17458 solver.cpp:243] Iteration 3400, loss = 3.83164
I0628 17:43:42.737908 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.26498 (* 1 = 3.26498 loss)
I0628 17:43:42.737931 17458 sgd_solver.cpp:138] Iteration 3400, lr = 0.00025
I0628 17:43:51.898154 17458 solver.cpp:243] Iteration 3410, loss = 4.26045
I0628 17:43:51.898177 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.88006 (* 1 = 2.88006 loss)
I0628 17:43:51.898202 17458 sgd_solver.cpp:138] Iteration 3410, lr = 0.00025
I0628 17:44:01.025357 17458 solver.cpp:243] Iteration 3420, loss = 3.40404
I0628 17:44:01.025380 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.11558 (* 1 = 4.11558 loss)
I0628 17:44:01.025405 17458 sgd_solver.cpp:138] Iteration 3420, lr = 0.00025
I0628 17:44:10.172969 17458 solver.cpp:243] Iteration 3430, loss = 3.89392
I0628 17:44:10.172992 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.49398 (* 1 = 1.49398 loss)
I0628 17:44:10.173018 17458 sgd_solver.cpp:138] Iteration 3430, lr = 0.00025
I0628 17:44:19.312232 17458 solver.cpp:243] Iteration 3440, loss = 3.3613
I0628 17:44:19.312376 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.05025 (* 1 = 3.05025 loss)
I0628 17:44:19.312400 17458 sgd_solver.cpp:138] Iteration 3440, lr = 0.00025
I0628 17:44:28.478361 17458 solver.cpp:243] Iteration 3450, loss = 2.9635
I0628 17:44:28.478386 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.30355 (* 1 = 2.30355 loss)
I0628 17:44:28.478411 17458 sgd_solver.cpp:138] Iteration 3450, lr = 0.00025
I0628 17:44:37.614693 17458 solver.cpp:243] Iteration 3460, loss = 3.80109
I0628 17:44:37.614717 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25018 (* 1 = 3.25018 loss)
I0628 17:44:37.614742 17458 sgd_solver.cpp:138] Iteration 3460, lr = 0.00025
I0628 17:44:46.773417 17458 solver.cpp:243] Iteration 3470, loss = 4.17394
I0628 17:44:46.773442 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.35592 (* 1 = 4.35592 loss)
I0628 17:44:46.773468 17458 sgd_solver.cpp:138] Iteration 3470, lr = 0.00025
I0628 17:44:55.913051 17458 solver.cpp:243] Iteration 3480, loss = 3.60215
I0628 17:44:55.913192 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.49108 (* 1 = 3.49108 loss)
I0628 17:44:55.913213 17458 sgd_solver.cpp:138] Iteration 3480, lr = 0.00025
I0628 17:45:05.069370 17458 solver.cpp:243] Iteration 3490, loss = 4.07476
I0628 17:45:05.069394 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.87727 (* 1 = 4.87727 loss)
I0628 17:45:05.069420 17458 sgd_solver.cpp:138] Iteration 3490, lr = 0.00025
I0628 17:45:14.212054 17458 solver.cpp:243] Iteration 3500, loss = 3.22309
I0628 17:45:14.212078 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.73372 (* 1 = 4.73372 loss)
I0628 17:45:14.212105 17458 sgd_solver.cpp:138] Iteration 3500, lr = 0.00025
I0628 17:45:23.379004 17458 solver.cpp:243] Iteration 3510, loss = 3.08457
I0628 17:45:23.379029 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.81966 (* 1 = 2.81966 loss)
I0628 17:45:23.379055 17458 sgd_solver.cpp:138] Iteration 3510, lr = 0.00025
I0628 17:45:32.518980 17458 solver.cpp:243] Iteration 3520, loss = 4.08438
I0628 17:45:32.519150 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.53977 (* 1 = 4.53977 loss)
I0628 17:45:32.519176 17458 sgd_solver.cpp:138] Iteration 3520, lr = 0.00025
I0628 17:45:41.683274 17458 solver.cpp:243] Iteration 3530, loss = 4.15215
I0628 17:45:41.683296 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.56649 (* 1 = 4.56649 loss)
I0628 17:45:41.683321 17458 sgd_solver.cpp:138] Iteration 3530, lr = 0.00025
I0628 17:45:50.817771 17458 solver.cpp:243] Iteration 3540, loss = 4.19747
I0628 17:45:50.817795 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.3956 (* 1 = 2.3956 loss)
I0628 17:45:50.817819 17458 sgd_solver.cpp:138] Iteration 3540, lr = 0.00025
I0628 17:45:59.978799 17458 solver.cpp:243] Iteration 3550, loss = 3.34802
I0628 17:45:59.978824 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.812 (* 1 = 2.812 loss)
I0628 17:45:59.978849 17458 sgd_solver.cpp:138] Iteration 3550, lr = 0.00025
I0628 17:46:09.119026 17458 solver.cpp:243] Iteration 3560, loss = 4.10297
I0628 17:46:09.119194 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.38316 (* 1 = 6.38316 loss)
I0628 17:46:09.119202 17458 sgd_solver.cpp:138] Iteration 3560, lr = 0.00025
I0628 17:46:18.266755 17458 solver.cpp:243] Iteration 3570, loss = 3.16542
I0628 17:46:18.266779 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.688 (* 1 = 1.688 loss)
I0628 17:46:18.266805 17458 sgd_solver.cpp:138] Iteration 3570, lr = 0.00025
I0628 17:46:27.379951 17458 solver.cpp:243] Iteration 3580, loss = 3.71828
I0628 17:46:27.379974 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.89695 (* 1 = 6.89695 loss)
I0628 17:46:27.379999 17458 sgd_solver.cpp:138] Iteration 3580, lr = 0.00025
I0628 17:46:36.544849 17458 solver.cpp:243] Iteration 3590, loss = 3.81803
I0628 17:46:36.544872 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.61752 (* 1 = 7.61752 loss)
I0628 17:46:36.544898 17458 sgd_solver.cpp:138] Iteration 3590, lr = 0.00025
I0628 17:46:45.687163 17458 solver.cpp:243] Iteration 3600, loss = 3.61579
I0628 17:46:45.687330 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.80875 (* 1 = 2.80875 loss)
I0628 17:46:45.687340 17458 sgd_solver.cpp:138] Iteration 3600, lr = 0.00025
I0628 17:46:54.847045 17458 solver.cpp:243] Iteration 3610, loss = 3.40178
I0628 17:46:54.847070 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.09516 (* 1 = 3.09516 loss)
I0628 17:46:54.847095 17458 sgd_solver.cpp:138] Iteration 3610, lr = 0.00025
I0628 17:47:03.992345 17458 solver.cpp:243] Iteration 3620, loss = 4.44238
I0628 17:47:03.992369 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.56956 (* 1 = 4.56956 loss)
I0628 17:47:03.992377 17458 sgd_solver.cpp:138] Iteration 3620, lr = 0.00025
I0628 17:47:13.163918 17458 solver.cpp:243] Iteration 3630, loss = 3.57127
I0628 17:47:13.163942 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.66967 (* 1 = 3.66967 loss)
I0628 17:47:13.163969 17458 sgd_solver.cpp:138] Iteration 3630, lr = 0.00025
I0628 17:47:22.304425 17458 solver.cpp:243] Iteration 3640, loss = 3.52766
I0628 17:47:22.304579 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.18365 (* 1 = 5.18365 loss)
I0628 17:47:22.304587 17458 sgd_solver.cpp:138] Iteration 3640, lr = 0.00025
I0628 17:47:31.464419 17458 solver.cpp:243] Iteration 3650, loss = 3.81835
I0628 17:47:31.464444 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.9728 (* 1 = 5.9728 loss)
I0628 17:47:31.464470 17458 sgd_solver.cpp:138] Iteration 3650, lr = 0.00025
I0628 17:47:40.603005 17458 solver.cpp:243] Iteration 3660, loss = 3.7536
I0628 17:47:40.603029 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.51358 (* 1 = 2.51358 loss)
I0628 17:47:40.603055 17458 sgd_solver.cpp:138] Iteration 3660, lr = 0.00025
I0628 17:47:49.767747 17458 solver.cpp:243] Iteration 3670, loss = 3.83102
I0628 17:47:49.767772 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.90526 (* 1 = 2.90526 loss)
I0628 17:47:49.767779 17458 sgd_solver.cpp:138] Iteration 3670, lr = 0.00025
I0628 17:47:58.908733 17458 solver.cpp:243] Iteration 3680, loss = 3.97555
I0628 17:47:58.908958 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.72062 (* 1 = 3.72062 loss)
I0628 17:47:58.908969 17458 sgd_solver.cpp:138] Iteration 3680, lr = 0.00025
I0628 17:48:08.080013 17458 solver.cpp:243] Iteration 3690, loss = 3.8031
I0628 17:48:08.080039 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.49903 (* 1 = 4.49903 loss)
I0628 17:48:08.080063 17458 sgd_solver.cpp:138] Iteration 3690, lr = 0.00025
I0628 17:48:17.221690 17458 solver.cpp:243] Iteration 3700, loss = 4.27906
I0628 17:48:17.221714 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.63942 (* 1 = 2.63942 loss)
I0628 17:48:17.221740 17458 sgd_solver.cpp:138] Iteration 3700, lr = 0.00025
I0628 17:48:26.384469 17458 solver.cpp:243] Iteration 3710, loss = 3.34268
I0628 17:48:26.384495 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.89778 (* 1 = 1.89778 loss)
I0628 17:48:26.384501 17458 sgd_solver.cpp:138] Iteration 3710, lr = 0.00025
I0628 17:48:35.513299 17458 solver.cpp:243] Iteration 3720, loss = 3.80258
I0628 17:48:35.513485 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.32504 (* 1 = 4.32504 loss)
I0628 17:48:35.513494 17458 sgd_solver.cpp:138] Iteration 3720, lr = 0.00025
I0628 17:48:44.677253 17458 solver.cpp:243] Iteration 3730, loss = 3.59697
I0628 17:48:44.677278 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.78769 (* 1 = 1.78769 loss)
I0628 17:48:44.677284 17458 sgd_solver.cpp:138] Iteration 3730, lr = 0.00025
I0628 17:48:53.809587 17458 solver.cpp:243] Iteration 3740, loss = 2.93952
I0628 17:48:53.809610 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.39353 (* 1 = 4.39353 loss)
I0628 17:48:53.809636 17458 sgd_solver.cpp:138] Iteration 3740, lr = 0.00025
I0628 17:49:02.972884 17458 solver.cpp:243] Iteration 3750, loss = 3.84678
I0628 17:49:02.972908 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.98025 (* 1 = 2.98025 loss)
I0628 17:49:02.972934 17458 sgd_solver.cpp:138] Iteration 3750, lr = 0.00025
I0628 17:49:12.110330 17458 solver.cpp:243] Iteration 3760, loss = 3.42935
I0628 17:49:12.110466 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.61548 (* 1 = 2.61548 loss)
I0628 17:49:12.110476 17458 sgd_solver.cpp:138] Iteration 3760, lr = 0.00025
I0628 17:49:21.267870 17458 solver.cpp:243] Iteration 3770, loss = 3.67303
I0628 17:49:21.267895 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.63966 (* 1 = 2.63966 loss)
I0628 17:49:21.267921 17458 sgd_solver.cpp:138] Iteration 3770, lr = 0.00025
I0628 17:49:30.393834 17458 solver.cpp:243] Iteration 3780, loss = 3.81566
I0628 17:49:30.393857 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.57701 (* 1 = 3.57701 loss)
I0628 17:49:30.393882 17458 sgd_solver.cpp:138] Iteration 3780, lr = 0.00025
I0628 17:49:39.554937 17458 solver.cpp:243] Iteration 3790, loss = 4.14611
I0628 17:49:39.554961 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.51015 (* 1 = 3.51015 loss)
I0628 17:49:39.554987 17458 sgd_solver.cpp:138] Iteration 3790, lr = 0.00025
I0628 17:49:48.689033 17458 solver.cpp:243] Iteration 3800, loss = 3.46984
I0628 17:49:48.689208 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.67679 (* 1 = 4.67679 loss)
I0628 17:49:48.689216 17458 sgd_solver.cpp:138] Iteration 3800, lr = 0.00025
I0628 17:49:57.854009 17458 solver.cpp:243] Iteration 3810, loss = 4.1652
I0628 17:49:57.854033 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.99091 (* 1 = 3.99091 loss)
I0628 17:49:57.854040 17458 sgd_solver.cpp:138] Iteration 3810, lr = 0.00025
I0628 17:50:06.993870 17458 solver.cpp:243] Iteration 3820, loss = 2.91261
I0628 17:50:06.993892 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.43528 (* 1 = 3.43528 loss)
I0628 17:50:06.993917 17458 sgd_solver.cpp:138] Iteration 3820, lr = 0.00025
I0628 17:50:16.155046 17458 solver.cpp:243] Iteration 3830, loss = 3.30341
I0628 17:50:16.155071 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53489 (* 1 = 3.53489 loss)
I0628 17:50:16.155097 17458 sgd_solver.cpp:138] Iteration 3830, lr = 0.00025
I0628 17:50:25.290128 17458 solver.cpp:243] Iteration 3840, loss = 3.64877
I0628 17:50:25.290360 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.1028 (* 1 = 5.1028 loss)
I0628 17:50:25.290388 17458 sgd_solver.cpp:138] Iteration 3840, lr = 0.00025
I0628 17:50:34.452998 17458 solver.cpp:243] Iteration 3850, loss = 3.78969
I0628 17:50:34.453023 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.05744 (* 1 = 4.05744 loss)
I0628 17:50:34.453048 17458 sgd_solver.cpp:138] Iteration 3850, lr = 0.00025
I0628 17:50:43.590919 17458 solver.cpp:243] Iteration 3860, loss = 3.45507
I0628 17:50:43.590942 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.38813 (* 1 = 3.38813 loss)
I0628 17:50:43.590968 17458 sgd_solver.cpp:138] Iteration 3860, lr = 0.00025
I0628 17:50:52.749980 17458 solver.cpp:243] Iteration 3870, loss = 4.0797
I0628 17:50:52.750005 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.98516 (* 1 = 2.98516 loss)
I0628 17:50:52.750031 17458 sgd_solver.cpp:138] Iteration 3870, lr = 0.00025
I0628 17:51:01.891463 17458 solver.cpp:243] Iteration 3880, loss = 3.6697
I0628 17:51:01.891638 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.4096 (* 1 = 2.4096 loss)
I0628 17:51:01.891649 17458 sgd_solver.cpp:138] Iteration 3880, lr = 0.00025
I0628 17:51:11.045722 17458 solver.cpp:243] Iteration 3890, loss = 3.08294
I0628 17:51:11.045747 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.7451 (* 1 = 1.7451 loss)
I0628 17:51:11.045771 17458 sgd_solver.cpp:138] Iteration 3890, lr = 0.00025
I0628 17:51:20.175686 17458 solver.cpp:243] Iteration 3900, loss = 3.89999
I0628 17:51:20.175709 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.9975 (* 1 = 4.9975 loss)
I0628 17:51:20.175734 17458 sgd_solver.cpp:138] Iteration 3900, lr = 0.00025
I0628 17:51:29.334931 17458 solver.cpp:243] Iteration 3910, loss = 4.83464
I0628 17:51:29.334957 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.19075 (* 1 = 5.19075 loss)
I0628 17:51:29.334983 17458 sgd_solver.cpp:138] Iteration 3910, lr = 0.00025
I0628 17:51:38.460189 17458 solver.cpp:243] Iteration 3920, loss = 3.53232
I0628 17:51:38.460314 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.05648 (* 1 = 3.05648 loss)
I0628 17:51:38.460335 17458 sgd_solver.cpp:138] Iteration 3920, lr = 0.00025
I0628 17:51:47.612721 17458 solver.cpp:243] Iteration 3930, loss = 3.05985
I0628 17:51:47.612746 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.45413 (* 1 = 2.45413 loss)
I0628 17:51:47.612771 17458 sgd_solver.cpp:138] Iteration 3930, lr = 0.00025
I0628 17:51:56.757550 17458 solver.cpp:243] Iteration 3940, loss = 4.13466
I0628 17:51:56.757575 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.2908 (* 1 = 5.2908 loss)
I0628 17:51:56.757601 17458 sgd_solver.cpp:138] Iteration 3940, lr = 0.00025
I0628 17:52:05.924444 17458 solver.cpp:243] Iteration 3950, loss = 3.92201
I0628 17:52:05.924469 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.42426 (* 1 = 4.42426 loss)
I0628 17:52:05.924495 17458 sgd_solver.cpp:138] Iteration 3950, lr = 0.00025
I0628 17:52:15.073233 17458 solver.cpp:243] Iteration 3960, loss = 3.25068
I0628 17:52:15.073357 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.65427 (* 1 = 4.65427 loss)
I0628 17:52:15.073366 17458 sgd_solver.cpp:138] Iteration 3960, lr = 0.00025
I0628 17:52:24.236203 17458 solver.cpp:243] Iteration 3970, loss = 3.75496
I0628 17:52:24.236227 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.84422 (* 1 = 3.84422 loss)
I0628 17:52:24.236251 17458 sgd_solver.cpp:138] Iteration 3970, lr = 0.00025
I0628 17:52:33.376289 17458 solver.cpp:243] Iteration 3980, loss = 4.03341
I0628 17:52:33.376313 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.88747 (* 1 = 3.88747 loss)
I0628 17:52:33.376322 17458 sgd_solver.cpp:138] Iteration 3980, lr = 0.00025
I0628 17:52:42.528908 17458 solver.cpp:243] Iteration 3990, loss = 3.17312
I0628 17:52:42.528931 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.30424 (* 1 = 2.30424 loss)
I0628 17:52:42.528956 17458 sgd_solver.cpp:138] Iteration 3990, lr = 0.00025
I0628 17:52:50.912981 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_4000.caffemodel
I0628 17:52:50.993592 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_4000.solverstate
I0628 17:52:51.025159 17458 solver.cpp:433] Iteration 4000, Testing net (#0)
I0628 17:52:51.025264 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 17:55:56.039258 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.211471
I0628 17:55:56.825237 17458 solver.cpp:243] Iteration 4000, loss = 3.81216
I0628 17:55:56.825260 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.24598 (* 1 = 4.24598 loss)
I0628 17:55:56.825286 17458 sgd_solver.cpp:138] Iteration 4000, lr = 0.00025
I0628 17:56:05.982700 17458 solver.cpp:243] Iteration 4010, loss = 2.92035
I0628 17:56:05.982724 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.17616 (* 1 = 2.17616 loss)
I0628 17:56:05.982750 17458 sgd_solver.cpp:138] Iteration 4010, lr = 0.00025
I0628 17:56:15.126670 17458 solver.cpp:243] Iteration 4020, loss = 2.8149
I0628 17:56:15.126711 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.83002 (* 1 = 2.83002 loss)
I0628 17:56:15.126736 17458 sgd_solver.cpp:138] Iteration 4020, lr = 0.00025
I0628 17:56:24.294025 17458 solver.cpp:243] Iteration 4030, loss = 3.58317
I0628 17:56:24.294049 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.63187 (* 1 = 3.63187 loss)
I0628 17:56:24.294075 17458 sgd_solver.cpp:138] Iteration 4030, lr = 0.00025
I0628 17:56:33.437570 17458 solver.cpp:243] Iteration 4040, loss = 3.66817
I0628 17:56:33.437738 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.01513 (* 1 = 3.01513 loss)
I0628 17:56:33.437747 17458 sgd_solver.cpp:138] Iteration 4040, lr = 0.00025
I0628 17:56:42.599838 17458 solver.cpp:243] Iteration 4050, loss = 3.56748
I0628 17:56:42.599859 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.84384 (* 1 = 1.84384 loss)
I0628 17:56:42.599884 17458 sgd_solver.cpp:138] Iteration 4050, lr = 0.00025
I0628 17:56:51.739375 17458 solver.cpp:243] Iteration 4060, loss = 3.08915
I0628 17:56:51.739418 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.351 (* 1 = 5.351 loss)
I0628 17:56:51.739424 17458 sgd_solver.cpp:138] Iteration 4060, lr = 0.00025
I0628 17:57:00.907523 17458 solver.cpp:243] Iteration 4070, loss = 4.12275
I0628 17:57:00.907547 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.98042 (* 1 = 1.98042 loss)
I0628 17:57:00.907554 17458 sgd_solver.cpp:138] Iteration 4070, lr = 0.00025
I0628 17:57:10.048763 17458 solver.cpp:243] Iteration 4080, loss = 3.57463
I0628 17:57:10.048892 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.69476 (* 1 = 3.69476 loss)
I0628 17:57:10.048914 17458 sgd_solver.cpp:138] Iteration 4080, lr = 0.00025
I0628 17:57:19.209154 17458 solver.cpp:243] Iteration 4090, loss = 2.61117
I0628 17:57:19.209178 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.42349 (* 1 = 3.42349 loss)
I0628 17:57:19.209184 17458 sgd_solver.cpp:138] Iteration 4090, lr = 0.00025
I0628 17:57:28.336047 17458 solver.cpp:243] Iteration 4100, loss = 3.70186
I0628 17:57:28.336071 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.58431 (* 1 = 3.58431 loss)
I0628 17:57:28.336097 17458 sgd_solver.cpp:138] Iteration 4100, lr = 0.00025
I0628 17:57:37.490586 17458 solver.cpp:243] Iteration 4110, loss = 3.7938
I0628 17:57:37.490612 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.9577 (* 1 = 3.9577 loss)
I0628 17:57:37.490638 17458 sgd_solver.cpp:138] Iteration 4110, lr = 0.00025
I0628 17:57:46.625092 17458 solver.cpp:243] Iteration 4120, loss = 3.66643
I0628 17:57:46.625314 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.47288 (* 1 = 3.47288 loss)
I0628 17:57:46.625325 17458 sgd_solver.cpp:138] Iteration 4120, lr = 0.00025
I0628 17:57:55.780520 17458 solver.cpp:243] Iteration 4130, loss = 4.61702
I0628 17:57:55.780544 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.04421 (* 1 = 5.04421 loss)
I0628 17:57:55.780570 17458 sgd_solver.cpp:138] Iteration 4130, lr = 0.00025
I0628 17:58:04.917840 17458 solver.cpp:243] Iteration 4140, loss = 3.10304
I0628 17:58:04.917863 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.0716 (* 1 = 2.0716 loss)
I0628 17:58:04.917889 17458 sgd_solver.cpp:138] Iteration 4140, lr = 0.00025
I0628 17:58:14.081260 17458 solver.cpp:243] Iteration 4150, loss = 3.0667
I0628 17:58:14.081285 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.16265 (* 1 = 2.16265 loss)
I0628 17:58:14.081315 17458 sgd_solver.cpp:138] Iteration 4150, lr = 0.00025
I0628 17:58:23.218070 17458 solver.cpp:243] Iteration 4160, loss = 3.06214
I0628 17:58:23.218217 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.8562 (* 1 = 1.8562 loss)
I0628 17:58:23.218225 17458 sgd_solver.cpp:138] Iteration 4160, lr = 0.00025
I0628 17:58:32.380002 17458 solver.cpp:243] Iteration 4170, loss = 3.92183
I0628 17:58:32.380028 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.92451 (* 1 = 4.92451 loss)
I0628 17:58:32.380053 17458 sgd_solver.cpp:138] Iteration 4170, lr = 0.00025
I0628 17:58:41.515733 17458 solver.cpp:243] Iteration 4180, loss = 3.75226
I0628 17:58:41.515758 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.18008 (* 1 = 4.18008 loss)
I0628 17:58:41.515764 17458 sgd_solver.cpp:138] Iteration 4180, lr = 0.00025
I0628 17:58:50.672585 17458 solver.cpp:243] Iteration 4190, loss = 3.1443
I0628 17:58:50.672608 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.75135 (* 1 = 2.75135 loss)
I0628 17:58:50.672634 17458 sgd_solver.cpp:138] Iteration 4190, lr = 0.00025
I0628 17:58:59.808298 17458 solver.cpp:243] Iteration 4200, loss = 3.60485
I0628 17:58:59.808421 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.85908 (* 1 = 2.85908 loss)
I0628 17:58:59.808429 17458 sgd_solver.cpp:138] Iteration 4200, lr = 0.00025
I0628 17:59:08.975186 17458 solver.cpp:243] Iteration 4210, loss = 3.23029
I0628 17:59:08.975210 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.42926 (* 1 = 3.42926 loss)
I0628 17:59:08.975235 17458 sgd_solver.cpp:138] Iteration 4210, lr = 0.00025
I0628 17:59:18.105494 17458 solver.cpp:243] Iteration 4220, loss = 3.20289
I0628 17:59:18.105517 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.42728 (* 1 = 2.42728 loss)
I0628 17:59:18.105542 17458 sgd_solver.cpp:138] Iteration 4220, lr = 0.00025
I0628 17:59:27.252131 17458 solver.cpp:243] Iteration 4230, loss = 4.61246
I0628 17:59:27.252156 17458 solver.cpp:259]     Train net output #0: mbox_loss = 8.20854 (* 1 = 8.20854 loss)
I0628 17:59:27.252182 17458 sgd_solver.cpp:138] Iteration 4230, lr = 0.00025
I0628 17:59:36.386808 17458 solver.cpp:243] Iteration 4240, loss = 3.57555
I0628 17:59:36.386960 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.84711 (* 1 = 6.84711 loss)
I0628 17:59:36.386970 17458 sgd_solver.cpp:138] Iteration 4240, lr = 0.00025
I0628 17:59:45.542348 17458 solver.cpp:243] Iteration 4250, loss = 2.94823
I0628 17:59:45.542373 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.96484 (* 1 = 1.96484 loss)
I0628 17:59:45.542398 17458 sgd_solver.cpp:138] Iteration 4250, lr = 0.00025
I0628 17:59:54.677904 17458 solver.cpp:243] Iteration 4260, loss = 3.80856
I0628 17:59:54.677928 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.58978 (* 1 = 2.58978 loss)
I0628 17:59:54.677954 17458 sgd_solver.cpp:138] Iteration 4260, lr = 0.00025
I0628 18:00:03.840020 17458 solver.cpp:243] Iteration 4270, loss = 3.33687
I0628 18:00:03.840044 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.60668 (* 1 = 5.60668 loss)
I0628 18:00:03.840070 17458 sgd_solver.cpp:138] Iteration 4270, lr = 0.00025
I0628 18:00:12.976469 17458 solver.cpp:243] Iteration 4280, loss = 3.81182
I0628 18:00:12.976621 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.56943 (* 1 = 5.56943 loss)
I0628 18:00:12.976632 17458 sgd_solver.cpp:138] Iteration 4280, lr = 0.00025
I0628 18:00:22.138725 17458 solver.cpp:243] Iteration 4290, loss = 3.93913
I0628 18:00:22.138749 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.09359 (* 1 = 5.09359 loss)
I0628 18:00:22.138775 17458 sgd_solver.cpp:138] Iteration 4290, lr = 0.00025
I0628 18:00:31.276981 17458 solver.cpp:243] Iteration 4300, loss = 3.69906
I0628 18:00:31.277004 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.20151 (* 1 = 3.20151 loss)
I0628 18:00:31.277030 17458 sgd_solver.cpp:138] Iteration 4300, lr = 0.00025
I0628 18:00:40.423172 17458 solver.cpp:243] Iteration 4310, loss = 3.38222
I0628 18:00:40.423197 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.57793 (* 1 = 3.57793 loss)
I0628 18:00:40.423223 17458 sgd_solver.cpp:138] Iteration 4310, lr = 0.00025
I0628 18:00:49.537444 17458 solver.cpp:243] Iteration 4320, loss = 3.40401
I0628 18:00:49.537621 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.88031 (* 1 = 3.88031 loss)
I0628 18:00:49.537631 17458 sgd_solver.cpp:138] Iteration 4320, lr = 0.00025
I0628 18:00:58.706940 17458 solver.cpp:243] Iteration 4330, loss = 3.49099
I0628 18:00:58.706965 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.2623 (* 1 = 4.2623 loss)
I0628 18:00:58.706990 17458 sgd_solver.cpp:138] Iteration 4330, lr = 0.00025
I0628 18:01:07.846218 17458 solver.cpp:243] Iteration 4340, loss = 3.82532
I0628 18:01:07.846241 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.38392 (* 1 = 3.38392 loss)
I0628 18:01:07.846267 17458 sgd_solver.cpp:138] Iteration 4340, lr = 0.00025
I0628 18:01:17.007156 17458 solver.cpp:243] Iteration 4350, loss = 3.47232
I0628 18:01:17.007179 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.747 (* 1 = 3.747 loss)
I0628 18:01:17.007205 17458 sgd_solver.cpp:138] Iteration 4350, lr = 0.00025
I0628 18:01:26.146920 17458 solver.cpp:243] Iteration 4360, loss = 4.31364
I0628 18:01:26.147055 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.80877 (* 1 = 2.80877 loss)
I0628 18:01:26.147063 17458 sgd_solver.cpp:138] Iteration 4360, lr = 0.00025
I0628 18:01:35.293680 17458 solver.cpp:243] Iteration 4370, loss = 3.34138
I0628 18:01:35.293705 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.79289 (* 1 = 2.79289 loss)
I0628 18:01:35.293730 17458 sgd_solver.cpp:138] Iteration 4370, lr = 0.00025
I0628 18:01:44.433523 17458 solver.cpp:243] Iteration 4380, loss = 3.52515
I0628 18:01:44.433547 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.87036 (* 1 = 3.87036 loss)
I0628 18:01:44.433573 17458 sgd_solver.cpp:138] Iteration 4380, lr = 0.00025
I0628 18:01:53.601158 17458 solver.cpp:243] Iteration 4390, loss = 3.31588
I0628 18:01:53.601182 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.72717 (* 1 = 1.72717 loss)
I0628 18:01:53.601207 17458 sgd_solver.cpp:138] Iteration 4390, lr = 0.00025
I0628 18:02:02.742197 17458 solver.cpp:243] Iteration 4400, loss = 3.26326
I0628 18:02:02.742342 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.63988 (* 1 = 3.63988 loss)
I0628 18:02:02.742367 17458 sgd_solver.cpp:138] Iteration 4400, lr = 0.00025
I0628 18:02:11.909626 17458 solver.cpp:243] Iteration 4410, loss = 2.99851
I0628 18:02:11.909649 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.77014 (* 1 = 2.77014 loss)
I0628 18:02:11.909657 17458 sgd_solver.cpp:138] Iteration 4410, lr = 0.00025
I0628 18:02:21.046677 17458 solver.cpp:243] Iteration 4420, loss = 4.1075
I0628 18:02:21.046701 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.48365 (* 1 = 3.48365 loss)
I0628 18:02:21.046727 17458 sgd_solver.cpp:138] Iteration 4420, lr = 0.00025
I0628 18:02:30.202440 17458 solver.cpp:243] Iteration 4430, loss = 3.39576
I0628 18:02:30.202464 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25588 (* 1 = 3.25588 loss)
I0628 18:02:30.202520 17458 sgd_solver.cpp:138] Iteration 4430, lr = 0.00025
I0628 18:02:39.338547 17458 solver.cpp:243] Iteration 4440, loss = 3.4724
I0628 18:02:39.338752 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.69294 (* 1 = 3.69294 loss)
I0628 18:02:39.338764 17458 sgd_solver.cpp:138] Iteration 4440, lr = 0.00025
I0628 18:02:48.490376 17458 solver.cpp:243] Iteration 4450, loss = 4.46749
I0628 18:02:48.490401 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.61882 (* 1 = 7.61882 loss)
I0628 18:02:48.490427 17458 sgd_solver.cpp:138] Iteration 4450, lr = 0.00025
I0628 18:02:57.609544 17458 solver.cpp:243] Iteration 4460, loss = 3.43711
I0628 18:02:57.609567 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.87656 (* 1 = 2.87656 loss)
I0628 18:02:57.609593 17458 sgd_solver.cpp:138] Iteration 4460, lr = 0.00025
I0628 18:03:06.780411 17458 solver.cpp:243] Iteration 4470, loss = 3.41831
I0628 18:03:06.780433 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.32534 (* 1 = 3.32534 loss)
I0628 18:03:06.780459 17458 sgd_solver.cpp:138] Iteration 4470, lr = 0.00025
I0628 18:03:15.917744 17458 solver.cpp:243] Iteration 4480, loss = 3.93417
I0628 18:03:15.917886 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.65077 (* 1 = 3.65077 loss)
I0628 18:03:15.917894 17458 sgd_solver.cpp:138] Iteration 4480, lr = 0.00025
I0628 18:03:25.083617 17458 solver.cpp:243] Iteration 4490, loss = 3.69027
I0628 18:03:25.083642 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.94964 (* 1 = 4.94964 loss)
I0628 18:03:25.083667 17458 sgd_solver.cpp:138] Iteration 4490, lr = 0.00025
I0628 18:03:34.224014 17458 solver.cpp:243] Iteration 4500, loss = 3.30832
I0628 18:03:34.224037 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.70125 (* 1 = 4.70125 loss)
I0628 18:03:34.224062 17458 sgd_solver.cpp:138] Iteration 4500, lr = 0.00025
I0628 18:03:43.384325 17458 solver.cpp:243] Iteration 4510, loss = 3.26858
I0628 18:03:43.384348 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.80394 (* 1 = 2.80394 loss)
I0628 18:03:43.384374 17458 sgd_solver.cpp:138] Iteration 4510, lr = 0.00025
I0628 18:03:52.529726 17458 solver.cpp:243] Iteration 4520, loss = 3.87256
I0628 18:03:52.529870 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.23581 (* 1 = 2.23581 loss)
I0628 18:03:52.529880 17458 sgd_solver.cpp:138] Iteration 4520, lr = 0.00025
I0628 18:04:01.671756 17458 solver.cpp:243] Iteration 4530, loss = 3.11164
I0628 18:04:01.671779 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.02865 (* 1 = 2.02865 loss)
I0628 18:04:01.671787 17458 sgd_solver.cpp:138] Iteration 4530, lr = 0.00025
I0628 18:04:10.787698 17458 solver.cpp:243] Iteration 4540, loss = 3.80324
I0628 18:04:10.787725 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.08542 (* 1 = 3.08542 loss)
I0628 18:04:10.787765 17458 sgd_solver.cpp:138] Iteration 4540, lr = 0.00025
I0628 18:04:19.940490 17458 solver.cpp:243] Iteration 4550, loss = 4.25864
I0628 18:04:19.940513 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.28898 (* 1 = 5.28898 loss)
I0628 18:04:19.940538 17458 sgd_solver.cpp:138] Iteration 4550, lr = 0.00025
I0628 18:04:29.064718 17458 solver.cpp:243] Iteration 4560, loss = 3.7093
I0628 18:04:29.064867 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.43372 (* 1 = 3.43372 loss)
I0628 18:04:29.064875 17458 sgd_solver.cpp:138] Iteration 4560, lr = 0.00025
I0628 18:04:38.216491 17458 solver.cpp:243] Iteration 4570, loss = 3.28632
I0628 18:04:38.216514 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.12829 (* 1 = 5.12829 loss)
I0628 18:04:38.216540 17458 sgd_solver.cpp:138] Iteration 4570, lr = 0.00025
I0628 18:04:47.343246 17458 solver.cpp:243] Iteration 4580, loss = 3.9997
I0628 18:04:47.343268 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.33916 (* 1 = 4.33916 loss)
I0628 18:04:47.343299 17458 sgd_solver.cpp:138] Iteration 4580, lr = 0.00025
I0628 18:04:56.504518 17458 solver.cpp:243] Iteration 4590, loss = 3.13245
I0628 18:04:56.504542 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.54828 (* 1 = 4.54828 loss)
I0628 18:04:56.504549 17458 sgd_solver.cpp:138] Iteration 4590, lr = 0.00025
I0628 18:05:05.648026 17458 solver.cpp:243] Iteration 4600, loss = 3.26538
I0628 18:05:05.648262 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.70943 (* 1 = 3.70943 loss)
I0628 18:05:05.648272 17458 sgd_solver.cpp:138] Iteration 4600, lr = 0.00025
I0628 18:05:14.807171 17458 solver.cpp:243] Iteration 4610, loss = 2.82004
I0628 18:05:14.807195 17458 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0628 18:05:14.807224 17458 sgd_solver.cpp:138] Iteration 4610, lr = 0.00025
I0628 18:05:23.951193 17458 solver.cpp:243] Iteration 4620, loss = 3.93159
I0628 18:05:23.951229 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.50969 (* 1 = 3.50969 loss)
I0628 18:05:23.951254 17458 sgd_solver.cpp:138] Iteration 4620, lr = 0.00025
I0628 18:05:33.115236 17458 solver.cpp:243] Iteration 4630, loss = 3.28158
I0628 18:05:33.115260 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.25652 (* 1 = 2.25652 loss)
I0628 18:05:33.115286 17458 sgd_solver.cpp:138] Iteration 4630, lr = 0.00025
I0628 18:05:42.251410 17458 solver.cpp:243] Iteration 4640, loss = 4.01167
I0628 18:05:42.251564 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.44791 (* 1 = 5.44791 loss)
I0628 18:05:42.251590 17458 sgd_solver.cpp:138] Iteration 4640, lr = 0.00025
I0628 18:05:51.416079 17458 solver.cpp:243] Iteration 4650, loss = 3.11732
I0628 18:05:51.416101 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.3914 (* 1 = 4.3914 loss)
I0628 18:05:51.416127 17458 sgd_solver.cpp:138] Iteration 4650, lr = 0.00025
I0628 18:06:00.560041 17458 solver.cpp:243] Iteration 4660, loss = 3.3428
I0628 18:06:00.560065 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.36393 (* 1 = 3.36393 loss)
I0628 18:06:00.560091 17458 sgd_solver.cpp:138] Iteration 4660, lr = 0.00025
I0628 18:06:09.721871 17458 solver.cpp:243] Iteration 4670, loss = 3.67951
I0628 18:06:09.721896 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.7128 (* 1 = 2.7128 loss)
I0628 18:06:09.721921 17458 sgd_solver.cpp:138] Iteration 4670, lr = 0.00025
I0628 18:06:18.844403 17458 solver.cpp:243] Iteration 4680, loss = 3.87575
I0628 18:06:18.844502 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.96999 (* 1 = 3.96999 loss)
I0628 18:06:18.844511 17458 sgd_solver.cpp:138] Iteration 4680, lr = 0.00025
I0628 18:06:27.981590 17458 solver.cpp:243] Iteration 4690, loss = 4.16981
I0628 18:06:27.981614 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.5383 (* 1 = 2.5383 loss)
I0628 18:06:27.981639 17458 sgd_solver.cpp:138] Iteration 4690, lr = 0.00025
I0628 18:06:37.119478 17458 solver.cpp:243] Iteration 4700, loss = 2.8864
I0628 18:06:37.119501 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.14167 (* 1 = 3.14167 loss)
I0628 18:06:37.119526 17458 sgd_solver.cpp:138] Iteration 4700, lr = 0.00025
I0628 18:06:46.285033 17458 solver.cpp:243] Iteration 4710, loss = 3.45397
I0628 18:06:46.285056 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.38452 (* 1 = 1.38452 loss)
I0628 18:06:46.285081 17458 sgd_solver.cpp:138] Iteration 4710, lr = 0.00025
I0628 18:06:55.428957 17458 solver.cpp:243] Iteration 4720, loss = 3.31136
I0628 18:06:55.429101 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.49336 (* 1 = 2.49336 loss)
I0628 18:06:55.429126 17458 sgd_solver.cpp:138] Iteration 4720, lr = 0.00025
I0628 18:07:04.589726 17458 solver.cpp:243] Iteration 4730, loss = 3.42015
I0628 18:07:04.589751 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.62576 (* 1 = 2.62576 loss)
I0628 18:07:04.589776 17458 sgd_solver.cpp:138] Iteration 4730, lr = 0.00025
I0628 18:07:13.727471 17458 solver.cpp:243] Iteration 4740, loss = 3.51778
I0628 18:07:13.727495 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.04039 (* 1 = 4.04039 loss)
I0628 18:07:13.727521 17458 sgd_solver.cpp:138] Iteration 4740, lr = 0.00025
I0628 18:07:22.884745 17458 solver.cpp:243] Iteration 4750, loss = 3.77385
I0628 18:07:22.884770 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.10873 (* 1 = 5.10873 loss)
I0628 18:07:22.884795 17458 sgd_solver.cpp:138] Iteration 4750, lr = 0.00025
I0628 18:07:32.016894 17458 solver.cpp:243] Iteration 4760, loss = 2.99874
I0628 18:07:32.017084 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.33593 (* 1 = 2.33593 loss)
I0628 18:07:32.017123 17458 sgd_solver.cpp:138] Iteration 4760, lr = 0.00025
I0628 18:07:41.172279 17458 solver.cpp:243] Iteration 4770, loss = 4.42298
I0628 18:07:41.172304 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.05584 (* 1 = 6.05584 loss)
I0628 18:07:41.172329 17458 sgd_solver.cpp:138] Iteration 4770, lr = 0.00025
I0628 18:07:50.308621 17458 solver.cpp:243] Iteration 4780, loss = 2.85451
I0628 18:07:50.308645 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.44278 (* 1 = 3.44278 loss)
I0628 18:07:50.308670 17458 sgd_solver.cpp:138] Iteration 4780, lr = 0.00025
I0628 18:07:59.466970 17458 solver.cpp:243] Iteration 4790, loss = 2.9821
I0628 18:07:59.466995 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.84964 (* 1 = 2.84964 loss)
I0628 18:07:59.467020 17458 sgd_solver.cpp:138] Iteration 4790, lr = 0.00025
I0628 18:08:08.605509 17458 solver.cpp:243] Iteration 4800, loss = 3.25555
I0628 18:08:08.605669 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.86192 (* 1 = 2.86192 loss)
I0628 18:08:08.605677 17458 sgd_solver.cpp:138] Iteration 4800, lr = 0.00025
I0628 18:08:17.768065 17458 solver.cpp:243] Iteration 4810, loss = 3.64811
I0628 18:08:17.768090 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.02514 (* 1 = 5.02514 loss)
I0628 18:08:17.768115 17458 sgd_solver.cpp:138] Iteration 4810, lr = 0.00025
I0628 18:08:26.897047 17458 solver.cpp:243] Iteration 4820, loss = 3.41157
I0628 18:08:26.897070 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.65206 (* 1 = 2.65206 loss)
I0628 18:08:26.897096 17458 sgd_solver.cpp:138] Iteration 4820, lr = 0.00025
I0628 18:08:36.054425 17458 solver.cpp:243] Iteration 4830, loss = 3.67276
I0628 18:08:36.054450 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.503 (* 1 = 3.503 loss)
I0628 18:08:36.054476 17458 sgd_solver.cpp:138] Iteration 4830, lr = 0.00025
I0628 18:08:45.193531 17458 solver.cpp:243] Iteration 4840, loss = 3.23613
I0628 18:08:45.193661 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.84389 (* 1 = 2.84389 loss)
I0628 18:08:45.193686 17458 sgd_solver.cpp:138] Iteration 4840, lr = 0.00025
I0628 18:08:54.348610 17458 solver.cpp:243] Iteration 4850, loss = 3.32046
I0628 18:08:54.348634 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.73348 (* 1 = 1.73348 loss)
I0628 18:08:54.348659 17458 sgd_solver.cpp:138] Iteration 4850, lr = 0.00025
I0628 18:09:03.484555 17458 solver.cpp:243] Iteration 4860, loss = 3.78741
I0628 18:09:03.484576 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.54563 (* 1 = 3.54563 loss)
I0628 18:09:03.484583 17458 sgd_solver.cpp:138] Iteration 4860, lr = 0.00025
I0628 18:09:12.643347 17458 solver.cpp:243] Iteration 4870, loss = 3.69945
I0628 18:09:12.643371 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.40845 (* 1 = 4.40845 loss)
I0628 18:09:12.643396 17458 sgd_solver.cpp:138] Iteration 4870, lr = 0.00025
I0628 18:09:21.774520 17458 solver.cpp:243] Iteration 4880, loss = 3.3463
I0628 18:09:21.774680 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53051 (* 1 = 3.53051 loss)
I0628 18:09:21.774689 17458 sgd_solver.cpp:138] Iteration 4880, lr = 0.00025
I0628 18:09:30.927664 17458 solver.cpp:243] Iteration 4890, loss = 3.34716
I0628 18:09:30.927686 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.99658 (* 1 = 2.99658 loss)
I0628 18:09:30.927712 17458 sgd_solver.cpp:138] Iteration 4890, lr = 0.00025
I0628 18:09:40.062029 17458 solver.cpp:243] Iteration 4900, loss = 3.84376
I0628 18:09:40.062053 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.66175 (* 1 = 3.66175 loss)
I0628 18:09:40.062079 17458 sgd_solver.cpp:138] Iteration 4900, lr = 0.00025
I0628 18:09:49.219081 17458 solver.cpp:243] Iteration 4910, loss = 3.13132
I0628 18:09:49.219106 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.79282 (* 1 = 1.79282 loss)
I0628 18:09:49.219131 17458 sgd_solver.cpp:138] Iteration 4910, lr = 0.00025
I0628 18:09:58.354220 17458 solver.cpp:243] Iteration 4920, loss = 2.87654
I0628 18:09:58.354436 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.05251 (* 1 = 3.05251 loss)
I0628 18:09:58.354465 17458 sgd_solver.cpp:138] Iteration 4920, lr = 0.00025
I0628 18:10:07.513697 17458 solver.cpp:243] Iteration 4930, loss = 3.21498
I0628 18:10:07.513721 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.3418 (* 1 = 4.3418 loss)
I0628 18:10:07.513746 17458 sgd_solver.cpp:138] Iteration 4930, lr = 0.00025
I0628 18:10:16.649756 17458 solver.cpp:243] Iteration 4940, loss = 3.74044
I0628 18:10:16.649780 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.16057 (* 1 = 4.16057 loss)
I0628 18:10:16.649804 17458 sgd_solver.cpp:138] Iteration 4940, lr = 0.00025
I0628 18:10:25.804828 17458 solver.cpp:243] Iteration 4950, loss = 3.62912
I0628 18:10:25.804852 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.86333 (* 1 = 3.86333 loss)
I0628 18:10:25.804877 17458 sgd_solver.cpp:138] Iteration 4950, lr = 0.00025
I0628 18:10:34.939698 17458 solver.cpp:243] Iteration 4960, loss = 3.70081
I0628 18:10:34.939844 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.84013 (* 1 = 4.84013 loss)
I0628 18:10:34.939854 17458 sgd_solver.cpp:138] Iteration 4960, lr = 0.00025
I0628 18:10:44.098583 17458 solver.cpp:243] Iteration 4970, loss = 3.12389
I0628 18:10:44.098609 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.8864 (* 1 = 2.8864 loss)
I0628 18:10:44.098634 17458 sgd_solver.cpp:138] Iteration 4970, lr = 0.00025
I0628 18:10:53.237577 17458 solver.cpp:243] Iteration 4980, loss = 3.50184
I0628 18:10:53.237601 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.83265 (* 1 = 3.83265 loss)
I0628 18:10:53.237625 17458 sgd_solver.cpp:138] Iteration 4980, lr = 0.00025
I0628 18:11:02.399132 17458 solver.cpp:243] Iteration 4990, loss = 3.55654
I0628 18:11:02.399156 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.77567 (* 1 = 1.77567 loss)
I0628 18:11:02.399183 17458 sgd_solver.cpp:138] Iteration 4990, lr = 0.00025
I0628 18:11:10.782245 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_5000.caffemodel
I0628 18:11:10.862571 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_5000.solverstate
I0628 18:11:10.894496 17458 solver.cpp:433] Iteration 5000, Testing net (#0)
I0628 18:11:10.894618 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 18:14:15.770442 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.260697
I0628 18:14:16.558722 17458 solver.cpp:243] Iteration 5000, loss = 3.6364
I0628 18:14:16.558746 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.14721 (* 1 = 2.14721 loss)
I0628 18:14:16.558754 17458 sgd_solver.cpp:138] Iteration 5000, lr = 0.00025
I0628 18:14:25.701040 17458 solver.cpp:243] Iteration 5010, loss = 3.65635
I0628 18:14:25.701064 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.70799 (* 1 = 1.70799 loss)
I0628 18:14:25.701072 17458 sgd_solver.cpp:138] Iteration 5010, lr = 0.00025
I0628 18:14:34.796788 17458 solver.cpp:243] Iteration 5020, loss = 3.31509
I0628 18:14:34.796814 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.37643 (* 1 = 2.37643 loss)
I0628 18:14:34.796821 17458 sgd_solver.cpp:138] Iteration 5020, lr = 0.00025
I0628 18:14:43.939224 17458 solver.cpp:243] Iteration 5030, loss = 4.40286
I0628 18:14:43.939249 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.85865 (* 1 = 2.85865 loss)
I0628 18:14:43.939255 17458 sgd_solver.cpp:138] Iteration 5030, lr = 0.00025
I0628 18:14:53.059739 17458 solver.cpp:243] Iteration 5040, loss = 3.40301
I0628 18:14:53.059900 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.76311 (* 1 = 2.76311 loss)
I0628 18:14:53.059908 17458 sgd_solver.cpp:138] Iteration 5040, lr = 0.00025
I0628 18:15:02.183737 17458 solver.cpp:243] Iteration 5050, loss = 2.95854
I0628 18:15:02.183763 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.40076 (* 1 = 3.40076 loss)
I0628 18:15:02.183769 17458 sgd_solver.cpp:138] Iteration 5050, lr = 0.00025
I0628 18:15:11.278837 17458 solver.cpp:243] Iteration 5060, loss = 3.23563
I0628 18:15:11.278862 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.61697 (* 1 = 3.61697 loss)
I0628 18:15:11.278869 17458 sgd_solver.cpp:138] Iteration 5060, lr = 0.00025
I0628 18:15:20.415977 17458 solver.cpp:243] Iteration 5070, loss = 3.80701
I0628 18:15:20.416003 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.53144 (* 1 = 4.53144 loss)
I0628 18:15:20.416010 17458 sgd_solver.cpp:138] Iteration 5070, lr = 0.00025
I0628 18:15:29.535045 17458 solver.cpp:243] Iteration 5080, loss = 3.39963
I0628 18:15:29.535173 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.7277 (* 1 = 3.7277 loss)
I0628 18:15:29.535182 17458 sgd_solver.cpp:138] Iteration 5080, lr = 0.00025
I0628 18:15:38.664465 17458 solver.cpp:243] Iteration 5090, loss = 3.8185
I0628 18:15:38.664490 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.81475 (* 1 = 3.81475 loss)
I0628 18:15:38.664497 17458 sgd_solver.cpp:138] Iteration 5090, lr = 0.00025
I0628 18:15:47.765391 17458 solver.cpp:243] Iteration 5100, loss = 2.97183
I0628 18:15:47.765417 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.31276 (* 1 = 3.31276 loss)
I0628 18:15:47.765424 17458 sgd_solver.cpp:138] Iteration 5100, lr = 0.00025
I0628 18:15:56.910187 17458 solver.cpp:243] Iteration 5110, loss = 3.31644
I0628 18:15:56.910212 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.83498 (* 1 = 3.83498 loss)
I0628 18:15:56.910219 17458 sgd_solver.cpp:138] Iteration 5110, lr = 0.00025
I0628 18:16:06.031858 17458 solver.cpp:243] Iteration 5120, loss = 3.50891
I0628 18:16:06.032007 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.98284 (* 1 = 2.98284 loss)
I0628 18:16:06.032016 17458 sgd_solver.cpp:138] Iteration 5120, lr = 0.00025
I0628 18:16:15.148679 17458 solver.cpp:243] Iteration 5130, loss = 3.85656
I0628 18:16:15.148703 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.73474 (* 1 = 3.73474 loss)
I0628 18:16:15.148710 17458 sgd_solver.cpp:138] Iteration 5130, lr = 0.00025
I0628 18:16:24.267485 17458 solver.cpp:243] Iteration 5140, loss = 3.40022
I0628 18:16:24.267509 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25483 (* 1 = 3.25483 loss)
I0628 18:16:24.267516 17458 sgd_solver.cpp:138] Iteration 5140, lr = 0.00025
I0628 18:16:33.408918 17458 solver.cpp:243] Iteration 5150, loss = 3.3858
I0628 18:16:33.408943 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.70661 (* 1 = 3.70661 loss)
I0628 18:16:33.408951 17458 sgd_solver.cpp:138] Iteration 5150, lr = 0.00025
I0628 18:16:42.514371 17458 solver.cpp:243] Iteration 5160, loss = 3.8458
I0628 18:16:42.514482 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.34452 (* 1 = 3.34452 loss)
I0628 18:16:42.514490 17458 sgd_solver.cpp:138] Iteration 5160, lr = 0.00025
I0628 18:16:51.638212 17458 solver.cpp:243] Iteration 5170, loss = 3.25841
I0628 18:16:51.638236 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.39228 (* 1 = 2.39228 loss)
I0628 18:16:51.638244 17458 sgd_solver.cpp:138] Iteration 5170, lr = 0.00025
I0628 18:17:01.158885 17458 solver.cpp:243] Iteration 5180, loss = 3.27024
I0628 18:17:01.158910 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.24646 (* 1 = 2.24646 loss)
I0628 18:17:01.158918 17458 sgd_solver.cpp:138] Iteration 5180, lr = 0.00025
I0628 18:17:10.675297 17458 solver.cpp:243] Iteration 5190, loss = 3.8037
I0628 18:17:10.675325 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.44339 (* 1 = 4.44339 loss)
I0628 18:17:10.675333 17458 sgd_solver.cpp:138] Iteration 5190, lr = 0.00025
I0628 18:17:20.196815 17458 solver.cpp:243] Iteration 5200, loss = 4.30471
I0628 18:17:20.197033 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.19199 (* 1 = 3.19199 loss)
I0628 18:17:20.197041 17458 sgd_solver.cpp:138] Iteration 5200, lr = 0.00025
I0628 18:17:29.560169 17458 solver.cpp:243] Iteration 5210, loss = 3.60797
I0628 18:17:29.560195 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.02059 (* 1 = 5.02059 loss)
I0628 18:17:29.560202 17458 sgd_solver.cpp:138] Iteration 5210, lr = 0.00025
I0628 18:17:38.995041 17458 solver.cpp:243] Iteration 5220, loss = 3.97578
I0628 18:17:38.995067 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.38613 (* 1 = 4.38613 loss)
I0628 18:17:38.995077 17458 sgd_solver.cpp:138] Iteration 5220, lr = 0.00025
I0628 18:17:48.470310 17458 solver.cpp:243] Iteration 5230, loss = 3.09026
I0628 18:17:48.470356 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.14046 (* 1 = 3.14046 loss)
I0628 18:17:48.470381 17458 sgd_solver.cpp:138] Iteration 5230, lr = 0.00025
I0628 18:17:58.018977 17458 solver.cpp:243] Iteration 5240, loss = 3.25573
I0628 18:17:58.019145 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.2544 (* 1 = 4.2544 loss)
I0628 18:17:58.019153 17458 sgd_solver.cpp:138] Iteration 5240, lr = 0.00025
I0628 18:18:07.153645 17458 solver.cpp:243] Iteration 5250, loss = 3.27809
I0628 18:18:07.153667 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.03 (* 1 = 4.03 loss)
I0628 18:18:07.153692 17458 sgd_solver.cpp:138] Iteration 5250, lr = 0.00025
I0628 18:18:16.307760 17458 solver.cpp:243] Iteration 5260, loss = 3.8429
I0628 18:18:16.307785 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.99953 (* 1 = 3.99953 loss)
I0628 18:18:16.307811 17458 sgd_solver.cpp:138] Iteration 5260, lr = 0.00025
I0628 18:18:25.436904 17458 solver.cpp:243] Iteration 5270, loss = 3.73931
I0628 18:18:25.436928 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.45355 (* 1 = 2.45355 loss)
I0628 18:18:25.436952 17458 sgd_solver.cpp:138] Iteration 5270, lr = 0.00025
I0628 18:18:34.599418 17458 solver.cpp:243] Iteration 5280, loss = 3.55157
I0628 18:18:34.599581 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.44752 (* 1 = 2.44752 loss)
I0628 18:18:34.599591 17458 sgd_solver.cpp:138] Iteration 5280, lr = 0.00025
I0628 18:18:43.734690 17458 solver.cpp:243] Iteration 5290, loss = 3.0108
I0628 18:18:43.734714 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.92824 (* 1 = 2.92824 loss)
I0628 18:18:43.734740 17458 sgd_solver.cpp:138] Iteration 5290, lr = 0.00025
I0628 18:18:52.880362 17458 solver.cpp:243] Iteration 5300, loss = 3.17082
I0628 18:18:52.880386 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.21103 (* 1 = 3.21103 loss)
I0628 18:18:52.880393 17458 sgd_solver.cpp:138] Iteration 5300, lr = 0.00025
I0628 18:19:01.989697 17458 solver.cpp:243] Iteration 5310, loss = 3.5877
I0628 18:19:01.989722 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.71729 (* 1 = 2.71729 loss)
I0628 18:19:01.989730 17458 sgd_solver.cpp:138] Iteration 5310, lr = 0.00025
I0628 18:19:11.145093 17458 solver.cpp:243] Iteration 5320, loss = 4.34506
I0628 18:19:11.145226 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.03132 (* 1 = 2.03132 loss)
I0628 18:19:11.145249 17458 sgd_solver.cpp:138] Iteration 5320, lr = 0.00025
I0628 18:19:20.278491 17458 solver.cpp:243] Iteration 5330, loss = 3.76143
I0628 18:19:20.278533 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.52218 (* 1 = 3.52218 loss)
I0628 18:19:20.278558 17458 sgd_solver.cpp:138] Iteration 5330, lr = 0.00025
I0628 18:19:29.430276 17458 solver.cpp:243] Iteration 5340, loss = 3.31705
I0628 18:19:29.430301 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.86111 (* 1 = 4.86111 loss)
I0628 18:19:29.430326 17458 sgd_solver.cpp:138] Iteration 5340, lr = 0.00025
I0628 18:19:38.546052 17458 solver.cpp:243] Iteration 5350, loss = 3.48131
I0628 18:19:38.546074 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.23645 (* 1 = 1.23645 loss)
I0628 18:19:38.546082 17458 sgd_solver.cpp:138] Iteration 5350, lr = 0.00025
I0628 18:19:47.693125 17458 solver.cpp:243] Iteration 5360, loss = 3.05682
I0628 18:19:47.693329 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.59856 (* 1 = 2.59856 loss)
I0628 18:19:47.693359 17458 sgd_solver.cpp:138] Iteration 5360, lr = 0.00025
I0628 18:19:56.823205 17458 solver.cpp:243] Iteration 5370, loss = 3.34321
I0628 18:19:56.823230 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.44803 (* 1 = 3.44803 loss)
I0628 18:19:56.823254 17458 sgd_solver.cpp:138] Iteration 5370, lr = 0.00025
I0628 18:20:05.972949 17458 solver.cpp:243] Iteration 5380, loss = 3.35114
I0628 18:20:05.972975 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.73994 (* 1 = 3.73994 loss)
I0628 18:20:05.973001 17458 sgd_solver.cpp:138] Iteration 5380, lr = 0.00025
I0628 18:20:15.076086 17458 solver.cpp:243] Iteration 5390, loss = 4.18312
I0628 18:20:15.076112 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.93939 (* 1 = 4.93939 loss)
I0628 18:20:15.076118 17458 sgd_solver.cpp:138] Iteration 5390, lr = 0.00025
I0628 18:20:24.233765 17458 solver.cpp:243] Iteration 5400, loss = 2.60716
I0628 18:20:24.233927 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.93541 (* 1 = 2.93541 loss)
I0628 18:20:24.233934 17458 sgd_solver.cpp:138] Iteration 5400, lr = 0.00025
I0628 18:20:33.371068 17458 solver.cpp:243] Iteration 5410, loss = 3.87587
I0628 18:20:33.371089 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.53563 (* 1 = 6.53563 loss)
I0628 18:20:33.371096 17458 sgd_solver.cpp:138] Iteration 5410, lr = 0.00025
I0628 18:20:42.527652 17458 solver.cpp:243] Iteration 5420, loss = 2.77596
I0628 18:20:42.527674 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.47495 (* 1 = 1.47495 loss)
I0628 18:20:42.527700 17458 sgd_solver.cpp:138] Iteration 5420, lr = 0.00025
I0628 18:20:51.657933 17458 solver.cpp:243] Iteration 5430, loss = 3.47717
I0628 18:20:51.657958 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.47873 (* 1 = 3.47873 loss)
I0628 18:20:51.657984 17458 sgd_solver.cpp:138] Iteration 5430, lr = 0.00025
I0628 18:21:00.805742 17458 solver.cpp:243] Iteration 5440, loss = 3.58098
I0628 18:21:00.805907 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.67817 (* 1 = 4.67817 loss)
I0628 18:21:00.805933 17458 sgd_solver.cpp:138] Iteration 5440, lr = 0.00025
I0628 18:21:09.937839 17458 solver.cpp:243] Iteration 5450, loss = 3.3622
I0628 18:21:09.937862 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.94955 (* 1 = 3.94955 loss)
I0628 18:21:09.937888 17458 sgd_solver.cpp:138] Iteration 5450, lr = 0.00025
I0628 18:21:19.096022 17458 solver.cpp:243] Iteration 5460, loss = 3.31754
I0628 18:21:19.096047 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.02729 (* 1 = 2.02729 loss)
I0628 18:21:19.096053 17458 sgd_solver.cpp:138] Iteration 5460, lr = 0.00025
I0628 18:21:28.204293 17458 solver.cpp:243] Iteration 5470, loss = 3.4717
I0628 18:21:28.204318 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25879 (* 1 = 3.25879 loss)
I0628 18:21:28.204324 17458 sgd_solver.cpp:138] Iteration 5470, lr = 0.00025
I0628 18:21:37.342552 17458 solver.cpp:243] Iteration 5480, loss = 3.46625
I0628 18:21:37.342679 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.40662 (* 1 = 2.40662 loss)
I0628 18:21:37.342703 17458 sgd_solver.cpp:138] Iteration 5480, lr = 0.00025
I0628 18:21:46.473074 17458 solver.cpp:243] Iteration 5490, loss = 3.10249
I0628 18:21:46.473098 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.05249 (* 1 = 3.05249 loss)
I0628 18:21:46.473122 17458 sgd_solver.cpp:138] Iteration 5490, lr = 0.00025
I0628 18:21:55.629284 17458 solver.cpp:243] Iteration 5500, loss = 3.54582
I0628 18:21:55.629330 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.54528 (* 1 = 4.54528 loss)
I0628 18:21:55.629338 17458 sgd_solver.cpp:138] Iteration 5500, lr = 0.00025
I0628 18:22:04.742835 17458 solver.cpp:243] Iteration 5510, loss = 3.95221
I0628 18:22:04.742858 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.56989 (* 1 = 3.56989 loss)
I0628 18:22:04.742883 17458 sgd_solver.cpp:138] Iteration 5510, lr = 0.00025
I0628 18:22:13.889850 17458 solver.cpp:243] Iteration 5520, loss = 4.51757
I0628 18:22:13.890048 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.04009 (* 1 = 4.04009 loss)
I0628 18:22:13.890058 17458 sgd_solver.cpp:138] Iteration 5520, lr = 0.00025
I0628 18:22:23.019593 17458 solver.cpp:243] Iteration 5530, loss = 2.95579
I0628 18:22:23.019616 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.78537 (* 1 = 2.78537 loss)
I0628 18:22:23.019642 17458 sgd_solver.cpp:138] Iteration 5530, lr = 0.00025
I0628 18:22:32.180800 17458 solver.cpp:243] Iteration 5540, loss = 3.88213
I0628 18:22:32.180824 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.89035 (* 1 = 3.89035 loss)
I0628 18:22:32.180850 17458 sgd_solver.cpp:138] Iteration 5540, lr = 0.00025
I0628 18:22:41.315320 17458 solver.cpp:243] Iteration 5550, loss = 3.07513
I0628 18:22:41.315344 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.2081 (* 1 = 3.2081 loss)
I0628 18:22:41.315351 17458 sgd_solver.cpp:138] Iteration 5550, lr = 0.00025
I0628 18:22:50.472987 17458 solver.cpp:243] Iteration 5560, loss = 3.88535
I0628 18:22:50.473150 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.18242 (* 1 = 5.18242 loss)
I0628 18:22:50.473157 17458 sgd_solver.cpp:138] Iteration 5560, lr = 0.00025
I0628 18:22:59.608549 17458 solver.cpp:243] Iteration 5570, loss = 3.53215
I0628 18:22:59.608572 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.24442 (* 1 = 4.24442 loss)
I0628 18:22:59.608597 17458 sgd_solver.cpp:138] Iteration 5570, lr = 0.00025
I0628 18:23:08.749346 17458 solver.cpp:243] Iteration 5580, loss = 3.40481
I0628 18:23:08.749372 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.0631 (* 1 = 4.0631 loss)
I0628 18:23:08.749379 17458 sgd_solver.cpp:138] Iteration 5580, lr = 0.00025
I0628 18:23:17.871662 17458 solver.cpp:243] Iteration 5590, loss = 3.84068
I0628 18:23:17.871687 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.06082 (* 1 = 3.06082 loss)
I0628 18:23:17.871712 17458 sgd_solver.cpp:138] Iteration 5590, lr = 0.00025
I0628 18:23:27.024976 17458 solver.cpp:243] Iteration 5600, loss = 3.50729
I0628 18:23:27.025161 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.48699 (* 1 = 4.48699 loss)
I0628 18:23:27.025168 17458 sgd_solver.cpp:138] Iteration 5600, lr = 0.00025
I0628 18:23:36.154601 17458 solver.cpp:243] Iteration 5610, loss = 3.19747
I0628 18:23:36.154626 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.76631 (* 1 = 5.76631 loss)
I0628 18:23:36.154633 17458 sgd_solver.cpp:138] Iteration 5610, lr = 0.00025
I0628 18:23:45.289703 17458 solver.cpp:243] Iteration 5620, loss = 3.60545
I0628 18:23:45.289728 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53076 (* 1 = 3.53076 loss)
I0628 18:23:45.289754 17458 sgd_solver.cpp:138] Iteration 5620, lr = 0.00025
I0628 18:23:54.397428 17458 solver.cpp:243] Iteration 5630, loss = 3.14713
I0628 18:23:54.397454 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.92896 (* 1 = 1.92896 loss)
I0628 18:23:54.397460 17458 sgd_solver.cpp:138] Iteration 5630, lr = 0.00025
I0628 18:24:03.557283 17458 solver.cpp:243] Iteration 5640, loss = 3.47321
I0628 18:24:03.557462 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.48487 (* 1 = 1.48487 loss)
I0628 18:24:03.557489 17458 sgd_solver.cpp:138] Iteration 5640, lr = 0.00025
I0628 18:24:12.689834 17458 solver.cpp:243] Iteration 5650, loss = 3.75439
I0628 18:24:12.689857 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.03662 (* 1 = 2.03662 loss)
I0628 18:24:12.689882 17458 sgd_solver.cpp:138] Iteration 5650, lr = 0.00025
I0628 18:24:21.830700 17458 solver.cpp:243] Iteration 5660, loss = 2.81245
I0628 18:24:21.830726 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.90136 (* 1 = 3.90136 loss)
I0628 18:24:21.830734 17458 sgd_solver.cpp:138] Iteration 5660, lr = 0.00025
I0628 18:24:30.940493 17458 solver.cpp:243] Iteration 5670, loss = 4.34555
I0628 18:24:30.940516 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.37777 (* 1 = 1.37777 loss)
I0628 18:24:30.940541 17458 sgd_solver.cpp:138] Iteration 5670, lr = 0.00025
I0628 18:24:40.078567 17458 solver.cpp:243] Iteration 5680, loss = 3.54687
I0628 18:24:40.078691 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.08987 (* 1 = 2.08987 loss)
I0628 18:24:40.078699 17458 sgd_solver.cpp:138] Iteration 5680, lr = 0.00025
I0628 18:24:49.191620 17458 solver.cpp:243] Iteration 5690, loss = 4.06079
I0628 18:24:49.191644 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.85883 (* 1 = 3.85883 loss)
I0628 18:24:49.191669 17458 sgd_solver.cpp:138] Iteration 5690, lr = 0.00025
I0628 18:24:58.344235 17458 solver.cpp:243] Iteration 5700, loss = 3.8445
I0628 18:24:58.344259 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.50961 (* 1 = 4.50961 loss)
I0628 18:24:58.344285 17458 sgd_solver.cpp:138] Iteration 5700, lr = 0.00025
I0628 18:25:07.482642 17458 solver.cpp:243] Iteration 5710, loss = 3.64092
I0628 18:25:07.482666 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.25138 (* 1 = 5.25138 loss)
I0628 18:25:07.482692 17458 sgd_solver.cpp:138] Iteration 5710, lr = 0.00025
I0628 18:25:16.634927 17458 solver.cpp:243] Iteration 5720, loss = 3.30344
I0628 18:25:16.635073 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.89682 (* 1 = 2.89682 loss)
I0628 18:25:16.635082 17458 sgd_solver.cpp:138] Iteration 5720, lr = 0.00025
I0628 18:25:25.751273 17458 solver.cpp:243] Iteration 5730, loss = 4.25164
I0628 18:25:25.751296 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.97296 (* 1 = 3.97296 loss)
I0628 18:25:25.751322 17458 sgd_solver.cpp:138] Iteration 5730, lr = 0.00025
I0628 18:25:34.912351 17458 solver.cpp:243] Iteration 5740, loss = 3.40332
I0628 18:25:34.912377 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.96365 (* 1 = 2.96365 loss)
I0628 18:25:34.912384 17458 sgd_solver.cpp:138] Iteration 5740, lr = 0.00025
I0628 18:25:44.051215 17458 solver.cpp:243] Iteration 5750, loss = 3.20163
I0628 18:25:44.051239 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.00843 (* 1 = 2.00843 loss)
I0628 18:25:44.051263 17458 sgd_solver.cpp:138] Iteration 5750, lr = 0.00025
I0628 18:25:53.205281 17458 solver.cpp:243] Iteration 5760, loss = 3.2232
I0628 18:25:53.205442 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.87642 (* 1 = 2.87642 loss)
I0628 18:25:53.205469 17458 sgd_solver.cpp:138] Iteration 5760, lr = 0.00025
I0628 18:26:02.325286 17458 solver.cpp:243] Iteration 5770, loss = 3.9858
I0628 18:26:02.325314 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.6383 (* 1 = 4.6383 loss)
I0628 18:26:02.325321 17458 sgd_solver.cpp:138] Iteration 5770, lr = 0.00025
I0628 18:26:11.462972 17458 solver.cpp:243] Iteration 5780, loss = 3.55362
I0628 18:26:11.462996 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.76436 (* 1 = 3.76436 loss)
I0628 18:26:11.463021 17458 sgd_solver.cpp:138] Iteration 5780, lr = 0.00025
I0628 18:26:20.571758 17458 solver.cpp:243] Iteration 5790, loss = 3.57567
I0628 18:26:20.571781 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.04276 (* 1 = 4.04276 loss)
I0628 18:26:20.571789 17458 sgd_solver.cpp:138] Iteration 5790, lr = 0.00025
I0628 18:26:29.710765 17458 solver.cpp:243] Iteration 5800, loss = 3.65467
I0628 18:26:29.710875 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.65669 (* 1 = 1.65669 loss)
I0628 18:26:29.710899 17458 sgd_solver.cpp:138] Iteration 5800, lr = 0.00025
I0628 18:26:38.846534 17458 solver.cpp:243] Iteration 5810, loss = 2.86322
I0628 18:26:38.846558 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.834 (* 1 = 1.834 loss)
I0628 18:26:38.846565 17458 sgd_solver.cpp:138] Iteration 5810, lr = 0.00025
I0628 18:26:48.005260 17458 solver.cpp:243] Iteration 5820, loss = 3.41255
I0628 18:26:48.005285 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.67266 (* 1 = 3.67266 loss)
I0628 18:26:48.005314 17458 sgd_solver.cpp:138] Iteration 5820, lr = 0.00025
I0628 18:26:57.120882 17458 solver.cpp:243] Iteration 5830, loss = 3.58272
I0628 18:26:57.120906 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.0328 (* 1 = 4.0328 loss)
I0628 18:26:57.120931 17458 sgd_solver.cpp:138] Iteration 5830, lr = 0.00025
I0628 18:27:06.259084 17458 solver.cpp:243] Iteration 5840, loss = 4.01949
I0628 18:27:06.259202 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.31538 (* 1 = 5.31538 loss)
I0628 18:27:06.259210 17458 sgd_solver.cpp:138] Iteration 5840, lr = 0.00025
I0628 18:27:15.375977 17458 solver.cpp:243] Iteration 5850, loss = 2.63265
I0628 18:27:15.375999 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.00725 (* 1 = 4.00725 loss)
I0628 18:27:15.376025 17458 sgd_solver.cpp:138] Iteration 5850, lr = 0.00025
I0628 18:27:24.535048 17458 solver.cpp:243] Iteration 5860, loss = 3.83567
I0628 18:27:24.535071 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.05141 (* 1 = 3.05141 loss)
I0628 18:27:24.535096 17458 sgd_solver.cpp:138] Iteration 5860, lr = 0.00025
I0628 18:27:33.671244 17458 solver.cpp:243] Iteration 5870, loss = 3.06436
I0628 18:27:33.671267 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.76652 (* 1 = 1.76652 loss)
I0628 18:27:33.671293 17458 sgd_solver.cpp:138] Iteration 5870, lr = 0.00025
I0628 18:27:42.829748 17458 solver.cpp:243] Iteration 5880, loss = 3.10691
I0628 18:27:42.829888 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.83873 (* 1 = 2.83873 loss)
I0628 18:27:42.829896 17458 sgd_solver.cpp:138] Iteration 5880, lr = 0.00025
I0628 18:27:51.959964 17458 solver.cpp:243] Iteration 5890, loss = 3.40929
I0628 18:27:51.959986 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.73464 (* 1 = 3.73464 loss)
I0628 18:27:51.960011 17458 sgd_solver.cpp:138] Iteration 5890, lr = 0.00025
I0628 18:28:01.118186 17458 solver.cpp:243] Iteration 5900, loss = 3.61943
I0628 18:28:01.118211 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.38062 (* 1 = 5.38062 loss)
I0628 18:28:01.118237 17458 sgd_solver.cpp:138] Iteration 5900, lr = 0.00025
I0628 18:28:10.231645 17458 solver.cpp:243] Iteration 5910, loss = 3.46869
I0628 18:28:10.231669 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.91581 (* 1 = 1.91581 loss)
I0628 18:28:10.231694 17458 sgd_solver.cpp:138] Iteration 5910, lr = 0.00025
I0628 18:28:19.368422 17458 solver.cpp:243] Iteration 5920, loss = 2.90584
I0628 18:28:19.368548 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.76944 (* 1 = 2.76944 loss)
I0628 18:28:19.368557 17458 sgd_solver.cpp:138] Iteration 5920, lr = 0.00025
I0628 18:28:28.480823 17458 solver.cpp:243] Iteration 5930, loss = 2.95405
I0628 18:28:28.480846 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.41725 (* 1 = 5.41725 loss)
I0628 18:28:28.480854 17458 sgd_solver.cpp:138] Iteration 5930, lr = 0.00025
I0628 18:28:37.609277 17458 solver.cpp:243] Iteration 5940, loss = 3.33851
I0628 18:28:37.609302 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.05454 (* 1 = 5.05454 loss)
I0628 18:28:37.609313 17458 sgd_solver.cpp:138] Iteration 5940, lr = 0.00025
I0628 18:28:46.722787 17458 solver.cpp:243] Iteration 5950, loss = 3.01898
I0628 18:28:46.722810 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.15284 (* 1 = 2.15284 loss)
I0628 18:28:46.722836 17458 sgd_solver.cpp:138] Iteration 5950, lr = 0.00025
I0628 18:28:55.879982 17458 solver.cpp:243] Iteration 5960, loss = 3.56893
I0628 18:28:55.880127 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.37203 (* 1 = 2.37203 loss)
I0628 18:28:55.880136 17458 sgd_solver.cpp:138] Iteration 5960, lr = 0.00025
I0628 18:29:05.013152 17458 solver.cpp:243] Iteration 5970, loss = 3.17698
I0628 18:29:05.013175 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.59746 (* 1 = 2.59746 loss)
I0628 18:29:05.013201 17458 sgd_solver.cpp:138] Iteration 5970, lr = 0.00025
I0628 18:29:14.169665 17458 solver.cpp:243] Iteration 5980, loss = 3.14971
I0628 18:29:14.169689 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.32489 (* 1 = 3.32489 loss)
I0628 18:29:14.169697 17458 sgd_solver.cpp:138] Iteration 5980, lr = 0.00025
I0628 18:29:23.307567 17458 solver.cpp:243] Iteration 5990, loss = 3.83182
I0628 18:29:23.307591 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.87598 (* 1 = 4.87598 loss)
I0628 18:29:23.307616 17458 sgd_solver.cpp:138] Iteration 5990, lr = 0.00025
I0628 18:29:31.695595 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_6000.caffemodel
I0628 18:29:31.776996 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_6000.solverstate
I0628 18:29:31.809092 17458 solver.cpp:433] Iteration 6000, Testing net (#0)
I0628 18:29:31.809207 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 18:32:36.671939 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.273587
I0628 18:32:37.457504 17458 solver.cpp:243] Iteration 6000, loss = 3.2971
I0628 18:32:37.457532 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.99331 (* 1 = 2.99331 loss)
I0628 18:32:37.457540 17458 sgd_solver.cpp:47] MultiStep Status: Iteration 6000, step = 2
I0628 18:32:37.457546 17458 sgd_solver.cpp:138] Iteration 6000, lr = 0.000125
I0628 18:32:46.596369 17458 solver.cpp:243] Iteration 6010, loss = 3.08917
I0628 18:32:46.596392 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.78007 (* 1 = 2.78007 loss)
I0628 18:32:46.596400 17458 sgd_solver.cpp:138] Iteration 6010, lr = 0.000125
I0628 18:32:55.712487 17458 solver.cpp:243] Iteration 6020, loss = 3.45755
I0628 18:32:55.712512 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.20893 (* 1 = 3.20893 loss)
I0628 18:32:55.712518 17458 sgd_solver.cpp:138] Iteration 6020, lr = 0.000125
I0628 18:33:04.845106 17458 solver.cpp:243] Iteration 6030, loss = 3.50667
I0628 18:33:04.845132 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.72035 (* 1 = 4.72035 loss)
I0628 18:33:04.845139 17458 sgd_solver.cpp:138] Iteration 6030, lr = 0.000125
I0628 18:33:13.946292 17458 solver.cpp:243] Iteration 6040, loss = 3.22815
I0628 18:33:13.946421 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.07748 (* 1 = 3.07748 loss)
I0628 18:33:13.946445 17458 sgd_solver.cpp:138] Iteration 6040, lr = 0.000125
I0628 18:33:23.091390 17458 solver.cpp:243] Iteration 6050, loss = 3.64933
I0628 18:33:23.091418 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.91531 (* 1 = 3.91531 loss)
I0628 18:33:23.091424 17458 sgd_solver.cpp:138] Iteration 6050, lr = 0.000125
I0628 18:33:32.213812 17458 solver.cpp:243] Iteration 6060, loss = 3.17814
I0628 18:33:32.213836 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.35101 (* 1 = 3.35101 loss)
I0628 18:33:32.213845 17458 sgd_solver.cpp:138] Iteration 6060, lr = 0.000125
I0628 18:33:41.334216 17458 solver.cpp:243] Iteration 6070, loss = 3.30124
I0628 18:33:41.334240 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.27925 (* 1 = 3.27925 loss)
I0628 18:33:41.334247 17458 sgd_solver.cpp:138] Iteration 6070, lr = 0.000125
I0628 18:33:50.431504 17458 solver.cpp:243] Iteration 6080, loss = 3.82871
I0628 18:33:50.431607 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.92211 (* 1 = 3.92211 loss)
I0628 18:33:50.431617 17458 sgd_solver.cpp:138] Iteration 6080, lr = 0.000125
I0628 18:33:59.565124 17458 solver.cpp:243] Iteration 6090, loss = 3.16565
I0628 18:33:59.565148 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.06943 (* 1 = 4.06943 loss)
I0628 18:33:59.565173 17458 sgd_solver.cpp:138] Iteration 6090, lr = 0.000125
I0628 18:34:08.686834 17458 solver.cpp:243] Iteration 6100, loss = 3.24154
I0628 18:34:08.686857 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.96953 (* 1 = 3.96953 loss)
I0628 18:34:08.686864 17458 sgd_solver.cpp:138] Iteration 6100, lr = 0.000125
I0628 18:34:17.819089 17458 solver.cpp:243] Iteration 6110, loss = 3.39153
I0628 18:34:17.819114 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.41694 (* 1 = 3.41694 loss)
I0628 18:34:17.819121 17458 sgd_solver.cpp:138] Iteration 6110, lr = 0.000125
I0628 18:34:26.922621 17458 solver.cpp:243] Iteration 6120, loss = 3.31572
I0628 18:34:26.922791 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.94729 (* 1 = 1.94729 loss)
I0628 18:34:26.922801 17458 sgd_solver.cpp:138] Iteration 6120, lr = 0.000125
I0628 18:34:36.050657 17458 solver.cpp:243] Iteration 6130, loss = 3.14857
I0628 18:34:36.050681 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.31818 (* 1 = 1.31818 loss)
I0628 18:34:36.050688 17458 sgd_solver.cpp:138] Iteration 6130, lr = 0.000125
I0628 18:34:45.157622 17458 solver.cpp:243] Iteration 6140, loss = 3.03836
I0628 18:34:45.157647 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.47984 (* 1 = 2.47984 loss)
I0628 18:34:45.157655 17458 sgd_solver.cpp:138] Iteration 6140, lr = 0.000125
I0628 18:34:54.281471 17458 solver.cpp:243] Iteration 6150, loss = 3.8026
I0628 18:34:54.281497 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.95229 (* 1 = 3.95229 loss)
I0628 18:34:54.281503 17458 sgd_solver.cpp:138] Iteration 6150, lr = 0.000125
I0628 18:35:03.391103 17458 solver.cpp:243] Iteration 6160, loss = 4.17903
I0628 18:35:03.391222 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.40203 (* 1 = 5.40203 loss)
I0628 18:35:03.391230 17458 sgd_solver.cpp:138] Iteration 6160, lr = 0.000125
I0628 18:35:12.519683 17458 solver.cpp:243] Iteration 6170, loss = 2.65916
I0628 18:35:12.519707 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.83846 (* 1 = 1.83846 loss)
I0628 18:35:12.519714 17458 sgd_solver.cpp:138] Iteration 6170, lr = 0.000125
I0628 18:35:21.634222 17458 solver.cpp:243] Iteration 6180, loss = 3.56825
I0628 18:35:21.634245 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.48946 (* 1 = 3.48946 loss)
I0628 18:35:21.634253 17458 sgd_solver.cpp:138] Iteration 6180, lr = 0.000125
I0628 18:35:30.759886 17458 solver.cpp:243] Iteration 6190, loss = 3.29216
I0628 18:35:30.759912 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.90628 (* 1 = 3.90628 loss)
I0628 18:35:30.759918 17458 sgd_solver.cpp:138] Iteration 6190, lr = 0.000125
I0628 18:35:39.867679 17458 solver.cpp:243] Iteration 6200, loss = 3.98828
I0628 18:35:39.867794 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.73176 (* 1 = 5.73176 loss)
I0628 18:35:39.867818 17458 sgd_solver.cpp:138] Iteration 6200, lr = 0.000125
I0628 18:35:48.992337 17458 solver.cpp:243] Iteration 6210, loss = 3.42063
I0628 18:35:48.992363 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.70336 (* 1 = 4.70336 loss)
I0628 18:35:48.992370 17458 sgd_solver.cpp:138] Iteration 6210, lr = 0.000125
I0628 18:35:58.095075 17458 solver.cpp:243] Iteration 6220, loss = 3.26097
I0628 18:35:58.095099 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.23069 (* 1 = 3.23069 loss)
I0628 18:35:58.095108 17458 sgd_solver.cpp:138] Iteration 6220, lr = 0.000125
I0628 18:36:07.225899 17458 solver.cpp:243] Iteration 6230, loss = 3.24043
I0628 18:36:07.225944 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.90953 (* 1 = 2.90953 loss)
I0628 18:36:07.225951 17458 sgd_solver.cpp:138] Iteration 6230, lr = 0.000125
I0628 18:36:16.331821 17458 solver.cpp:243] Iteration 6240, loss = 3.46051
I0628 18:36:16.331921 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.17175 (* 1 = 4.17175 loss)
I0628 18:36:16.331929 17458 sgd_solver.cpp:138] Iteration 6240, lr = 0.000125
I0628 18:36:25.460309 17458 solver.cpp:243] Iteration 6250, loss = 3.05942
I0628 18:36:25.460335 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.7258 (* 1 = 3.7258 loss)
I0628 18:36:25.460342 17458 sgd_solver.cpp:138] Iteration 6250, lr = 0.000125
I0628 18:36:34.571460 17458 solver.cpp:243] Iteration 6260, loss = 2.62891
I0628 18:36:34.571483 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.74333 (* 1 = 1.74333 loss)
I0628 18:36:34.571491 17458 sgd_solver.cpp:138] Iteration 6260, lr = 0.000125
I0628 18:36:43.697547 17458 solver.cpp:243] Iteration 6270, loss = 3.07525
I0628 18:36:43.697571 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.96017 (* 1 = 3.96017 loss)
I0628 18:36:43.697577 17458 sgd_solver.cpp:138] Iteration 6270, lr = 0.000125
I0628 18:36:52.806941 17458 solver.cpp:243] Iteration 6280, loss = 3.97327
I0628 18:36:52.807099 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.57102 (* 1 = 2.57102 loss)
I0628 18:36:52.807108 17458 sgd_solver.cpp:138] Iteration 6280, lr = 0.000125
I0628 18:37:01.934931 17458 solver.cpp:243] Iteration 6290, loss = 4.53837
I0628 18:37:01.934955 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53757 (* 1 = 3.53757 loss)
I0628 18:37:01.934963 17458 sgd_solver.cpp:138] Iteration 6290, lr = 0.000125
I0628 18:37:11.043552 17458 solver.cpp:243] Iteration 6300, loss = 2.44083
I0628 18:37:11.043576 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.70229 (* 1 = 1.70229 loss)
I0628 18:37:11.043584 17458 sgd_solver.cpp:138] Iteration 6300, lr = 0.000125
I0628 18:37:20.168954 17458 solver.cpp:243] Iteration 6310, loss = 3.74292
I0628 18:37:20.168979 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.645 (* 1 = 3.645 loss)
I0628 18:37:20.168987 17458 sgd_solver.cpp:138] Iteration 6310, lr = 0.000125
I0628 18:37:29.281849 17458 solver.cpp:243] Iteration 6320, loss = 2.9219
I0628 18:37:29.282012 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.19441 (* 1 = 3.19441 loss)
I0628 18:37:29.282039 17458 sgd_solver.cpp:138] Iteration 6320, lr = 0.000125
I0628 18:37:38.413429 17458 solver.cpp:243] Iteration 6330, loss = 2.99782
I0628 18:37:38.413453 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.9423 (* 1 = 2.9423 loss)
I0628 18:37:38.413461 17458 sgd_solver.cpp:138] Iteration 6330, lr = 0.000125
I0628 18:37:47.542250 17458 solver.cpp:243] Iteration 6340, loss = 2.97703
I0628 18:37:47.542275 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3462 (* 1 = 3.3462 loss)
I0628 18:37:47.542282 17458 sgd_solver.cpp:138] Iteration 6340, lr = 0.000125
I0628 18:37:56.692595 17458 solver.cpp:243] Iteration 6350, loss = 3.34473
I0628 18:37:56.692618 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.30596 (* 1 = 4.30596 loss)
I0628 18:37:56.692625 17458 sgd_solver.cpp:138] Iteration 6350, lr = 0.000125
I0628 18:38:05.802852 17458 solver.cpp:243] Iteration 6360, loss = 3.15227
I0628 18:38:05.802981 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.64693 (* 1 = 2.64693 loss)
I0628 18:38:05.802989 17458 sgd_solver.cpp:138] Iteration 6360, lr = 0.000125
I0628 18:38:14.930835 17458 solver.cpp:243] Iteration 6370, loss = 4.51223
I0628 18:38:14.930860 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.473 (* 1 = 3.473 loss)
I0628 18:38:14.930866 17458 sgd_solver.cpp:138] Iteration 6370, lr = 0.000125
I0628 18:38:24.044476 17458 solver.cpp:243] Iteration 6380, loss = 2.93554
I0628 18:38:24.044500 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53695 (* 1 = 3.53695 loss)
I0628 18:38:24.044507 17458 sgd_solver.cpp:138] Iteration 6380, lr = 0.000125
I0628 18:38:33.174787 17458 solver.cpp:243] Iteration 6390, loss = 2.98315
I0628 18:38:33.174811 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.74039 (* 1 = 2.74039 loss)
I0628 18:38:33.174818 17458 sgd_solver.cpp:138] Iteration 6390, lr = 0.000125
I0628 18:38:42.283615 17458 solver.cpp:243] Iteration 6400, loss = 3.45014
I0628 18:38:42.283782 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.26073 (* 1 = 3.26073 loss)
I0628 18:38:42.283792 17458 sgd_solver.cpp:138] Iteration 6400, lr = 0.000125
I0628 18:38:51.413659 17458 solver.cpp:243] Iteration 6410, loss = 3.62417
I0628 18:38:51.413684 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53538 (* 1 = 3.53538 loss)
I0628 18:38:51.413691 17458 sgd_solver.cpp:138] Iteration 6410, lr = 0.000125
I0628 18:39:00.524415 17458 solver.cpp:243] Iteration 6420, loss = 3.47731
I0628 18:39:00.524438 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.72963 (* 1 = 1.72963 loss)
I0628 18:39:00.524446 17458 sgd_solver.cpp:138] Iteration 6420, lr = 0.000125
I0628 18:39:09.654054 17458 solver.cpp:243] Iteration 6430, loss = 3.31373
I0628 18:39:09.654080 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.4489 (* 1 = 2.4489 loss)
I0628 18:39:09.654088 17458 sgd_solver.cpp:138] Iteration 6430, lr = 0.000125
I0628 18:39:18.760002 17458 solver.cpp:243] Iteration 6440, loss = 3.93092
I0628 18:39:18.760174 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.94365 (* 1 = 1.94365 loss)
I0628 18:39:18.760183 17458 sgd_solver.cpp:138] Iteration 6440, lr = 0.000125
I0628 18:39:27.907698 17458 solver.cpp:243] Iteration 6450, loss = 3.26518
I0628 18:39:27.907723 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.04874 (* 1 = 4.04874 loss)
I0628 18:39:27.907730 17458 sgd_solver.cpp:138] Iteration 6450, lr = 0.000125
I0628 18:39:37.030964 17458 solver.cpp:243] Iteration 6460, loss = 3.58207
I0628 18:39:37.030987 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.77005 (* 1 = 3.77005 loss)
I0628 18:39:37.030995 17458 sgd_solver.cpp:138] Iteration 6460, lr = 0.000125
I0628 18:39:46.166416 17458 solver.cpp:243] Iteration 6470, loss = 3.90318
I0628 18:39:46.166443 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.4229 (* 1 = 3.4229 loss)
I0628 18:39:46.166450 17458 sgd_solver.cpp:138] Iteration 6470, lr = 0.000125
I0628 18:39:55.271502 17458 solver.cpp:243] Iteration 6480, loss = 3.56748
I0628 18:39:55.271649 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.77659 (* 1 = 3.77659 loss)
I0628 18:39:55.271693 17458 sgd_solver.cpp:138] Iteration 6480, lr = 0.000125
I0628 18:40:04.400568 17458 solver.cpp:243] Iteration 6490, loss = 3.27631
I0628 18:40:04.400593 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.74702 (* 1 = 2.74702 loss)
I0628 18:40:04.400600 17458 sgd_solver.cpp:138] Iteration 6490, lr = 0.000125
I0628 18:40:13.513298 17458 solver.cpp:243] Iteration 6500, loss = 3.87185
I0628 18:40:13.513326 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.80056 (* 1 = 3.80056 loss)
I0628 18:40:13.513334 17458 sgd_solver.cpp:138] Iteration 6500, lr = 0.000125
I0628 18:40:22.643694 17458 solver.cpp:243] Iteration 6510, loss = 2.9371
I0628 18:40:22.643719 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.80516 (* 1 = 2.80516 loss)
I0628 18:40:22.643744 17458 sgd_solver.cpp:138] Iteration 6510, lr = 0.000125
I0628 18:40:31.751461 17458 solver.cpp:243] Iteration 6520, loss = 3.0222
I0628 18:40:31.751569 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.69157 (* 1 = 2.69157 loss)
I0628 18:40:31.751576 17458 sgd_solver.cpp:138] Iteration 6520, lr = 0.000125
I0628 18:40:40.881541 17458 solver.cpp:243] Iteration 6530, loss = 3.16575
I0628 18:40:40.881564 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.30892 (* 1 = 4.30892 loss)
I0628 18:40:40.881572 17458 sgd_solver.cpp:138] Iteration 6530, lr = 0.000125
I0628 18:40:49.993953 17458 solver.cpp:243] Iteration 6540, loss = 3.76497
I0628 18:40:49.993978 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.98736 (* 1 = 3.98736 loss)
I0628 18:40:49.993984 17458 sgd_solver.cpp:138] Iteration 6540, lr = 0.000125
I0628 18:40:59.122207 17458 solver.cpp:243] Iteration 6550, loss = 3.15021
I0628 18:40:59.122232 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.05244 (* 1 = 2.05244 loss)
I0628 18:40:59.122239 17458 sgd_solver.cpp:138] Iteration 6550, lr = 0.000125
I0628 18:41:08.231120 17458 solver.cpp:243] Iteration 6560, loss = 4.03692
I0628 18:41:08.231251 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.78755 (* 1 = 3.78755 loss)
I0628 18:41:08.231259 17458 sgd_solver.cpp:138] Iteration 6560, lr = 0.000125
I0628 18:41:17.364814 17458 solver.cpp:243] Iteration 6570, loss = 3.26874
I0628 18:41:17.364838 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.42479 (* 1 = 4.42479 loss)
I0628 18:41:17.364845 17458 sgd_solver.cpp:138] Iteration 6570, lr = 0.000125
I0628 18:41:26.474139 17458 solver.cpp:243] Iteration 6580, loss = 2.64527
I0628 18:41:26.474164 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.36254 (* 1 = 3.36254 loss)
I0628 18:41:26.474171 17458 sgd_solver.cpp:138] Iteration 6580, lr = 0.000125
I0628 18:41:35.607745 17458 solver.cpp:243] Iteration 6590, loss = 2.47045
I0628 18:41:35.607771 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.30389 (* 1 = 2.30389 loss)
I0628 18:41:35.607779 17458 sgd_solver.cpp:138] Iteration 6590, lr = 0.000125
I0628 18:41:44.712885 17458 solver.cpp:243] Iteration 6600, loss = 4.03998
I0628 18:41:44.713013 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.19395 (* 1 = 3.19395 loss)
I0628 18:41:44.713022 17458 sgd_solver.cpp:138] Iteration 6600, lr = 0.000125
I0628 18:41:53.838088 17458 solver.cpp:243] Iteration 6610, loss = 3.82418
I0628 18:41:53.838111 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.21767 (* 1 = 3.21767 loss)
I0628 18:41:53.838119 17458 sgd_solver.cpp:138] Iteration 6610, lr = 0.000125
I0628 18:42:02.946885 17458 solver.cpp:243] Iteration 6620, loss = 3.15465
I0628 18:42:02.946908 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.47695 (* 1 = 4.47695 loss)
I0628 18:42:02.946915 17458 sgd_solver.cpp:138] Iteration 6620, lr = 0.000125
I0628 18:42:12.077845 17458 solver.cpp:243] Iteration 6630, loss = 3.48943
I0628 18:42:12.077869 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.06397 (* 1 = 2.06397 loss)
I0628 18:42:12.077877 17458 sgd_solver.cpp:138] Iteration 6630, lr = 0.000125
I0628 18:42:21.185397 17458 solver.cpp:243] Iteration 6640, loss = 3.28546
I0628 18:42:21.185557 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.66216 (* 1 = 2.66216 loss)
I0628 18:42:21.185585 17458 sgd_solver.cpp:138] Iteration 6640, lr = 0.000125
I0628 18:42:30.314040 17458 solver.cpp:243] Iteration 6650, loss = 3.36056
I0628 18:42:30.314064 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.29578 (* 1 = 5.29578 loss)
I0628 18:42:30.314070 17458 sgd_solver.cpp:138] Iteration 6650, lr = 0.000125
I0628 18:42:39.421975 17458 solver.cpp:243] Iteration 6660, loss = 3.23839
I0628 18:42:39.422019 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.68079 (* 1 = 3.68079 loss)
I0628 18:42:39.422026 17458 sgd_solver.cpp:138] Iteration 6660, lr = 0.000125
I0628 18:42:48.548527 17458 solver.cpp:243] Iteration 6670, loss = 3.18318
I0628 18:42:48.548568 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.76702 (* 1 = 5.76702 loss)
I0628 18:42:48.548575 17458 sgd_solver.cpp:138] Iteration 6670, lr = 0.000125
I0628 18:42:57.652019 17458 solver.cpp:243] Iteration 6680, loss = 4.01185
I0628 18:42:57.652166 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.8946 (* 1 = 3.8946 loss)
I0628 18:42:57.652175 17458 sgd_solver.cpp:138] Iteration 6680, lr = 0.000125
I0628 18:43:06.787818 17458 solver.cpp:243] Iteration 6690, loss = 3.48043
I0628 18:43:06.787843 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.24406 (* 1 = 4.24406 loss)
I0628 18:43:06.787850 17458 sgd_solver.cpp:138] Iteration 6690, lr = 0.000125
I0628 18:43:15.918506 17458 solver.cpp:243] Iteration 6700, loss = 3.34349
I0628 18:43:15.918530 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.66645 (* 1 = 3.66645 loss)
I0628 18:43:15.918537 17458 sgd_solver.cpp:138] Iteration 6700, lr = 0.000125
I0628 18:43:25.068243 17458 solver.cpp:243] Iteration 6710, loss = 3.4705
I0628 18:43:25.068265 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.69458 (* 1 = 4.69458 loss)
I0628 18:43:25.068274 17458 sgd_solver.cpp:138] Iteration 6710, lr = 0.000125
I0628 18:43:34.176714 17458 solver.cpp:243] Iteration 6720, loss = 2.81914
I0628 18:43:34.176858 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.556 (* 1 = 3.556 loss)
I0628 18:43:34.176867 17458 sgd_solver.cpp:138] Iteration 6720, lr = 0.000125
I0628 18:43:43.309810 17458 solver.cpp:243] Iteration 6730, loss = 3.80373
I0628 18:43:43.309836 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.2241 (* 1 = 3.2241 loss)
I0628 18:43:43.309844 17458 sgd_solver.cpp:138] Iteration 6730, lr = 0.000125
I0628 18:43:52.417510 17458 solver.cpp:243] Iteration 6740, loss = 3.17371
I0628 18:43:52.417532 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.10821 (* 1 = 1.10821 loss)
I0628 18:43:52.417539 17458 sgd_solver.cpp:138] Iteration 6740, lr = 0.000125
I0628 18:44:01.548007 17458 solver.cpp:243] Iteration 6750, loss = 2.91567
I0628 18:44:01.548032 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.09384 (* 1 = 2.09384 loss)
I0628 18:44:01.548039 17458 sgd_solver.cpp:138] Iteration 6750, lr = 0.000125
I0628 18:44:10.662549 17458 solver.cpp:243] Iteration 6760, loss = 4.01661
I0628 18:44:10.662703 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.17592 (* 1 = 4.17592 loss)
I0628 18:44:10.662727 17458 sgd_solver.cpp:138] Iteration 6760, lr = 0.000125
I0628 18:44:19.792127 17458 solver.cpp:243] Iteration 6770, loss = 3.52583
I0628 18:44:19.792152 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.50704 (* 1 = 1.50704 loss)
I0628 18:44:19.792160 17458 sgd_solver.cpp:138] Iteration 6770, lr = 0.000125
I0628 18:44:28.897372 17458 solver.cpp:243] Iteration 6780, loss = 2.85631
I0628 18:44:28.897397 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.46994 (* 1 = 2.46994 loss)
I0628 18:44:28.897404 17458 sgd_solver.cpp:138] Iteration 6780, lr = 0.000125
I0628 18:44:38.025041 17458 solver.cpp:243] Iteration 6790, loss = 2.96784
I0628 18:44:38.025068 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.78156 (* 1 = 2.78156 loss)
I0628 18:44:38.025074 17458 sgd_solver.cpp:138] Iteration 6790, lr = 0.000125
I0628 18:44:47.137122 17458 solver.cpp:243] Iteration 6800, loss = 3.56298
I0628 18:44:47.137262 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.75249 (* 1 = 3.75249 loss)
I0628 18:44:47.137274 17458 sgd_solver.cpp:138] Iteration 6800, lr = 0.000125
I0628 18:44:56.262605 17458 solver.cpp:243] Iteration 6810, loss = 2.94482
I0628 18:44:56.262630 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.383 (* 1 = 4.383 loss)
I0628 18:44:56.262637 17458 sgd_solver.cpp:138] Iteration 6810, lr = 0.000125
I0628 18:45:05.376858 17458 solver.cpp:243] Iteration 6820, loss = 3.70623
I0628 18:45:05.376883 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.08143 (* 1 = 4.08143 loss)
I0628 18:45:05.376889 17458 sgd_solver.cpp:138] Iteration 6820, lr = 0.000125
I0628 18:45:14.509516 17458 solver.cpp:243] Iteration 6830, loss = 3.02014
I0628 18:45:14.509542 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.1677 (* 1 = 4.1677 loss)
I0628 18:45:14.509549 17458 sgd_solver.cpp:138] Iteration 6830, lr = 0.000125
I0628 18:45:23.619058 17458 solver.cpp:243] Iteration 6840, loss = 3.08463
I0628 18:45:23.619210 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.80096 (* 1 = 1.80096 loss)
I0628 18:45:23.619218 17458 sgd_solver.cpp:138] Iteration 6840, lr = 0.000125
I0628 18:45:32.741129 17458 solver.cpp:243] Iteration 6850, loss = 3.41646
I0628 18:45:32.741155 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.51228 (* 1 = 4.51228 loss)
I0628 18:45:32.741163 17458 sgd_solver.cpp:138] Iteration 6850, lr = 0.000125
I0628 18:45:41.850005 17458 solver.cpp:243] Iteration 6860, loss = 3.53173
I0628 18:45:41.850029 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.46168 (* 1 = 3.46168 loss)
I0628 18:45:41.850037 17458 sgd_solver.cpp:138] Iteration 6860, lr = 0.000125
I0628 18:45:50.976094 17458 solver.cpp:243] Iteration 6870, loss = 3.21479
I0628 18:45:50.976120 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.91077 (* 1 = 3.91077 loss)
I0628 18:45:50.976128 17458 sgd_solver.cpp:138] Iteration 6870, lr = 0.000125
I0628 18:46:00.079959 17458 solver.cpp:243] Iteration 6880, loss = 4.53527
I0628 18:46:00.080090 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.91132 (* 1 = 5.91132 loss)
I0628 18:46:00.080099 17458 sgd_solver.cpp:138] Iteration 6880, lr = 0.000125
I0628 18:46:09.209064 17458 solver.cpp:243] Iteration 6890, loss = 2.73973
I0628 18:46:09.209089 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.4775 (* 1 = 4.4775 loss)
I0628 18:46:09.209095 17458 sgd_solver.cpp:138] Iteration 6890, lr = 0.000125
I0628 18:46:18.312736 17458 solver.cpp:243] Iteration 6900, loss = 3.1983
I0628 18:46:18.312759 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.16438 (* 1 = 4.16438 loss)
I0628 18:46:18.312767 17458 sgd_solver.cpp:138] Iteration 6900, lr = 0.000125
I0628 18:46:27.457257 17458 solver.cpp:243] Iteration 6910, loss = 3.39012
I0628 18:46:27.457281 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.57844 (* 1 = 2.57844 loss)
I0628 18:46:27.457288 17458 sgd_solver.cpp:138] Iteration 6910, lr = 0.000125
I0628 18:46:36.580758 17458 solver.cpp:243] Iteration 6920, loss = 3.09319
I0628 18:46:36.580909 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.28584 (* 1 = 2.28584 loss)
I0628 18:46:36.580917 17458 sgd_solver.cpp:138] Iteration 6920, lr = 0.000125
I0628 18:46:45.715591 17458 solver.cpp:243] Iteration 6930, loss = 3.51344
I0628 18:46:45.715615 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.38526 (* 1 = 1.38526 loss)
I0628 18:46:45.715623 17458 sgd_solver.cpp:138] Iteration 6930, lr = 0.000125
I0628 18:46:54.818850 17458 solver.cpp:243] Iteration 6940, loss = 3.12523
I0628 18:46:54.818873 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.32565 (* 1 = 3.32565 loss)
I0628 18:46:54.818881 17458 sgd_solver.cpp:138] Iteration 6940, lr = 0.000125
I0628 18:47:03.948880 17458 solver.cpp:243] Iteration 6950, loss = 4.00504
I0628 18:47:03.948905 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.46008 (* 1 = 2.46008 loss)
I0628 18:47:03.948912 17458 sgd_solver.cpp:138] Iteration 6950, lr = 0.000125
I0628 18:47:13.064874 17458 solver.cpp:243] Iteration 6960, loss = 3.21352
I0628 18:47:13.065018 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.88393 (* 1 = 2.88393 loss)
I0628 18:47:13.065062 17458 sgd_solver.cpp:138] Iteration 6960, lr = 0.000125
I0628 18:47:22.200603 17458 solver.cpp:243] Iteration 6970, loss = 3.0857
I0628 18:47:22.200628 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.28195 (* 1 = 4.28195 loss)
I0628 18:47:22.200635 17458 sgd_solver.cpp:138] Iteration 6970, lr = 0.000125
I0628 18:47:31.307677 17458 solver.cpp:243] Iteration 6980, loss = 4.12175
I0628 18:47:31.307701 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.61182 (* 1 = 6.61182 loss)
I0628 18:47:31.307708 17458 sgd_solver.cpp:138] Iteration 6980, lr = 0.000125
I0628 18:47:40.438599 17458 solver.cpp:243] Iteration 6990, loss = 3.16987
I0628 18:47:40.438624 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.34846 (* 1 = 4.34846 loss)
I0628 18:47:40.438632 17458 sgd_solver.cpp:138] Iteration 6990, lr = 0.000125
I0628 18:47:48.826678 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_7000.caffemodel
I0628 18:47:48.911849 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_7000.solverstate
I0628 18:47:48.946311 17458 solver.cpp:433] Iteration 7000, Testing net (#0)
I0628 18:47:48.946419 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 18:50:54.776737 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.282905
I0628 18:50:55.563313 17458 solver.cpp:243] Iteration 7000, loss = 3.29349
I0628 18:50:55.563339 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.31203 (* 1 = 3.31203 loss)
I0628 18:50:55.563347 17458 sgd_solver.cpp:138] Iteration 7000, lr = 0.000125
I0628 18:51:04.694730 17458 solver.cpp:243] Iteration 7010, loss = 4.01171
I0628 18:51:04.694756 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.17238 (* 1 = 3.17238 loss)
I0628 18:51:04.694762 17458 sgd_solver.cpp:138] Iteration 7010, lr = 0.000125
I0628 18:51:13.797626 17458 solver.cpp:243] Iteration 7020, loss = 3.18173
I0628 18:51:13.797652 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.91456 (* 1 = 4.91456 loss)
I0628 18:51:13.797659 17458 sgd_solver.cpp:138] Iteration 7020, lr = 0.000125
I0628 18:51:22.920222 17458 solver.cpp:243] Iteration 7030, loss = 3.03246
I0628 18:51:22.920245 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.10817 (* 1 = 3.10817 loss)
I0628 18:51:22.920253 17458 sgd_solver.cpp:138] Iteration 7030, lr = 0.000125
I0628 18:51:32.039778 17458 solver.cpp:243] Iteration 7040, loss = 3.37872
I0628 18:51:32.039914 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.83341 (* 1 = 2.83341 loss)
I0628 18:51:32.039923 17458 sgd_solver.cpp:138] Iteration 7040, lr = 0.000125
I0628 18:51:41.182637 17458 solver.cpp:243] Iteration 7050, loss = 3.90076
I0628 18:51:41.182662 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.95038 (* 1 = 3.95038 loss)
I0628 18:51:41.182668 17458 sgd_solver.cpp:138] Iteration 7050, lr = 0.000125
I0628 18:51:50.284852 17458 solver.cpp:243] Iteration 7060, loss = 2.95611
I0628 18:51:50.284875 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.27839 (* 1 = 3.27839 loss)
I0628 18:51:50.284883 17458 sgd_solver.cpp:138] Iteration 7060, lr = 0.000125
I0628 18:51:59.408653 17458 solver.cpp:243] Iteration 7070, loss = 3.16263
I0628 18:51:59.408679 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.0704 (* 1 = 4.0704 loss)
I0628 18:51:59.408685 17458 sgd_solver.cpp:138] Iteration 7070, lr = 0.000125
I0628 18:52:08.517508 17458 solver.cpp:243] Iteration 7080, loss = 3.21167
I0628 18:52:08.517657 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.47126 (* 1 = 1.47126 loss)
I0628 18:52:08.517665 17458 sgd_solver.cpp:138] Iteration 7080, lr = 0.000125
I0628 18:52:17.638262 17458 solver.cpp:243] Iteration 7090, loss = 3.41023
I0628 18:52:17.638288 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.27151 (* 1 = 2.27151 loss)
I0628 18:52:17.638295 17458 sgd_solver.cpp:138] Iteration 7090, lr = 0.000125
I0628 18:52:26.741748 17458 solver.cpp:243] Iteration 7100, loss = 3.29574
I0628 18:52:26.741773 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.50873 (* 1 = 3.50873 loss)
I0628 18:52:26.741781 17458 sgd_solver.cpp:138] Iteration 7100, lr = 0.000125
I0628 18:52:35.886693 17458 solver.cpp:243] Iteration 7110, loss = 4.26799
I0628 18:52:35.886718 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.44108 (* 1 = 5.44108 loss)
I0628 18:52:35.886744 17458 sgd_solver.cpp:138] Iteration 7110, lr = 0.000125
I0628 18:52:45.018767 17458 solver.cpp:243] Iteration 7120, loss = 3.62496
I0628 18:52:45.018900 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.43672 (* 1 = 3.43672 loss)
I0628 18:52:45.018908 17458 sgd_solver.cpp:138] Iteration 7120, lr = 0.000125
I0628 18:52:54.180801 17458 solver.cpp:243] Iteration 7130, loss = 3.03404
I0628 18:52:54.180830 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.29968 (* 1 = 4.29968 loss)
I0628 18:52:54.180837 17458 sgd_solver.cpp:138] Iteration 7130, lr = 0.000125
I0628 18:53:03.326778 17458 solver.cpp:243] Iteration 7140, loss = 3.6963
I0628 18:53:03.326802 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.99588 (* 1 = 2.99588 loss)
I0628 18:53:03.326826 17458 sgd_solver.cpp:138] Iteration 7140, lr = 0.000125
I0628 18:53:12.494910 17458 solver.cpp:243] Iteration 7150, loss = 3.27371
I0628 18:53:12.494933 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.87933 (* 1 = 3.87933 loss)
I0628 18:53:12.494940 17458 sgd_solver.cpp:138] Iteration 7150, lr = 0.000125
I0628 18:53:21.628036 17458 solver.cpp:243] Iteration 7160, loss = 3.13842
I0628 18:53:21.628199 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.21052 (* 1 = 2.21052 loss)
I0628 18:53:21.628208 17458 sgd_solver.cpp:138] Iteration 7160, lr = 0.000125
I0628 18:53:30.767946 17458 solver.cpp:243] Iteration 7170, loss = 3.17381
I0628 18:53:30.767969 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.4651 (* 1 = 3.4651 loss)
I0628 18:53:30.767995 17458 sgd_solver.cpp:138] Iteration 7170, lr = 0.000125
I0628 18:53:39.874928 17458 solver.cpp:243] Iteration 7180, loss = 3.48943
I0628 18:53:39.874953 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.14382 (* 1 = 4.14382 loss)
I0628 18:53:39.874961 17458 sgd_solver.cpp:138] Iteration 7180, lr = 0.000125
I0628 18:53:49.015357 17458 solver.cpp:243] Iteration 7190, loss = 3.23401
I0628 18:53:49.015380 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53887 (* 1 = 3.53887 loss)
I0628 18:53:49.015405 17458 sgd_solver.cpp:138] Iteration 7190, lr = 0.000125
I0628 18:53:58.149096 17458 solver.cpp:243] Iteration 7200, loss = 3.76435
I0628 18:53:58.149293 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.85009 (* 1 = 3.85009 loss)
I0628 18:53:58.149302 17458 sgd_solver.cpp:138] Iteration 7200, lr = 0.000125
I0628 18:54:07.302451 17458 solver.cpp:243] Iteration 7210, loss = 3.01162
I0628 18:54:07.302495 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.98589 (* 1 = 3.98589 loss)
I0628 18:54:07.302502 17458 sgd_solver.cpp:138] Iteration 7210, lr = 0.000125
I0628 18:54:16.433001 17458 solver.cpp:243] Iteration 7220, loss = 2.94267
I0628 18:54:16.433024 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.24202 (* 1 = 3.24202 loss)
I0628 18:54:16.433049 17458 sgd_solver.cpp:138] Iteration 7220, lr = 0.000125
I0628 18:54:25.591073 17458 solver.cpp:243] Iteration 7230, loss = 3.14364
I0628 18:54:25.591099 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.67571 (* 1 = 3.67571 loss)
I0628 18:54:25.591123 17458 sgd_solver.cpp:138] Iteration 7230, lr = 0.000125
I0628 18:54:34.723575 17458 solver.cpp:243] Iteration 7240, loss = 3.68628
I0628 18:54:34.723716 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.13957 (* 1 = 2.13957 loss)
I0628 18:54:34.723726 17458 sgd_solver.cpp:138] Iteration 7240, lr = 0.000125
I0628 18:54:43.876098 17458 solver.cpp:243] Iteration 7250, loss = 3.28381
I0628 18:54:43.876123 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.00399 (* 1 = 2.00399 loss)
I0628 18:54:43.876148 17458 sgd_solver.cpp:138] Iteration 7250, lr = 0.000125
I0628 18:54:53.008832 17458 solver.cpp:243] Iteration 7260, loss = 2.75902
I0628 18:54:53.008869 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.91143 (* 1 = 2.91143 loss)
I0628 18:54:53.008895 17458 sgd_solver.cpp:138] Iteration 7260, lr = 0.000125
I0628 18:55:02.161164 17458 solver.cpp:243] Iteration 7270, loss = 3.59113
I0628 18:55:02.161191 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.56197 (* 1 = 1.56197 loss)
I0628 18:55:02.161198 17458 sgd_solver.cpp:138] Iteration 7270, lr = 0.000125
I0628 18:55:11.275490 17458 solver.cpp:243] Iteration 7280, loss = 3.16943
I0628 18:55:11.275650 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.21828 (* 1 = 2.21828 loss)
I0628 18:55:11.275677 17458 sgd_solver.cpp:138] Iteration 7280, lr = 0.000125
I0628 18:55:20.428515 17458 solver.cpp:243] Iteration 7290, loss = 3.45364
I0628 18:55:20.428539 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.99195 (* 1 = 1.99195 loss)
I0628 18:55:20.428563 17458 sgd_solver.cpp:138] Iteration 7290, lr = 0.000125
I0628 18:55:29.556339 17458 solver.cpp:243] Iteration 7300, loss = 3.26299
I0628 18:55:29.556361 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.04876 (* 1 = 3.04876 loss)
I0628 18:55:29.556386 17458 sgd_solver.cpp:138] Iteration 7300, lr = 0.000125
I0628 18:55:38.710995 17458 solver.cpp:243] Iteration 7310, loss = 3.73778
I0628 18:55:38.711032 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.43917 (* 1 = 4.43917 loss)
I0628 18:55:38.711058 17458 sgd_solver.cpp:138] Iteration 7310, lr = 0.000125
I0628 18:55:47.841712 17458 solver.cpp:243] Iteration 7320, loss = 3.06295
I0628 18:55:47.841881 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.00422 (* 1 = 3.00422 loss)
I0628 18:55:47.841902 17458 sgd_solver.cpp:138] Iteration 7320, lr = 0.000125
I0628 18:55:56.998405 17458 solver.cpp:243] Iteration 7330, loss = 4.40085
I0628 18:55:56.998430 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.46308 (* 1 = 4.46308 loss)
I0628 18:55:56.998437 17458 sgd_solver.cpp:138] Iteration 7330, lr = 0.000125
I0628 18:56:06.134560 17458 solver.cpp:243] Iteration 7340, loss = 2.63847
I0628 18:56:06.134584 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.37603 (* 1 = 1.37603 loss)
I0628 18:56:06.134609 17458 sgd_solver.cpp:138] Iteration 7340, lr = 0.000125
I0628 18:56:15.291252 17458 solver.cpp:243] Iteration 7350, loss = 3.14447
I0628 18:56:15.291276 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.69796 (* 1 = 3.69796 loss)
I0628 18:56:15.291301 17458 sgd_solver.cpp:138] Iteration 7350, lr = 0.000125
I0628 18:56:24.415037 17458 solver.cpp:243] Iteration 7360, loss = 2.86247
I0628 18:56:24.415202 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.02688 (* 1 = 4.02688 loss)
I0628 18:56:24.415211 17458 sgd_solver.cpp:138] Iteration 7360, lr = 0.000125
I0628 18:56:33.548586 17458 solver.cpp:243] Iteration 7370, loss = 3.02762
I0628 18:56:33.548610 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.06386 (* 1 = 3.06386 loss)
I0628 18:56:33.548617 17458 sgd_solver.cpp:138] Iteration 7370, lr = 0.000125
I0628 18:56:42.674052 17458 solver.cpp:243] Iteration 7380, loss = 2.65503
I0628 18:56:42.674075 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.64121 (* 1 = 2.64121 loss)
I0628 18:56:42.674100 17458 sgd_solver.cpp:138] Iteration 7380, lr = 0.000125
I0628 18:56:51.828603 17458 solver.cpp:243] Iteration 7390, loss = 3.62528
I0628 18:56:51.828627 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.78263 (* 1 = 5.78263 loss)
I0628 18:56:51.828653 17458 sgd_solver.cpp:138] Iteration 7390, lr = 0.000125
I0628 18:57:00.964521 17458 solver.cpp:243] Iteration 7400, loss = 4.00483
I0628 18:57:00.964675 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.08981 (* 1 = 2.08981 loss)
I0628 18:57:00.964684 17458 sgd_solver.cpp:138] Iteration 7400, lr = 0.000125
I0628 18:57:10.124742 17458 solver.cpp:243] Iteration 7410, loss = 3.41377
I0628 18:57:10.124766 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.0441 (* 1 = 3.0441 loss)
I0628 18:57:10.124791 17458 sgd_solver.cpp:138] Iteration 7410, lr = 0.000125
I0628 18:57:19.250627 17458 solver.cpp:243] Iteration 7420, loss = 3.31025
I0628 18:57:19.250653 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.30843 (* 1 = 3.30843 loss)
I0628 18:57:19.250677 17458 sgd_solver.cpp:138] Iteration 7420, lr = 0.000125
I0628 18:57:28.406035 17458 solver.cpp:243] Iteration 7430, loss = 3.11356
I0628 18:57:28.406087 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.20613 (* 1 = 2.20613 loss)
I0628 18:57:28.406111 17458 sgd_solver.cpp:138] Iteration 7430, lr = 0.000125
I0628 18:57:37.536289 17458 solver.cpp:243] Iteration 7440, loss = 3.13958
I0628 18:57:37.536464 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.73287 (* 1 = 3.73287 loss)
I0628 18:57:37.536491 17458 sgd_solver.cpp:138] Iteration 7440, lr = 0.000125
I0628 18:57:46.689018 17458 solver.cpp:243] Iteration 7450, loss = 3.48637
I0628 18:57:46.689041 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.93277 (* 1 = 2.93277 loss)
I0628 18:57:46.689067 17458 sgd_solver.cpp:138] Iteration 7450, lr = 0.000125
I0628 18:57:55.824790 17458 solver.cpp:243] Iteration 7460, loss = 3.50336
I0628 18:57:55.824812 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.09018 (* 1 = 3.09018 loss)
I0628 18:57:55.824838 17458 sgd_solver.cpp:138] Iteration 7460, lr = 0.000125
I0628 18:58:04.976733 17458 solver.cpp:243] Iteration 7470, loss = 3.08413
I0628 18:58:04.976758 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.48198 (* 1 = 3.48198 loss)
I0628 18:58:04.976783 17458 sgd_solver.cpp:138] Iteration 7470, lr = 0.000125
I0628 18:58:14.109412 17458 solver.cpp:243] Iteration 7480, loss = 3.27628
I0628 18:58:14.109555 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.63001 (* 1 = 4.63001 loss)
I0628 18:58:14.109563 17458 sgd_solver.cpp:138] Iteration 7480, lr = 0.000125
I0628 18:58:23.256986 17458 solver.cpp:243] Iteration 7490, loss = 3.29425
I0628 18:58:23.257030 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.73369 (* 1 = 4.73369 loss)
I0628 18:58:23.257037 17458 sgd_solver.cpp:138] Iteration 7490, lr = 0.000125
I0628 18:58:32.377773 17458 solver.cpp:243] Iteration 7500, loss = 4.29966
I0628 18:58:32.377796 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.30127 (* 1 = 4.30127 loss)
I0628 18:58:32.377821 17458 sgd_solver.cpp:138] Iteration 7500, lr = 0.000125
I0628 18:58:41.518795 17458 solver.cpp:243] Iteration 7510, loss = 3.2841
I0628 18:58:41.518821 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.08419 (* 1 = 4.08419 loss)
I0628 18:58:41.518846 17458 sgd_solver.cpp:138] Iteration 7510, lr = 0.000125
I0628 18:58:50.643034 17458 solver.cpp:243] Iteration 7520, loss = 3.16133
I0628 18:58:50.643220 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.03639 (* 1 = 4.03639 loss)
I0628 18:58:50.643245 17458 sgd_solver.cpp:138] Iteration 7520, lr = 0.000125
I0628 18:58:59.800954 17458 solver.cpp:243] Iteration 7530, loss = 2.77488
I0628 18:58:59.800977 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.09872 (* 1 = 3.09872 loss)
I0628 18:58:59.801003 17458 sgd_solver.cpp:138] Iteration 7530, lr = 0.000125
I0628 18:59:08.930084 17458 solver.cpp:243] Iteration 7540, loss = 3.20853
I0628 18:59:08.930107 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.75276 (* 1 = 2.75276 loss)
I0628 18:59:08.930114 17458 sgd_solver.cpp:138] Iteration 7540, lr = 0.000125
I0628 18:59:18.085568 17458 solver.cpp:243] Iteration 7550, loss = 3.13033
I0628 18:59:18.085593 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.50791 (* 1 = 3.50791 loss)
I0628 18:59:18.085618 17458 sgd_solver.cpp:138] Iteration 7550, lr = 0.000125
I0628 18:59:27.205835 17458 solver.cpp:243] Iteration 7560, loss = 3.53236
I0628 18:59:27.205986 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.22857 (* 1 = 3.22857 loss)
I0628 18:59:27.206010 17458 sgd_solver.cpp:138] Iteration 7560, lr = 0.000125
I0628 18:59:36.336459 17458 solver.cpp:243] Iteration 7570, loss = 3.10037
I0628 18:59:36.336485 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.73169 (* 1 = 1.73169 loss)
I0628 18:59:36.336493 17458 sgd_solver.cpp:138] Iteration 7570, lr = 0.000125
I0628 18:59:45.444794 17458 solver.cpp:243] Iteration 7580, loss = 3.43167
I0628 18:59:45.444818 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.65845 (* 1 = 3.65845 loss)
I0628 18:59:45.444842 17458 sgd_solver.cpp:138] Iteration 7580, lr = 0.000125
I0628 18:59:54.576774 17458 solver.cpp:243] Iteration 7590, loss = 3.73355
I0628 18:59:54.576799 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.70286 (* 1 = 1.70286 loss)
I0628 18:59:54.576807 17458 sgd_solver.cpp:138] Iteration 7590, lr = 0.000125
I0628 19:00:03.714043 17458 solver.cpp:243] Iteration 7600, loss = 3.0622
I0628 19:00:03.714208 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.68302 (* 1 = 2.68302 loss)
I0628 19:00:03.714236 17458 sgd_solver.cpp:138] Iteration 7600, lr = 0.000125
I0628 19:00:12.871049 17458 solver.cpp:243] Iteration 7610, loss = 3.05615
I0628 19:00:12.871073 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3861 (* 1 = 3.3861 loss)
I0628 19:00:12.871098 17458 sgd_solver.cpp:138] Iteration 7610, lr = 0.000125
I0628 19:00:22.001595 17458 solver.cpp:243] Iteration 7620, loss = 3.05614
I0628 19:00:22.001619 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.73246 (* 1 = 2.73246 loss)
I0628 19:00:22.001644 17458 sgd_solver.cpp:138] Iteration 7620, lr = 0.000125
I0628 19:00:31.135165 17458 solver.cpp:243] Iteration 7630, loss = 3.43554
I0628 19:00:31.135190 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.33147 (* 1 = 4.33147 loss)
I0628 19:00:31.135215 17458 sgd_solver.cpp:138] Iteration 7630, lr = 0.000125
I0628 19:00:40.243036 17458 solver.cpp:243] Iteration 7640, loss = 3.05387
I0628 19:00:40.243146 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.87408 (* 1 = 2.87408 loss)
I0628 19:00:40.243155 17458 sgd_solver.cpp:138] Iteration 7640, lr = 0.000125
I0628 19:00:49.380340 17458 solver.cpp:243] Iteration 7650, loss = 3.78578
I0628 19:00:49.380365 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.50678 (* 1 = 3.50678 loss)
I0628 19:00:49.380391 17458 sgd_solver.cpp:138] Iteration 7650, lr = 0.000125
I0628 19:00:58.493868 17458 solver.cpp:243] Iteration 7660, loss = 2.7048
I0628 19:00:58.493894 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.24752 (* 1 = 1.24752 loss)
I0628 19:00:58.493902 17458 sgd_solver.cpp:138] Iteration 7660, lr = 0.000125
I0628 19:01:07.631027 17458 solver.cpp:243] Iteration 7670, loss = 3.71973
I0628 19:01:07.631052 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.43279 (* 1 = 4.43279 loss)
I0628 19:01:07.631101 17458 sgd_solver.cpp:138] Iteration 7670, lr = 0.000125
I0628 19:01:16.762835 17458 solver.cpp:243] Iteration 7680, loss = 2.61483
I0628 19:01:16.763033 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.9145 (* 1 = 2.9145 loss)
I0628 19:01:16.763042 17458 sgd_solver.cpp:138] Iteration 7680, lr = 0.000125
I0628 19:01:25.913720 17458 solver.cpp:243] Iteration 7690, loss = 3.10913
I0628 19:01:25.913744 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.39882 (* 1 = 4.39882 loss)
I0628 19:01:25.913769 17458 sgd_solver.cpp:138] Iteration 7690, lr = 0.000125
I0628 19:01:35.039638 17458 solver.cpp:243] Iteration 7700, loss = 3.44251
I0628 19:01:35.039662 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.36354 (* 1 = 2.36354 loss)
I0628 19:01:35.039687 17458 sgd_solver.cpp:138] Iteration 7700, lr = 0.000125
I0628 19:01:44.194869 17458 solver.cpp:243] Iteration 7710, loss = 2.98851
I0628 19:01:44.194913 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.48314 (* 1 = 3.48314 loss)
I0628 19:01:44.194938 17458 sgd_solver.cpp:138] Iteration 7710, lr = 0.000125
I0628 19:01:53.334493 17458 solver.cpp:243] Iteration 7720, loss = 3.52008
I0628 19:01:53.334628 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.26126 (* 1 = 2.26126 loss)
I0628 19:01:53.334650 17458 sgd_solver.cpp:138] Iteration 7720, lr = 0.000125
I0628 19:02:02.490914 17458 solver.cpp:243] Iteration 7730, loss = 3.13891
I0628 19:02:02.490939 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.39285 (* 1 = 1.39285 loss)
I0628 19:02:02.490947 17458 sgd_solver.cpp:138] Iteration 7730, lr = 0.000125
I0628 19:02:11.622249 17458 solver.cpp:243] Iteration 7740, loss = 3.31347
I0628 19:02:11.622275 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.21024 (* 1 = 2.21024 loss)
I0628 19:02:11.622300 17458 sgd_solver.cpp:138] Iteration 7740, lr = 0.000125
I0628 19:02:20.765743 17458 solver.cpp:243] Iteration 7750, loss = 3.70575
I0628 19:02:20.765767 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.44736 (* 1 = 4.44736 loss)
I0628 19:02:20.765792 17458 sgd_solver.cpp:138] Iteration 7750, lr = 0.000125
I0628 19:02:29.883479 17458 solver.cpp:243] Iteration 7760, loss = 3.34654
I0628 19:02:29.883611 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.84879 (* 1 = 3.84879 loss)
I0628 19:02:29.883620 17458 sgd_solver.cpp:138] Iteration 7760, lr = 0.000125
I0628 19:02:39.016607 17458 solver.cpp:243] Iteration 7770, loss = 2.68541
I0628 19:02:39.016630 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.28174 (* 1 = 2.28174 loss)
I0628 19:02:39.016638 17458 sgd_solver.cpp:138] Iteration 7770, lr = 0.000125
I0628 19:02:48.126930 17458 solver.cpp:243] Iteration 7780, loss = 3.67386
I0628 19:02:48.126952 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.85467 (* 1 = 2.85467 loss)
I0628 19:02:48.126977 17458 sgd_solver.cpp:138] Iteration 7780, lr = 0.000125
I0628 19:02:57.282377 17458 solver.cpp:243] Iteration 7790, loss = 3.40438
I0628 19:02:57.282402 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.36269 (* 1 = 4.36269 loss)
I0628 19:02:57.282428 17458 sgd_solver.cpp:138] Iteration 7790, lr = 0.000125
I0628 19:03:06.418283 17458 solver.cpp:243] Iteration 7800, loss = 2.99587
I0628 19:03:06.418442 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.5425 (* 1 = 3.5425 loss)
I0628 19:03:06.418468 17458 sgd_solver.cpp:138] Iteration 7800, lr = 0.000125
I0628 19:03:15.576102 17458 solver.cpp:243] Iteration 7810, loss = 2.98426
I0628 19:03:15.576125 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.40972 (* 1 = 3.40972 loss)
I0628 19:03:15.576150 17458 sgd_solver.cpp:138] Iteration 7810, lr = 0.000125
I0628 19:03:24.707917 17458 solver.cpp:243] Iteration 7820, loss = 3.59413
I0628 19:03:24.707942 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.46108 (* 1 = 2.46108 loss)
I0628 19:03:24.707967 17458 sgd_solver.cpp:138] Iteration 7820, lr = 0.000125
I0628 19:03:33.858621 17458 solver.cpp:243] Iteration 7830, loss = 2.80345
I0628 19:03:33.858645 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.37627 (* 1 = 3.37627 loss)
I0628 19:03:33.858670 17458 sgd_solver.cpp:138] Iteration 7830, lr = 0.000125
I0628 19:03:42.991940 17458 solver.cpp:243] Iteration 7840, loss = 4.10645
I0628 19:03:42.992137 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.79253 (* 1 = 5.79253 loss)
I0628 19:03:42.992146 17458 sgd_solver.cpp:138] Iteration 7840, lr = 0.000125
I0628 19:03:52.148960 17458 solver.cpp:243] Iteration 7850, loss = 2.6091
I0628 19:03:52.148983 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.37428 (* 1 = 3.37428 loss)
I0628 19:03:52.149008 17458 sgd_solver.cpp:138] Iteration 7850, lr = 0.000125
I0628 19:04:01.285392 17458 solver.cpp:243] Iteration 7860, loss = 3.30462
I0628 19:04:01.285415 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.80298 (* 1 = 4.80298 loss)
I0628 19:04:01.285440 17458 sgd_solver.cpp:138] Iteration 7860, lr = 0.000125
I0628 19:04:10.443305 17458 solver.cpp:243] Iteration 7870, loss = 3.22384
I0628 19:04:10.443331 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.26822 (* 1 = 2.26822 loss)
I0628 19:04:10.443356 17458 sgd_solver.cpp:138] Iteration 7870, lr = 0.000125
I0628 19:04:19.576856 17458 solver.cpp:243] Iteration 7880, loss = 3.25279
I0628 19:04:19.577008 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.11216 (* 1 = 2.11216 loss)
I0628 19:04:19.577016 17458 sgd_solver.cpp:138] Iteration 7880, lr = 0.000125
I0628 19:04:28.715947 17458 solver.cpp:243] Iteration 7890, loss = 3.50332
I0628 19:04:28.715973 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.67701 (* 1 = 2.67701 loss)
I0628 19:04:28.715981 17458 sgd_solver.cpp:138] Iteration 7890, lr = 0.000125
I0628 19:04:37.827077 17458 solver.cpp:243] Iteration 7900, loss = 2.73957
I0628 19:04:37.827101 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.06332 (* 1 = 3.06332 loss)
I0628 19:04:37.827126 17458 sgd_solver.cpp:138] Iteration 7900, lr = 0.000125
I0628 19:04:46.984031 17458 solver.cpp:243] Iteration 7910, loss = 3.43836
I0628 19:04:46.984057 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.32036 (* 1 = 1.32036 loss)
I0628 19:04:46.984066 17458 sgd_solver.cpp:138] Iteration 7910, lr = 0.000125
I0628 19:04:56.120082 17458 solver.cpp:243] Iteration 7920, loss = 2.80946
I0628 19:04:56.120259 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.68955 (* 1 = 2.68955 loss)
I0628 19:04:56.120266 17458 sgd_solver.cpp:138] Iteration 7920, lr = 0.000125
I0628 19:05:05.278162 17458 solver.cpp:243] Iteration 7930, loss = 2.98988
I0628 19:05:05.278187 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.2607 (* 1 = 2.2607 loss)
I0628 19:05:05.278213 17458 sgd_solver.cpp:138] Iteration 7930, lr = 0.000125
I0628 19:05:14.391376 17458 solver.cpp:243] Iteration 7940, loss = 3.32758
I0628 19:05:14.391398 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.56201 (* 1 = 3.56201 loss)
I0628 19:05:14.391423 17458 sgd_solver.cpp:138] Iteration 7940, lr = 0.000125
I0628 19:05:23.548882 17458 solver.cpp:243] Iteration 7950, loss = 4.0564
I0628 19:05:23.548907 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.48335 (* 1 = 4.48335 loss)
I0628 19:05:23.548933 17458 sgd_solver.cpp:138] Iteration 7950, lr = 0.000125
I0628 19:05:32.678663 17458 solver.cpp:243] Iteration 7960, loss = 3.42501
I0628 19:05:32.678836 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.38568 (* 1 = 3.38568 loss)
I0628 19:05:32.678845 17458 sgd_solver.cpp:138] Iteration 7960, lr = 0.000125
I0628 19:05:41.824666 17458 solver.cpp:243] Iteration 7970, loss = 4.0675
I0628 19:05:41.824692 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.00027 (* 1 = 6.00027 loss)
I0628 19:05:41.824699 17458 sgd_solver.cpp:138] Iteration 7970, lr = 0.000125
I0628 19:05:50.939344 17458 solver.cpp:243] Iteration 7980, loss = 2.39269
I0628 19:05:50.939368 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.69562 (* 1 = 2.69562 loss)
I0628 19:05:50.939393 17458 sgd_solver.cpp:138] Iteration 7980, lr = 0.000125
I0628 19:06:00.092710 17458 solver.cpp:243] Iteration 7990, loss = 3.23875
I0628 19:06:00.092754 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.49474 (* 1 = 2.49474 loss)
I0628 19:06:00.092779 17458 sgd_solver.cpp:138] Iteration 7990, lr = 0.000125
I0628 19:06:08.473317 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_8000.caffemodel
I0628 19:06:08.554198 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_8000.solverstate
I0628 19:06:08.586058 17458 solver.cpp:433] Iteration 8000, Testing net (#0)
I0628 19:06:08.586184 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 19:09:13.493214 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.305672
I0628 19:09:14.276906 17458 solver.cpp:243] Iteration 8000, loss = 2.91691
I0628 19:09:14.276932 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.47011 (* 1 = 4.47011 loss)
I0628 19:09:14.276939 17458 sgd_solver.cpp:138] Iteration 8000, lr = 0.000125
I0628 19:09:23.409783 17458 solver.cpp:243] Iteration 8010, loss = 4.09031
I0628 19:09:23.409809 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.08809 (* 1 = 4.08809 loss)
I0628 19:09:23.409834 17458 sgd_solver.cpp:138] Iteration 8010, lr = 0.000125
I0628 19:09:32.525867 17458 solver.cpp:243] Iteration 8020, loss = 4.01546
I0628 19:09:32.525889 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.22478 (* 1 = 2.22478 loss)
I0628 19:09:32.525915 17458 sgd_solver.cpp:138] Iteration 8020, lr = 0.000125
I0628 19:09:41.683322 17458 solver.cpp:243] Iteration 8030, loss = 3.47609
I0628 19:09:41.683347 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.03661 (* 1 = 5.03661 loss)
I0628 19:09:41.683372 17458 sgd_solver.cpp:138] Iteration 8030, lr = 0.000125
I0628 19:09:50.821398 17458 solver.cpp:243] Iteration 8040, loss = 3.40604
I0628 19:09:50.821555 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.34729 (* 1 = 1.34729 loss)
I0628 19:09:50.821564 17458 sgd_solver.cpp:138] Iteration 8040, lr = 0.000125
I0628 19:09:59.978336 17458 solver.cpp:243] Iteration 8050, loss = 2.47344
I0628 19:09:59.978360 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.2883 (* 1 = 1.2883 loss)
I0628 19:09:59.978386 17458 sgd_solver.cpp:138] Iteration 8050, lr = 0.000125
I0628 19:10:09.109443 17458 solver.cpp:243] Iteration 8060, loss = 3.65275
I0628 19:10:09.109467 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.95528 (* 1 = 2.95528 loss)
I0628 19:10:09.109493 17458 sgd_solver.cpp:138] Iteration 8060, lr = 0.000125
I0628 19:10:18.269165 17458 solver.cpp:243] Iteration 8070, loss = 3.18924
I0628 19:10:18.269218 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.54989 (* 1 = 4.54989 loss)
I0628 19:10:18.269227 17458 sgd_solver.cpp:138] Iteration 8070, lr = 0.000125
I0628 19:10:27.403549 17458 solver.cpp:243] Iteration 8080, loss = 4.06978
I0628 19:10:27.403692 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.08044 (* 1 = 6.08044 loss)
I0628 19:10:27.403702 17458 sgd_solver.cpp:138] Iteration 8080, lr = 0.000125
I0628 19:10:36.550405 17458 solver.cpp:243] Iteration 8090, loss = 3.12204
I0628 19:10:36.550431 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.72886 (* 1 = 4.72886 loss)
I0628 19:10:36.550437 17458 sgd_solver.cpp:138] Iteration 8090, lr = 0.000125
I0628 19:10:45.660848 17458 solver.cpp:243] Iteration 8100, loss = 3.69711
I0628 19:10:45.660871 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.0563 (* 1 = 4.0563 loss)
I0628 19:10:45.660878 17458 sgd_solver.cpp:138] Iteration 8100, lr = 0.000125
I0628 19:10:54.792943 17458 solver.cpp:243] Iteration 8110, loss = 3.1662
I0628 19:10:54.792968 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.19685 (* 1 = 2.19685 loss)
I0628 19:10:54.792994 17458 sgd_solver.cpp:138] Iteration 8110, lr = 0.000125
I0628 19:11:03.914994 17458 solver.cpp:243] Iteration 8120, loss = 2.82095
I0628 19:11:03.915194 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.30802 (* 1 = 3.30802 loss)
I0628 19:11:03.915203 17458 sgd_solver.cpp:138] Iteration 8120, lr = 0.000125
I0628 19:11:13.068840 17458 solver.cpp:243] Iteration 8130, loss = 3.07855
I0628 19:11:13.068866 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.31812 (* 1 = 3.31812 loss)
I0628 19:11:13.068890 17458 sgd_solver.cpp:138] Iteration 8130, lr = 0.000125
I0628 19:11:22.200736 17458 solver.cpp:243] Iteration 8140, loss = 3.29661
I0628 19:11:22.200758 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.67927 (* 1 = 2.67927 loss)
I0628 19:11:22.200783 17458 sgd_solver.cpp:138] Iteration 8140, lr = 0.000125
I0628 19:11:31.343575 17458 solver.cpp:243] Iteration 8150, loss = 3.4654
I0628 19:11:31.343600 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.96975 (* 1 = 1.96975 loss)
I0628 19:11:31.343624 17458 sgd_solver.cpp:138] Iteration 8150, lr = 0.000125
I0628 19:11:40.449772 17458 solver.cpp:243] Iteration 8160, loss = 3.66931
I0628 19:11:40.449918 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.47154 (* 1 = 4.47154 loss)
I0628 19:11:40.449928 17458 sgd_solver.cpp:138] Iteration 8160, lr = 0.000125
I0628 19:11:49.587435 17458 solver.cpp:243] Iteration 8170, loss = 2.90231
I0628 19:11:49.587460 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.18383 (* 1 = 3.18383 loss)
I0628 19:11:49.587484 17458 sgd_solver.cpp:138] Iteration 8170, lr = 0.000125
I0628 19:11:58.694867 17458 solver.cpp:243] Iteration 8180, loss = 2.54398
I0628 19:11:58.694890 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.22255 (* 1 = 2.22255 loss)
I0628 19:11:58.694914 17458 sgd_solver.cpp:138] Iteration 8180, lr = 0.000125
I0628 19:12:07.837849 17458 solver.cpp:243] Iteration 8190, loss = 3.26326
I0628 19:12:07.837874 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.88656 (* 1 = 4.88656 loss)
I0628 19:12:07.837882 17458 sgd_solver.cpp:138] Iteration 8190, lr = 0.000125
I0628 19:12:16.963973 17458 solver.cpp:243] Iteration 8200, loss = 3.69903
I0628 19:12:16.964134 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.11402 (* 1 = 5.11402 loss)
I0628 19:12:16.964143 17458 sgd_solver.cpp:138] Iteration 8200, lr = 0.000125
I0628 19:12:26.114890 17458 solver.cpp:243] Iteration 8210, loss = 3.51387
I0628 19:12:26.114914 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.10777 (* 1 = 2.10777 loss)
I0628 19:12:26.114940 17458 sgd_solver.cpp:138] Iteration 8210, lr = 0.000125
I0628 19:12:35.247606 17458 solver.cpp:243] Iteration 8220, loss = 3.12794
I0628 19:12:35.247630 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.61018 (* 1 = 2.61018 loss)
I0628 19:12:35.247637 17458 sgd_solver.cpp:138] Iteration 8220, lr = 0.000125
I0628 19:12:44.405292 17458 solver.cpp:243] Iteration 8230, loss = 3.24421
I0628 19:12:44.405319 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.74617 (* 1 = 3.74617 loss)
I0628 19:12:44.405345 17458 sgd_solver.cpp:138] Iteration 8230, lr = 0.000125
I0628 19:12:53.537008 17458 solver.cpp:243] Iteration 8240, loss = 3.72945
I0628 19:12:53.537181 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.31514 (* 1 = 2.31514 loss)
I0628 19:12:53.537204 17458 sgd_solver.cpp:138] Iteration 8240, lr = 0.000125
I0628 19:13:02.696457 17458 solver.cpp:243] Iteration 8250, loss = 3.07672
I0628 19:13:02.696482 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.8674 (* 1 = 3.8674 loss)
I0628 19:13:02.696508 17458 sgd_solver.cpp:138] Iteration 8250, lr = 0.000125
I0628 19:13:11.827582 17458 solver.cpp:243] Iteration 8260, loss = 3.0513
I0628 19:13:11.827605 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3501 (* 1 = 3.3501 loss)
I0628 19:13:11.827612 17458 sgd_solver.cpp:138] Iteration 8260, lr = 0.000125
I0628 19:13:20.980404 17458 solver.cpp:243] Iteration 8270, loss = 3.38252
I0628 19:13:20.980427 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.18865 (* 1 = 4.18865 loss)
I0628 19:13:20.980453 17458 sgd_solver.cpp:138] Iteration 8270, lr = 0.000125
I0628 19:13:30.114603 17458 solver.cpp:243] Iteration 8280, loss = 3.01983
I0628 19:13:30.114775 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.0191 (* 1 = 4.0191 loss)
I0628 19:13:30.114786 17458 sgd_solver.cpp:138] Iteration 8280, lr = 0.000125
I0628 19:13:39.256095 17458 solver.cpp:243] Iteration 8290, loss = 4.06592
I0628 19:13:39.256121 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.88811 (* 1 = 5.88811 loss)
I0628 19:13:39.256129 17458 sgd_solver.cpp:138] Iteration 8290, lr = 0.000125
I0628 19:13:48.375005 17458 solver.cpp:243] Iteration 8300, loss = 2.8505
I0628 19:13:48.375030 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.32789 (* 1 = 3.32789 loss)
I0628 19:13:48.375056 17458 sgd_solver.cpp:138] Iteration 8300, lr = 0.000125
I0628 19:13:57.532701 17458 solver.cpp:243] Iteration 8310, loss = 2.76193
I0628 19:13:57.532725 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.28171 (* 1 = 3.28171 loss)
I0628 19:13:57.532752 17458 sgd_solver.cpp:138] Iteration 8310, lr = 0.000125
I0628 19:14:06.661361 17458 solver.cpp:243] Iteration 8320, loss = 3.25286
I0628 19:14:06.661495 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.74313 (* 1 = 2.74313 loss)
I0628 19:14:06.661517 17458 sgd_solver.cpp:138] Iteration 8320, lr = 0.000125
I0628 19:14:15.816347 17458 solver.cpp:243] Iteration 8330, loss = 3.453
I0628 19:14:15.816371 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.83633 (* 1 = 3.83633 loss)
I0628 19:14:15.816396 17458 sgd_solver.cpp:138] Iteration 8330, lr = 0.000125
I0628 19:14:24.943073 17458 solver.cpp:243] Iteration 8340, loss = 3.27905
I0628 19:14:24.943096 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.94896 (* 1 = 2.94896 loss)
I0628 19:14:24.943104 17458 sgd_solver.cpp:138] Iteration 8340, lr = 0.000125
I0628 19:14:34.097841 17458 solver.cpp:243] Iteration 8350, loss = 3.29423
I0628 19:14:34.097864 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.2772 (* 1 = 4.2772 loss)
I0628 19:14:34.097890 17458 sgd_solver.cpp:138] Iteration 8350, lr = 0.000125
I0628 19:14:43.230232 17458 solver.cpp:243] Iteration 8360, loss = 3.33421
I0628 19:14:43.230406 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.25795 (* 1 = 1.25795 loss)
I0628 19:14:43.230433 17458 sgd_solver.cpp:138] Iteration 8360, lr = 0.000125
I0628 19:14:52.370492 17458 solver.cpp:243] Iteration 8370, loss = 2.88889
I0628 19:14:52.370517 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.9539 (* 1 = 2.9539 loss)
I0628 19:14:52.370524 17458 sgd_solver.cpp:138] Iteration 8370, lr = 0.000125
I0628 19:15:01.482512 17458 solver.cpp:243] Iteration 8380, loss = 3.33164
I0628 19:15:01.482537 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.14156 (* 1 = 3.14156 loss)
I0628 19:15:01.482561 17458 sgd_solver.cpp:138] Iteration 8380, lr = 0.000125
I0628 19:15:10.617767 17458 solver.cpp:243] Iteration 8390, loss = 3.49379
I0628 19:15:10.617794 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.41861 (* 1 = 4.41861 loss)
I0628 19:15:10.617799 17458 sgd_solver.cpp:138] Iteration 8390, lr = 0.000125
I0628 19:15:19.749626 17458 solver.cpp:243] Iteration 8400, loss = 4.3447
I0628 19:15:19.749804 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.82997 (* 1 = 7.82997 loss)
I0628 19:15:19.749830 17458 sgd_solver.cpp:138] Iteration 8400, lr = 0.000125
I0628 19:15:28.904949 17458 solver.cpp:243] Iteration 8410, loss = 2.59676
I0628 19:15:28.904975 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.70184 (* 1 = 2.70184 loss)
I0628 19:15:28.905000 17458 sgd_solver.cpp:138] Iteration 8410, lr = 0.000125
I0628 19:15:38.032192 17458 solver.cpp:243] Iteration 8420, loss = 4.00438
I0628 19:15:38.032217 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.82778 (* 1 = 2.82778 loss)
I0628 19:15:38.032243 17458 sgd_solver.cpp:138] Iteration 8420, lr = 0.000125
I0628 19:15:47.193686 17458 solver.cpp:243] Iteration 8430, loss = 2.79838
I0628 19:15:47.193711 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.20807 (* 1 = 2.20807 loss)
I0628 19:15:47.193717 17458 sgd_solver.cpp:138] Iteration 8430, lr = 0.000125
I0628 19:15:56.325438 17458 solver.cpp:243] Iteration 8440, loss = 2.8471
I0628 19:15:56.325636 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.463 (* 1 = 2.463 loss)
I0628 19:15:56.325644 17458 sgd_solver.cpp:138] Iteration 8440, lr = 0.000125
I0628 19:16:05.480103 17458 solver.cpp:243] Iteration 8450, loss = 3.30108
I0628 19:16:05.480129 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.69146 (* 1 = 4.69146 loss)
I0628 19:16:05.480135 17458 sgd_solver.cpp:138] Iteration 8450, lr = 0.000125
I0628 19:16:14.594128 17458 solver.cpp:243] Iteration 8460, loss = 4.0525
I0628 19:16:14.594153 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.80889 (* 1 = 4.80889 loss)
I0628 19:16:14.594161 17458 sgd_solver.cpp:138] Iteration 8460, lr = 0.000125
I0628 19:16:23.723908 17458 solver.cpp:243] Iteration 8470, loss = 2.96363
I0628 19:16:23.723934 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.95491 (* 1 = 3.95491 loss)
I0628 19:16:23.723959 17458 sgd_solver.cpp:138] Iteration 8470, lr = 0.000125
I0628 19:16:32.854631 17458 solver.cpp:243] Iteration 8480, loss = 3.70563
I0628 19:16:32.854801 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.24493 (* 1 = 5.24493 loss)
I0628 19:16:32.854809 17458 sgd_solver.cpp:138] Iteration 8480, lr = 0.000125
I0628 19:16:42.014565 17458 solver.cpp:243] Iteration 8490, loss = 3.14996
I0628 19:16:42.014591 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.03002 (* 1 = 4.03002 loss)
I0628 19:16:42.014616 17458 sgd_solver.cpp:138] Iteration 8490, lr = 0.000125
I0628 19:16:51.147034 17458 solver.cpp:243] Iteration 8500, loss = 3.14069
I0628 19:16:51.147058 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.97542 (* 1 = 2.97542 loss)
I0628 19:16:51.147083 17458 sgd_solver.cpp:138] Iteration 8500, lr = 0.000125
I0628 19:17:00.304148 17458 solver.cpp:243] Iteration 8510, loss = 3.02623
I0628 19:17:00.304172 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.12986 (* 1 = 2.12986 loss)
I0628 19:17:00.304198 17458 sgd_solver.cpp:138] Iteration 8510, lr = 0.000125
I0628 19:17:09.437574 17458 solver.cpp:243] Iteration 8520, loss = 3.4038
I0628 19:17:09.437754 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.57971 (* 1 = 3.57971 loss)
I0628 19:17:09.437781 17458 sgd_solver.cpp:138] Iteration 8520, lr = 0.000125
I0628 19:17:18.599983 17458 solver.cpp:243] Iteration 8530, loss = 2.83057
I0628 19:17:18.600008 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.79555 (* 1 = 1.79555 loss)
I0628 19:17:18.600033 17458 sgd_solver.cpp:138] Iteration 8530, lr = 0.000125
I0628 19:17:27.718180 17458 solver.cpp:243] Iteration 8540, loss = 3.44154
I0628 19:17:27.718206 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.11132 (* 1 = 4.11132 loss)
I0628 19:17:27.718214 17458 sgd_solver.cpp:138] Iteration 8540, lr = 0.000125
I0628 19:17:36.856289 17458 solver.cpp:243] Iteration 8550, loss = 3.14029
I0628 19:17:36.856313 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.3422 (* 1 = 2.3422 loss)
I0628 19:17:36.856338 17458 sgd_solver.cpp:138] Iteration 8550, lr = 0.000125
I0628 19:17:45.965943 17458 solver.cpp:243] Iteration 8560, loss = 3.2761
I0628 19:17:45.966092 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.47586 (* 1 = 1.47586 loss)
I0628 19:17:45.966100 17458 sgd_solver.cpp:138] Iteration 8560, lr = 0.000125
I0628 19:17:55.099862 17458 solver.cpp:243] Iteration 8570, loss = 3.23853
I0628 19:17:55.099906 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.86105 (* 1 = 1.86105 loss)
I0628 19:17:55.099931 17458 sgd_solver.cpp:138] Iteration 8570, lr = 0.000125
I0628 19:18:04.222489 17458 solver.cpp:243] Iteration 8580, loss = 3.67935
I0628 19:18:04.222513 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.17734 (* 1 = 3.17734 loss)
I0628 19:18:04.222538 17458 sgd_solver.cpp:138] Iteration 8580, lr = 0.000125
I0628 19:18:13.380337 17458 solver.cpp:243] Iteration 8590, loss = 2.99208
I0628 19:18:13.380362 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.87114 (* 1 = 5.87114 loss)
I0628 19:18:13.380386 17458 sgd_solver.cpp:138] Iteration 8590, lr = 0.000125
I0628 19:18:22.512262 17458 solver.cpp:243] Iteration 8600, loss = 3.67314
I0628 19:18:22.512445 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.26284 (* 1 = 4.26284 loss)
I0628 19:18:22.512472 17458 sgd_solver.cpp:138] Iteration 8600, lr = 0.000125
I0628 19:18:31.664852 17458 solver.cpp:243] Iteration 8610, loss = 4.20395
I0628 19:18:31.664876 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.06061 (* 1 = 4.06061 loss)
I0628 19:18:31.664901 17458 sgd_solver.cpp:138] Iteration 8610, lr = 0.000125
I0628 19:18:40.788760 17458 solver.cpp:243] Iteration 8620, loss = 2.83112
I0628 19:18:40.788784 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.62071 (* 1 = 2.62071 loss)
I0628 19:18:40.788810 17458 sgd_solver.cpp:138] Iteration 8620, lr = 0.000125
I0628 19:18:49.942636 17458 solver.cpp:243] Iteration 8630, loss = 2.56333
I0628 19:18:49.942688 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.53777 (* 1 = 1.53777 loss)
I0628 19:18:49.942708 17458 sgd_solver.cpp:138] Iteration 8630, lr = 0.000125
I0628 19:18:59.071231 17458 solver.cpp:243] Iteration 8640, loss = 3.17131
I0628 19:18:59.071370 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.5138 (* 1 = 3.5138 loss)
I0628 19:18:59.071378 17458 sgd_solver.cpp:138] Iteration 8640, lr = 0.000125
I0628 19:19:08.230083 17458 solver.cpp:243] Iteration 8650, loss = 3.08831
I0628 19:19:08.230106 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.95241 (* 1 = 2.95241 loss)
I0628 19:19:08.230131 17458 sgd_solver.cpp:138] Iteration 8650, lr = 0.000125
I0628 19:19:17.357492 17458 solver.cpp:243] Iteration 8660, loss = 3.60719
I0628 19:19:17.357519 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3729 (* 1 = 3.3729 loss)
I0628 19:19:17.357545 17458 sgd_solver.cpp:138] Iteration 8660, lr = 0.000125
I0628 19:19:26.487933 17458 solver.cpp:243] Iteration 8670, loss = 3.5302
I0628 19:19:26.487958 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.47494 (* 1 = 3.47494 loss)
I0628 19:19:26.487965 17458 sgd_solver.cpp:138] Iteration 8670, lr = 0.000125
I0628 19:19:35.599861 17458 solver.cpp:243] Iteration 8680, loss = 3.31028
I0628 19:19:35.600040 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.28685 (* 1 = 1.28685 loss)
I0628 19:19:35.600067 17458 sgd_solver.cpp:138] Iteration 8680, lr = 0.000125
I0628 19:19:44.732642 17458 solver.cpp:243] Iteration 8690, loss = 2.70647
I0628 19:19:44.732668 17458 solver.cpp:259]     Train net output #0: mbox_loss = 0.916048 (* 1 = 0.916048 loss)
I0628 19:19:44.732676 17458 sgd_solver.cpp:138] Iteration 8690, lr = 0.000125
I0628 19:19:53.840394 17458 solver.cpp:243] Iteration 8700, loss = 3.00905
I0628 19:19:53.840418 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.4996 (* 1 = 1.4996 loss)
I0628 19:19:53.840443 17458 sgd_solver.cpp:138] Iteration 8700, lr = 0.000125
I0628 19:20:02.981391 17458 solver.cpp:243] Iteration 8710, loss = 3.37806
I0628 19:20:02.981416 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.71471 (* 1 = 3.71471 loss)
I0628 19:20:02.981441 17458 sgd_solver.cpp:138] Iteration 8710, lr = 0.000125
I0628 19:20:12.117791 17458 solver.cpp:243] Iteration 8720, loss = 2.94687
I0628 19:20:12.117985 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.4309 (* 1 = 2.4309 loss)
I0628 19:20:12.117992 17458 sgd_solver.cpp:138] Iteration 8720, lr = 0.000125
I0628 19:20:21.272321 17458 solver.cpp:243] Iteration 8730, loss = 3.2365
I0628 19:20:21.272346 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.03136 (* 1 = 5.03136 loss)
I0628 19:20:21.272370 17458 sgd_solver.cpp:138] Iteration 8730, lr = 0.000125
I0628 19:20:30.405731 17458 solver.cpp:243] Iteration 8740, loss = 3.66875
I0628 19:20:30.405755 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.35129 (* 1 = 3.35129 loss)
I0628 19:20:30.405761 17458 sgd_solver.cpp:138] Iteration 8740, lr = 0.000125
I0628 19:20:39.552763 17458 solver.cpp:243] Iteration 8750, loss = 3.23782
I0628 19:20:39.552788 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.22352 (* 1 = 2.22352 loss)
I0628 19:20:39.552814 17458 sgd_solver.cpp:138] Iteration 8750, lr = 0.000125
I0628 19:20:48.685214 17458 solver.cpp:243] Iteration 8760, loss = 3.13776
I0628 19:20:48.685408 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.46449 (* 1 = 3.46449 loss)
I0628 19:20:48.685417 17458 sgd_solver.cpp:138] Iteration 8760, lr = 0.000125
I0628 19:20:57.832020 17458 solver.cpp:243] Iteration 8770, loss = 3.77501
I0628 19:20:57.832046 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.80876 (* 1 = 4.80876 loss)
I0628 19:20:57.832070 17458 sgd_solver.cpp:138] Iteration 8770, lr = 0.000125
I0628 19:21:06.967346 17458 solver.cpp:243] Iteration 8780, loss = 3.27551
I0628 19:21:06.967370 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.01313 (* 1 = 5.01313 loss)
I0628 19:21:06.967396 17458 sgd_solver.cpp:138] Iteration 8780, lr = 0.000125
I0628 19:21:16.122871 17458 solver.cpp:243] Iteration 8790, loss = 3.62014
I0628 19:21:16.122896 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.47465 (* 1 = 1.47465 loss)
I0628 19:21:16.122921 17458 sgd_solver.cpp:138] Iteration 8790, lr = 0.000125
I0628 19:21:25.250553 17458 solver.cpp:243] Iteration 8800, loss = 3.40963
I0628 19:21:25.250669 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3118 (* 1 = 3.3118 loss)
I0628 19:21:25.250694 17458 sgd_solver.cpp:138] Iteration 8800, lr = 0.000125
I0628 19:21:34.403955 17458 solver.cpp:243] Iteration 8810, loss = 2.89983
I0628 19:21:34.403981 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.23936 (* 1 = 3.23936 loss)
I0628 19:21:34.404006 17458 sgd_solver.cpp:138] Iteration 8810, lr = 0.000125
I0628 19:21:43.538280 17458 solver.cpp:243] Iteration 8820, loss = 2.83596
I0628 19:21:43.538303 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.50403 (* 1 = 3.50403 loss)
I0628 19:21:43.538328 17458 sgd_solver.cpp:138] Iteration 8820, lr = 0.000125
I0628 19:21:52.694949 17458 solver.cpp:243] Iteration 8830, loss = 3.34484
I0628 19:21:52.694975 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.09102 (* 1 = 5.09102 loss)
I0628 19:21:52.695000 17458 sgd_solver.cpp:138] Iteration 8830, lr = 0.000125
I0628 19:22:01.808226 17458 solver.cpp:243] Iteration 8840, loss = 3.81029
I0628 19:22:01.808395 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.06518 (* 1 = 3.06518 loss)
I0628 19:22:01.808423 17458 sgd_solver.cpp:138] Iteration 8840, lr = 0.000125
I0628 19:22:10.949951 17458 solver.cpp:243] Iteration 8850, loss = 3.85968
I0628 19:22:10.949976 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.10006 (* 1 = 3.10006 loss)
I0628 19:22:10.950002 17458 sgd_solver.cpp:138] Iteration 8850, lr = 0.000125
I0628 19:22:20.081250 17458 solver.cpp:243] Iteration 8860, loss = 2.23458
I0628 19:22:20.081274 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.89755 (* 1 = 3.89755 loss)
I0628 19:22:20.081300 17458 sgd_solver.cpp:138] Iteration 8860, lr = 0.000125
I0628 19:22:29.240847 17458 solver.cpp:243] Iteration 8870, loss = 3.12836
I0628 19:22:29.240872 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.33683 (* 1 = 1.33683 loss)
I0628 19:22:29.240897 17458 sgd_solver.cpp:138] Iteration 8870, lr = 0.000125
I0628 19:22:38.376109 17458 solver.cpp:243] Iteration 8880, loss = 2.64843
I0628 19:22:38.376272 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.00267 (* 1 = 2.00267 loss)
I0628 19:22:38.376281 17458 sgd_solver.cpp:138] Iteration 8880, lr = 0.000125
I0628 19:22:47.527809 17458 solver.cpp:243] Iteration 8890, loss = 2.99226
I0628 19:22:47.527832 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.40853 (* 1 = 3.40853 loss)
I0628 19:22:47.527858 17458 sgd_solver.cpp:138] Iteration 8890, lr = 0.000125
I0628 19:22:56.639597 17458 solver.cpp:243] Iteration 8900, loss = 3.4146
I0628 19:22:56.639621 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.65704 (* 1 = 3.65704 loss)
I0628 19:22:56.639628 17458 sgd_solver.cpp:138] Iteration 8900, lr = 0.000125
I0628 19:23:05.774900 17458 solver.cpp:243] Iteration 8910, loss = 2.88266
I0628 19:23:05.774924 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.66018 (* 1 = 4.66018 loss)
I0628 19:23:05.774950 17458 sgd_solver.cpp:138] Iteration 8910, lr = 0.000125
I0628 19:23:14.902586 17458 solver.cpp:243] Iteration 8920, loss = 2.78297
I0628 19:23:14.902752 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.61076 (* 1 = 2.61076 loss)
I0628 19:23:14.902761 17458 sgd_solver.cpp:138] Iteration 8920, lr = 0.000125
I0628 19:23:24.053313 17458 solver.cpp:243] Iteration 8930, loss = 3.71307
I0628 19:23:24.053337 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.30555 (* 1 = 4.30555 loss)
I0628 19:23:24.053364 17458 sgd_solver.cpp:138] Iteration 8930, lr = 0.000125
I0628 19:23:33.186118 17458 solver.cpp:243] Iteration 8940, loss = 3.24071
I0628 19:23:33.186142 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.43792 (* 1 = 5.43792 loss)
I0628 19:23:33.186167 17458 sgd_solver.cpp:138] Iteration 8940, lr = 0.000125
I0628 19:23:42.340478 17458 solver.cpp:243] Iteration 8950, loss = 3.06577
I0628 19:23:42.340502 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.75717 (* 1 = 2.75717 loss)
I0628 19:23:42.340509 17458 sgd_solver.cpp:138] Iteration 8950, lr = 0.000125
I0628 19:23:51.448613 17458 solver.cpp:243] Iteration 8960, loss = 3.04614
I0628 19:23:51.448746 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.27387 (* 1 = 3.27387 loss)
I0628 19:23:51.448755 17458 sgd_solver.cpp:138] Iteration 8960, lr = 0.000125
I0628 19:24:00.606873 17458 solver.cpp:243] Iteration 8970, loss = 3.76772
I0628 19:24:00.606896 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.23665 (* 1 = 4.23665 loss)
I0628 19:24:00.606922 17458 sgd_solver.cpp:138] Iteration 8970, lr = 0.000125
I0628 19:24:09.743479 17458 solver.cpp:243] Iteration 8980, loss = 3.01558
I0628 19:24:09.743503 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.92118 (* 1 = 2.92118 loss)
I0628 19:24:09.743510 17458 sgd_solver.cpp:138] Iteration 8980, lr = 0.000125
I0628 19:24:18.897373 17458 solver.cpp:243] Iteration 8990, loss = 3.07861
I0628 19:24:18.897398 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.41572 (* 1 = 5.41572 loss)
I0628 19:24:18.897423 17458 sgd_solver.cpp:138] Iteration 8990, lr = 0.000125
I0628 19:24:27.278518 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_9000.caffemodel
I0628 19:24:27.359895 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_9000.solverstate
I0628 19:24:27.392045 17458 solver.cpp:433] Iteration 9000, Testing net (#0)
I0628 19:24:27.392163 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 19:27:32.262069 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.290035
I0628 19:27:33.047520 17458 solver.cpp:243] Iteration 9000, loss = 3.08832
I0628 19:27:33.047544 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.31639 (* 1 = 2.31639 loss)
I0628 19:27:33.047569 17458 sgd_solver.cpp:47] MultiStep Status: Iteration 9000, step = 3
I0628 19:27:33.047580 17458 sgd_solver.cpp:138] Iteration 9000, lr = 6.25e-05
I0628 19:27:42.198323 17458 solver.cpp:243] Iteration 9010, loss = 3.68248
I0628 19:27:42.198345 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.56644 (* 1 = 1.56644 loss)
I0628 19:27:42.198371 17458 sgd_solver.cpp:138] Iteration 9010, lr = 6.25e-05
I0628 19:27:51.328052 17458 solver.cpp:243] Iteration 9020, loss = 3.08868
I0628 19:27:51.328075 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.17983 (* 1 = 3.17983 loss)
I0628 19:27:51.328101 17458 sgd_solver.cpp:138] Iteration 9020, lr = 6.25e-05
I0628 19:28:00.477077 17458 solver.cpp:243] Iteration 9030, loss = 3.60582
I0628 19:28:00.477102 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.07562 (* 1 = 4.07562 loss)
I0628 19:28:00.477128 17458 sgd_solver.cpp:138] Iteration 9030, lr = 6.25e-05
I0628 19:28:09.615042 17458 solver.cpp:243] Iteration 9040, loss = 3.51957
I0628 19:28:09.615276 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.92794 (* 1 = 4.92794 loss)
I0628 19:28:09.615299 17458 sgd_solver.cpp:138] Iteration 9040, lr = 6.25e-05
I0628 19:28:18.769536 17458 solver.cpp:243] Iteration 9050, loss = 2.61519
I0628 19:28:18.769560 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.84112 (* 1 = 2.84112 loss)
I0628 19:28:18.769587 17458 sgd_solver.cpp:138] Iteration 9050, lr = 6.25e-05
I0628 19:28:27.904561 17458 solver.cpp:243] Iteration 9060, loss = 4.05376
I0628 19:28:27.904587 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.89682 (* 1 = 1.89682 loss)
I0628 19:28:27.904614 17458 sgd_solver.cpp:138] Iteration 9060, lr = 6.25e-05
I0628 19:28:37.059900 17458 solver.cpp:243] Iteration 9070, loss = 3.94585
I0628 19:28:37.059923 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.42715 (* 1 = 3.42715 loss)
I0628 19:28:37.059931 17458 sgd_solver.cpp:138] Iteration 9070, lr = 6.25e-05
I0628 19:28:46.182427 17458 solver.cpp:243] Iteration 9080, loss = 2.78238
I0628 19:28:46.182555 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.36303 (* 1 = 2.36303 loss)
I0628 19:28:46.182579 17458 sgd_solver.cpp:138] Iteration 9080, lr = 6.25e-05
I0628 19:28:55.341617 17458 solver.cpp:243] Iteration 9090, loss = 3.15138
I0628 19:28:55.341642 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.46311 (* 1 = 3.46311 loss)
I0628 19:28:55.341668 17458 sgd_solver.cpp:138] Iteration 9090, lr = 6.25e-05
I0628 19:29:04.467878 17458 solver.cpp:243] Iteration 9100, loss = 3.43639
I0628 19:29:04.467901 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.32923 (* 1 = 3.32923 loss)
I0628 19:29:04.467927 17458 sgd_solver.cpp:138] Iteration 9100, lr = 6.25e-05
I0628 19:29:13.623800 17458 solver.cpp:243] Iteration 9110, loss = 3.14981
I0628 19:29:13.623826 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.75357 (* 1 = 3.75357 loss)
I0628 19:29:13.623850 17458 sgd_solver.cpp:138] Iteration 9110, lr = 6.25e-05
I0628 19:29:22.759550 17458 solver.cpp:243] Iteration 9120, loss = 3.4495
I0628 19:29:22.759727 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.28212 (* 1 = 4.28212 loss)
I0628 19:29:22.759753 17458 sgd_solver.cpp:138] Iteration 9120, lr = 6.25e-05
I0628 19:29:31.907829 17458 solver.cpp:243] Iteration 9130, loss = 3.3954
I0628 19:29:31.907852 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.54112 (* 1 = 3.54112 loss)
I0628 19:29:31.907878 17458 sgd_solver.cpp:138] Iteration 9130, lr = 6.25e-05
I0628 19:29:41.037859 17458 solver.cpp:243] Iteration 9140, loss = 3.17224
I0628 19:29:41.037883 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.43588 (* 1 = 4.43588 loss)
I0628 19:29:41.037909 17458 sgd_solver.cpp:138] Iteration 9140, lr = 6.25e-05
I0628 19:29:50.193773 17458 solver.cpp:243] Iteration 9150, loss = 3.25822
I0628 19:29:50.193799 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.86598 (* 1 = 1.86598 loss)
I0628 19:29:50.193823 17458 sgd_solver.cpp:138] Iteration 9150, lr = 6.25e-05
I0628 19:29:59.325381 17458 solver.cpp:243] Iteration 9160, loss = 3.43062
I0628 19:29:59.325491 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.5422 (* 1 = 2.5422 loss)
I0628 19:29:59.325501 17458 sgd_solver.cpp:138] Iteration 9160, lr = 6.25e-05
I0628 19:30:08.463250 17458 solver.cpp:243] Iteration 9170, loss = 3.14678
I0628 19:30:08.463295 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.55054 (* 1 = 2.55054 loss)
I0628 19:30:08.463321 17458 sgd_solver.cpp:138] Iteration 9170, lr = 6.25e-05
I0628 19:30:17.573508 17458 solver.cpp:243] Iteration 9180, loss = 3.53433
I0628 19:30:17.573532 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.15861 (* 1 = 4.15861 loss)
I0628 19:30:17.573539 17458 sgd_solver.cpp:138] Iteration 9180, lr = 6.25e-05
I0628 19:30:26.706528 17458 solver.cpp:243] Iteration 9190, loss = 3.61586
I0628 19:30:26.706552 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.52685 (* 1 = 1.52685 loss)
I0628 19:30:26.706559 17458 sgd_solver.cpp:138] Iteration 9190, lr = 6.25e-05
I0628 19:30:35.823550 17458 solver.cpp:243] Iteration 9200, loss = 3.06444
I0628 19:30:35.823746 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.50638 (* 1 = 1.50638 loss)
I0628 19:30:35.823755 17458 sgd_solver.cpp:138] Iteration 9200, lr = 6.25e-05
I0628 19:30:44.976801 17458 solver.cpp:243] Iteration 9210, loss = 3.79838
I0628 19:30:44.976825 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.60631 (* 1 = 3.60631 loss)
I0628 19:30:44.976851 17458 sgd_solver.cpp:138] Iteration 9210, lr = 6.25e-05
I0628 19:30:54.107199 17458 solver.cpp:243] Iteration 9220, loss = 3.34656
I0628 19:30:54.107223 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.61802 (* 1 = 3.61802 loss)
I0628 19:30:54.107249 17458 sgd_solver.cpp:138] Iteration 9220, lr = 6.25e-05
I0628 19:31:03.268864 17458 solver.cpp:243] Iteration 9230, loss = 2.97813
I0628 19:31:03.268888 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.33834 (* 1 = 3.33834 loss)
I0628 19:31:03.268914 17458 sgd_solver.cpp:138] Iteration 9230, lr = 6.25e-05
I0628 19:31:12.402690 17458 solver.cpp:243] Iteration 9240, loss = 2.65809
I0628 19:31:12.402868 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.40969 (* 1 = 2.40969 loss)
I0628 19:31:12.402895 17458 sgd_solver.cpp:138] Iteration 9240, lr = 6.25e-05
I0628 19:31:21.542007 17458 solver.cpp:243] Iteration 9250, loss = 3.74692
I0628 19:31:21.542032 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.20361 (* 1 = 3.20361 loss)
I0628 19:31:21.542057 17458 sgd_solver.cpp:138] Iteration 9250, lr = 6.25e-05
I0628 19:31:30.659529 17458 solver.cpp:243] Iteration 9260, loss = 3.24264
I0628 19:31:30.659552 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.18146 (* 1 = 2.18146 loss)
I0628 19:31:30.659579 17458 sgd_solver.cpp:138] Iteration 9260, lr = 6.25e-05
I0628 19:31:39.819880 17458 solver.cpp:243] Iteration 9270, loss = 3.15873
I0628 19:31:39.819905 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.3407 (* 1 = 4.3407 loss)
I0628 19:31:39.819931 17458 sgd_solver.cpp:138] Iteration 9270, lr = 6.25e-05
I0628 19:31:48.950136 17458 solver.cpp:243] Iteration 9280, loss = 3.20606
I0628 19:31:48.950332 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.35369 (* 1 = 3.35369 loss)
I0628 19:31:48.950359 17458 sgd_solver.cpp:138] Iteration 9280, lr = 6.25e-05
I0628 19:31:58.108367 17458 solver.cpp:243] Iteration 9290, loss = 3.33045
I0628 19:31:58.108392 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53137 (* 1 = 3.53137 loss)
I0628 19:31:58.108417 17458 sgd_solver.cpp:138] Iteration 9290, lr = 6.25e-05
I0628 19:32:07.237813 17458 solver.cpp:243] Iteration 9300, loss = 3.407
I0628 19:32:07.237838 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.20689 (* 1 = 2.20689 loss)
I0628 19:32:07.237845 17458 sgd_solver.cpp:138] Iteration 9300, lr = 6.25e-05
I0628 19:32:16.374231 17458 solver.cpp:243] Iteration 9310, loss = 3.32398
I0628 19:32:16.374256 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.41963 (* 1 = 3.41963 loss)
I0628 19:32:16.374264 17458 sgd_solver.cpp:138] Iteration 9310, lr = 6.25e-05
I0628 19:32:25.489322 17458 solver.cpp:243] Iteration 9320, loss = 3.51727
I0628 19:32:25.489476 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.38601 (* 1 = 2.38601 loss)
I0628 19:32:25.489504 17458 sgd_solver.cpp:138] Iteration 9320, lr = 6.25e-05
I0628 19:32:34.633292 17458 solver.cpp:243] Iteration 9330, loss = 2.61008
I0628 19:32:34.633338 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.36369 (* 1 = 1.36369 loss)
I0628 19:32:34.633364 17458 sgd_solver.cpp:138] Iteration 9330, lr = 6.25e-05
I0628 19:32:43.767411 17458 solver.cpp:243] Iteration 9340, loss = 3.14647
I0628 19:32:43.767436 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.34492 (* 1 = 2.34492 loss)
I0628 19:32:43.767460 17458 sgd_solver.cpp:138] Iteration 9340, lr = 6.25e-05
I0628 19:32:52.906879 17458 solver.cpp:243] Iteration 9350, loss = 3.57091
I0628 19:32:52.906904 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.74637 (* 1 = 3.74637 loss)
I0628 19:32:52.906911 17458 sgd_solver.cpp:138] Iteration 9350, lr = 6.25e-05
I0628 19:33:02.019613 17458 solver.cpp:243] Iteration 9360, loss = 3.34961
I0628 19:33:02.019809 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.98069 (* 1 = 2.98069 loss)
I0628 19:33:02.019817 17458 sgd_solver.cpp:138] Iteration 9360, lr = 6.25e-05
I0628 19:33:11.150723 17458 solver.cpp:243] Iteration 9370, loss = 2.93122
I0628 19:33:11.150748 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.40927 (* 1 = 2.40927 loss)
I0628 19:33:11.150756 17458 sgd_solver.cpp:138] Iteration 9370, lr = 6.25e-05
I0628 19:33:20.266170 17458 solver.cpp:243] Iteration 9380, loss = 3.47519
I0628 19:33:20.266194 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.51284 (* 1 = 3.51284 loss)
I0628 19:33:20.266221 17458 sgd_solver.cpp:138] Iteration 9380, lr = 6.25e-05
I0628 19:33:29.399457 17458 solver.cpp:243] Iteration 9390, loss = 2.77737
I0628 19:33:29.399480 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.25054 (* 1 = 2.25054 loss)
I0628 19:33:29.399505 17458 sgd_solver.cpp:138] Iteration 9390, lr = 6.25e-05
I0628 19:33:38.528805 17458 solver.cpp:243] Iteration 9400, loss = 3.44582
I0628 19:33:38.528997 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.09452 (* 1 = 4.09452 loss)
I0628 19:33:38.529022 17458 sgd_solver.cpp:138] Iteration 9400, lr = 6.25e-05
I0628 19:33:47.684104 17458 solver.cpp:243] Iteration 9410, loss = 3.59693
I0628 19:33:47.684129 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.7455 (* 1 = 4.7455 loss)
I0628 19:33:47.684150 17458 sgd_solver.cpp:138] Iteration 9410, lr = 6.25e-05
I0628 19:33:56.812887 17458 solver.cpp:243] Iteration 9420, loss = 3.61629
I0628 19:33:56.812911 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.31277 (* 1 = 3.31277 loss)
I0628 19:33:56.812935 17458 sgd_solver.cpp:138] Iteration 9420, lr = 6.25e-05
I0628 19:34:05.971459 17458 solver.cpp:243] Iteration 9430, loss = 3.93958
I0628 19:34:05.971482 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.92336 (* 1 = 2.92336 loss)
I0628 19:34:05.971508 17458 sgd_solver.cpp:138] Iteration 9430, lr = 6.25e-05
I0628 19:34:15.104912 17458 solver.cpp:243] Iteration 9440, loss = 3.67084
I0628 19:34:15.105046 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.12552 (* 1 = 2.12552 loss)
I0628 19:34:15.105067 17458 sgd_solver.cpp:138] Iteration 9440, lr = 6.25e-05
I0628 19:34:24.261162 17458 solver.cpp:243] Iteration 9450, loss = 3.58118
I0628 19:34:24.261186 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.69174 (* 1 = 4.69174 loss)
I0628 19:34:24.261193 17458 sgd_solver.cpp:138] Iteration 9450, lr = 6.25e-05
I0628 19:34:33.387588 17458 solver.cpp:243] Iteration 9460, loss = 3.00048
I0628 19:34:33.387611 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.6837 (* 1 = 3.6837 loss)
I0628 19:34:33.387637 17458 sgd_solver.cpp:138] Iteration 9460, lr = 6.25e-05
I0628 19:34:42.543926 17458 solver.cpp:243] Iteration 9470, loss = 3.0797
I0628 19:34:42.543948 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.79479 (* 1 = 3.79479 loss)
I0628 19:34:42.543974 17458 sgd_solver.cpp:138] Iteration 9470, lr = 6.25e-05
I0628 19:34:51.671236 17458 solver.cpp:243] Iteration 9480, loss = 3.70357
I0628 19:34:51.671324 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.64647 (* 1 = 3.64647 loss)
I0628 19:34:51.671351 17458 sgd_solver.cpp:138] Iteration 9480, lr = 6.25e-05
I0628 19:35:00.816154 17458 solver.cpp:243] Iteration 9490, loss = 3.7212
I0628 19:35:00.816179 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.71911 (* 1 = 2.71911 loss)
I0628 19:35:00.816185 17458 sgd_solver.cpp:138] Iteration 9490, lr = 6.25e-05
I0628 19:35:09.948310 17458 solver.cpp:243] Iteration 9500, loss = 3.28627
I0628 19:35:09.948334 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.21556 (* 1 = 4.21556 loss)
I0628 19:35:09.948341 17458 sgd_solver.cpp:138] Iteration 9500, lr = 6.25e-05
I0628 19:35:19.107192 17458 solver.cpp:243] Iteration 9510, loss = 3.19709
I0628 19:35:19.107218 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.88626 (* 1 = 1.88626 loss)
I0628 19:35:19.107264 17458 sgd_solver.cpp:138] Iteration 9510, lr = 6.25e-05
I0628 19:35:28.234855 17458 solver.cpp:243] Iteration 9520, loss = 2.76506
I0628 19:35:28.235023 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.13108 (* 1 = 3.13108 loss)
I0628 19:35:28.235059 17458 sgd_solver.cpp:138] Iteration 9520, lr = 6.25e-05
I0628 19:35:37.361244 17458 solver.cpp:243] Iteration 9530, loss = 3.38692
I0628 19:35:37.361269 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.41226 (* 1 = 4.41226 loss)
I0628 19:35:37.361277 17458 sgd_solver.cpp:138] Iteration 9530, lr = 6.25e-05
I0628 19:35:46.490669 17458 solver.cpp:243] Iteration 9540, loss = 3.4277
I0628 19:35:46.490694 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.27023 (* 1 = 4.27023 loss)
I0628 19:35:46.490720 17458 sgd_solver.cpp:138] Iteration 9540, lr = 6.25e-05
I0628 19:35:55.637657 17458 solver.cpp:243] Iteration 9550, loss = 3.40921
I0628 19:35:55.637681 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.33849 (* 1 = 3.33849 loss)
I0628 19:35:55.637707 17458 sgd_solver.cpp:138] Iteration 9550, lr = 6.25e-05
I0628 19:36:04.770581 17458 solver.cpp:243] Iteration 9560, loss = 2.78706
I0628 19:36:04.770748 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.57913 (* 1 = 4.57913 loss)
I0628 19:36:04.770756 17458 sgd_solver.cpp:138] Iteration 9560, lr = 6.25e-05
I0628 19:36:13.915467 17458 solver.cpp:243] Iteration 9570, loss = 3.76136
I0628 19:36:13.915490 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.8779 (* 1 = 5.8779 loss)
I0628 19:36:13.915515 17458 sgd_solver.cpp:138] Iteration 9570, lr = 6.25e-05
I0628 19:36:23.043462 17458 solver.cpp:243] Iteration 9580, loss = 2.70438
I0628 19:36:23.043486 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.33576 (* 1 = 1.33576 loss)
I0628 19:36:23.043512 17458 sgd_solver.cpp:138] Iteration 9580, lr = 6.25e-05
I0628 19:36:32.196508 17458 solver.cpp:243] Iteration 9590, loss = 3.63511
I0628 19:36:32.196534 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.23463 (* 1 = 3.23463 loss)
I0628 19:36:32.196559 17458 sgd_solver.cpp:138] Iteration 9590, lr = 6.25e-05
I0628 19:36:41.323895 17458 solver.cpp:243] Iteration 9600, loss = 3.47815
I0628 19:36:41.324039 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.66923 (* 1 = 5.66923 loss)
I0628 19:36:41.324064 17458 sgd_solver.cpp:138] Iteration 9600, lr = 6.25e-05
I0628 19:36:50.475526 17458 solver.cpp:243] Iteration 9610, loss = 3.55405
I0628 19:36:50.475553 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.78342 (* 1 = 3.78342 loss)
I0628 19:36:50.475577 17458 sgd_solver.cpp:138] Iteration 9610, lr = 6.25e-05
I0628 19:36:59.602398 17458 solver.cpp:243] Iteration 9620, loss = 3.19263
I0628 19:36:59.602423 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.6666 (* 1 = 2.6666 loss)
I0628 19:36:59.602432 17458 sgd_solver.cpp:138] Iteration 9620, lr = 6.25e-05
I0628 19:37:08.759203 17458 solver.cpp:243] Iteration 9630, loss = 2.83728
I0628 19:37:08.759228 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.94598 (* 1 = 2.94598 loss)
I0628 19:37:08.759254 17458 sgd_solver.cpp:138] Iteration 9630, lr = 6.25e-05
I0628 19:37:17.898162 17458 solver.cpp:243] Iteration 9640, loss = 3.73584
I0628 19:37:17.898357 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.68854 (* 1 = 4.68854 loss)
I0628 19:37:17.898366 17458 sgd_solver.cpp:138] Iteration 9640, lr = 6.25e-05
I0628 19:37:27.050329 17458 solver.cpp:243] Iteration 9650, loss = 2.61646
I0628 19:37:27.050354 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.15894 (* 1 = 1.15894 loss)
I0628 19:37:27.050380 17458 sgd_solver.cpp:138] Iteration 9650, lr = 6.25e-05
I0628 19:37:36.174872 17458 solver.cpp:243] Iteration 9660, loss = 3.04291
I0628 19:37:36.174896 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.06125 (* 1 = 3.06125 loss)
I0628 19:37:36.174922 17458 sgd_solver.cpp:138] Iteration 9660, lr = 6.25e-05
I0628 19:37:45.319667 17458 solver.cpp:243] Iteration 9670, loss = 3.8737
I0628 19:37:45.319694 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.69444 (* 1 = 6.69444 loss)
I0628 19:37:45.319701 17458 sgd_solver.cpp:138] Iteration 9670, lr = 6.25e-05
I0628 19:37:54.431708 17458 solver.cpp:243] Iteration 9680, loss = 4.07583
I0628 19:37:54.431886 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.82742 (* 1 = 3.82742 loss)
I0628 19:37:54.431896 17458 sgd_solver.cpp:138] Iteration 9680, lr = 6.25e-05
I0628 19:38:03.587052 17458 solver.cpp:243] Iteration 9690, loss = 3.74281
I0628 19:38:03.587076 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.39555 (* 1 = 3.39555 loss)
I0628 19:38:03.587102 17458 sgd_solver.cpp:138] Iteration 9690, lr = 6.25e-05
I0628 19:38:12.723816 17458 solver.cpp:243] Iteration 9700, loss = 4.25767
I0628 19:38:12.723840 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.58485 (* 1 = 4.58485 loss)
I0628 19:38:12.723866 17458 sgd_solver.cpp:138] Iteration 9700, lr = 6.25e-05
I0628 19:38:21.875140 17458 solver.cpp:243] Iteration 9710, loss = 3.27165
I0628 19:38:21.875165 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.19196 (* 1 = 3.19196 loss)
I0628 19:38:21.875191 17458 sgd_solver.cpp:138] Iteration 9710, lr = 6.25e-05
I0628 19:38:31.008242 17458 solver.cpp:243] Iteration 9720, loss = 3.19874
I0628 19:38:31.008366 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.94104 (* 1 = 2.94104 loss)
I0628 19:38:31.008375 17458 sgd_solver.cpp:138] Iteration 9720, lr = 6.25e-05
I0628 19:38:40.162402 17458 solver.cpp:243] Iteration 9730, loss = 3.17108
I0628 19:38:40.162426 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.24349 (* 1 = 4.24349 loss)
I0628 19:38:40.162452 17458 sgd_solver.cpp:138] Iteration 9730, lr = 6.25e-05
I0628 19:38:49.278527 17458 solver.cpp:243] Iteration 9740, loss = 3.66526
I0628 19:38:49.278550 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.14109 (* 1 = 4.14109 loss)
I0628 19:38:49.278575 17458 sgd_solver.cpp:138] Iteration 9740, lr = 6.25e-05
I0628 19:38:58.409552 17458 solver.cpp:243] Iteration 9750, loss = 3.18332
I0628 19:38:58.409577 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.07079 (* 1 = 3.07079 loss)
I0628 19:38:58.409584 17458 sgd_solver.cpp:138] Iteration 9750, lr = 6.25e-05
I0628 19:39:07.525043 17458 solver.cpp:243] Iteration 9760, loss = 3.58171
I0628 19:39:07.525215 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.77592 (* 1 = 2.77592 loss)
I0628 19:39:07.525243 17458 sgd_solver.cpp:138] Iteration 9760, lr = 6.25e-05
I0628 19:39:16.658640 17458 solver.cpp:243] Iteration 9770, loss = 3.0797
I0628 19:39:16.658665 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.52977 (* 1 = 4.52977 loss)
I0628 19:39:16.658674 17458 sgd_solver.cpp:138] Iteration 9770, lr = 6.25e-05
I0628 19:39:25.768697 17458 solver.cpp:243] Iteration 9780, loss = 3.1301
I0628 19:39:25.768721 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.62162 (* 1 = 3.62162 loss)
I0628 19:39:25.768746 17458 sgd_solver.cpp:138] Iteration 9780, lr = 6.25e-05
I0628 19:39:34.915720 17458 solver.cpp:243] Iteration 9790, loss = 3.15029
I0628 19:39:34.915742 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.48623 (* 1 = 4.48623 loss)
I0628 19:39:34.915768 17458 sgd_solver.cpp:138] Iteration 9790, lr = 6.25e-05
I0628 19:39:44.050001 17458 solver.cpp:243] Iteration 9800, loss = 3.48305
I0628 19:39:44.050163 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.62652 (* 1 = 2.62652 loss)
I0628 19:39:44.050171 17458 sgd_solver.cpp:138] Iteration 9800, lr = 6.25e-05
I0628 19:39:53.209933 17458 solver.cpp:243] Iteration 9810, loss = 3.60998
I0628 19:39:53.209957 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.89838 (* 1 = 1.89838 loss)
I0628 19:39:53.209983 17458 sgd_solver.cpp:138] Iteration 9810, lr = 6.25e-05
I0628 19:40:02.339833 17458 solver.cpp:243] Iteration 9820, loss = 3.49568
I0628 19:40:02.339856 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.36042 (* 1 = 4.36042 loss)
I0628 19:40:02.339882 17458 sgd_solver.cpp:138] Iteration 9820, lr = 6.25e-05
I0628 19:40:11.494040 17458 solver.cpp:243] Iteration 9830, loss = 3.83411
I0628 19:40:11.494065 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.53163 (* 1 = 1.53163 loss)
I0628 19:40:11.494089 17458 sgd_solver.cpp:138] Iteration 9830, lr = 6.25e-05
I0628 19:40:20.629062 17458 solver.cpp:243] Iteration 9840, loss = 3.02589
I0628 19:40:20.629216 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.20078 (* 1 = 2.20078 loss)
I0628 19:40:20.629243 17458 sgd_solver.cpp:138] Iteration 9840, lr = 6.25e-05
I0628 19:40:29.780550 17458 solver.cpp:243] Iteration 9850, loss = 3.39497
I0628 19:40:29.780575 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.00872 (* 1 = 2.00872 loss)
I0628 19:40:29.780601 17458 sgd_solver.cpp:138] Iteration 9850, lr = 6.25e-05
I0628 19:40:38.910198 17458 solver.cpp:243] Iteration 9860, loss = 3.59061
I0628 19:40:38.910221 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.54544 (* 1 = 3.54544 loss)
I0628 19:40:38.910248 17458 sgd_solver.cpp:138] Iteration 9860, lr = 6.25e-05
I0628 19:40:48.065270 17458 solver.cpp:243] Iteration 9870, loss = 3.62629
I0628 19:40:48.065295 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.20207 (* 1 = 4.20207 loss)
I0628 19:40:48.065325 17458 sgd_solver.cpp:138] Iteration 9870, lr = 6.25e-05
I0628 19:40:57.192940 17458 solver.cpp:243] Iteration 9880, loss = 3.42033
I0628 19:40:57.193086 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.66795 (* 1 = 4.66795 loss)
I0628 19:40:57.193096 17458 sgd_solver.cpp:138] Iteration 9880, lr = 6.25e-05
I0628 19:41:06.353629 17458 solver.cpp:243] Iteration 9890, loss = 3.3865
I0628 19:41:06.353653 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.38832 (* 1 = 3.38832 loss)
I0628 19:41:06.353662 17458 sgd_solver.cpp:138] Iteration 9890, lr = 6.25e-05
I0628 19:41:15.488087 17458 solver.cpp:243] Iteration 9900, loss = 2.68804
I0628 19:41:15.488111 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.72131 (* 1 = 1.72131 loss)
I0628 19:41:15.488137 17458 sgd_solver.cpp:138] Iteration 9900, lr = 6.25e-05
I0628 19:41:24.646546 17458 solver.cpp:243] Iteration 9910, loss = 3.36001
I0628 19:41:24.646571 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.00739 (* 1 = 4.00739 loss)
I0628 19:41:24.646597 17458 sgd_solver.cpp:138] Iteration 9910, lr = 6.25e-05
I0628 19:41:33.770795 17458 solver.cpp:243] Iteration 9920, loss = 3.45919
I0628 19:41:33.770956 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.47372 (* 1 = 3.47372 loss)
I0628 19:41:33.770984 17458 sgd_solver.cpp:138] Iteration 9920, lr = 6.25e-05
I0628 19:41:42.925607 17458 solver.cpp:243] Iteration 9930, loss = 3.63411
I0628 19:41:42.925633 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.81749 (* 1 = 3.81749 loss)
I0628 19:41:42.925659 17458 sgd_solver.cpp:138] Iteration 9930, lr = 6.25e-05
I0628 19:41:52.051534 17458 solver.cpp:243] Iteration 9940, loss = 3.62393
I0628 19:41:52.051558 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.88477 (* 1 = 1.88477 loss)
I0628 19:41:52.051582 17458 sgd_solver.cpp:138] Iteration 9940, lr = 6.25e-05
I0628 19:42:01.199225 17458 solver.cpp:243] Iteration 9950, loss = 3.33205
I0628 19:42:01.199250 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.03216 (* 1 = 4.03216 loss)
I0628 19:42:01.199276 17458 sgd_solver.cpp:138] Iteration 9950, lr = 6.25e-05
I0628 19:42:10.336913 17458 solver.cpp:243] Iteration 9960, loss = 2.95761
I0628 19:42:10.337131 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.27191 (* 1 = 1.27191 loss)
I0628 19:42:10.337141 17458 sgd_solver.cpp:138] Iteration 9960, lr = 6.25e-05
I0628 19:42:19.493541 17458 solver.cpp:243] Iteration 9970, loss = 2.71851
I0628 19:42:19.493584 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.37703 (* 1 = 1.37703 loss)
I0628 19:42:19.493592 17458 sgd_solver.cpp:138] Iteration 9970, lr = 6.25e-05
I0628 19:42:28.624025 17458 solver.cpp:243] Iteration 9980, loss = 3.22734
I0628 19:42:28.624050 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.88556 (* 1 = 2.88556 loss)
I0628 19:42:28.624076 17458 sgd_solver.cpp:138] Iteration 9980, lr = 6.25e-05
I0628 19:42:37.765830 17458 solver.cpp:243] Iteration 9990, loss = 3.82709
I0628 19:42:37.765854 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.85271 (* 1 = 3.85271 loss)
I0628 19:42:37.765880 17458 sgd_solver.cpp:138] Iteration 9990, lr = 6.25e-05
I0628 19:42:46.144754 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_10000.caffemodel
I0628 19:42:46.226394 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_10000.solverstate
I0628 19:42:46.258816 17458 solver.cpp:433] Iteration 10000, Testing net (#0)
I0628 19:42:46.258975 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 19:45:51.509418 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.314053
I0628 19:45:52.299082 17458 solver.cpp:243] Iteration 10000, loss = 3.29115
I0628 19:45:52.299105 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.26482 (* 1 = 3.26482 loss)
I0628 19:45:52.299132 17458 sgd_solver.cpp:138] Iteration 10000, lr = 6.25e-05
I0628 19:46:01.462796 17458 solver.cpp:243] Iteration 10010, loss = 3.20985
I0628 19:46:01.462821 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.16298 (* 1 = 4.16298 loss)
I0628 19:46:01.462846 17458 sgd_solver.cpp:138] Iteration 10010, lr = 6.25e-05
I0628 19:46:10.595463 17458 solver.cpp:243] Iteration 10020, loss = 3.9299
I0628 19:46:10.595485 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.96236 (* 1 = 3.96236 loss)
I0628 19:46:10.595525 17458 sgd_solver.cpp:138] Iteration 10020, lr = 6.25e-05
I0628 19:46:19.758787 17458 solver.cpp:243] Iteration 10030, loss = 2.62409
I0628 19:46:19.758811 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.44218 (* 1 = 2.44218 loss)
I0628 19:46:19.758837 17458 sgd_solver.cpp:138] Iteration 10030, lr = 6.25e-05
I0628 19:46:28.896878 17458 solver.cpp:243] Iteration 10040, loss = 3.95254
I0628 19:46:28.897051 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.71521 (* 1 = 3.71521 loss)
I0628 19:46:28.897060 17458 sgd_solver.cpp:138] Iteration 10040, lr = 6.25e-05
I0628 19:46:38.059723 17458 solver.cpp:243] Iteration 10050, loss = 2.89775
I0628 19:46:38.059748 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.76199 (* 1 = 3.76199 loss)
I0628 19:46:38.059774 17458 sgd_solver.cpp:138] Iteration 10050, lr = 6.25e-05
I0628 19:46:47.199803 17458 solver.cpp:243] Iteration 10060, loss = 3.29326
I0628 19:46:47.199826 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.79226 (* 1 = 3.79226 loss)
I0628 19:46:47.199853 17458 sgd_solver.cpp:138] Iteration 10060, lr = 6.25e-05
I0628 19:46:56.361003 17458 solver.cpp:243] Iteration 10070, loss = 3.98036
I0628 19:46:56.361027 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.64416 (* 1 = 2.64416 loss)
I0628 19:46:56.361053 17458 sgd_solver.cpp:138] Iteration 10070, lr = 6.25e-05
I0628 19:47:05.496819 17458 solver.cpp:243] Iteration 10080, loss = 3.34946
I0628 19:47:05.496978 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.18884 (* 1 = 4.18884 loss)
I0628 19:47:05.497004 17458 sgd_solver.cpp:138] Iteration 10080, lr = 6.25e-05
I0628 19:47:14.670042 17458 solver.cpp:243] Iteration 10090, loss = 3.43715
I0628 19:47:14.670065 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.20043 (* 1 = 4.20043 loss)
I0628 19:47:14.670091 17458 sgd_solver.cpp:138] Iteration 10090, lr = 6.25e-05
I0628 19:47:23.810701 17458 solver.cpp:243] Iteration 10100, loss = 2.88272
I0628 19:47:23.810726 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.77726 (* 1 = 3.77726 loss)
I0628 19:47:23.810751 17458 sgd_solver.cpp:138] Iteration 10100, lr = 6.25e-05
I0628 19:47:32.970274 17458 solver.cpp:243] Iteration 10110, loss = 3.15513
I0628 19:47:32.970299 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.66244 (* 1 = 2.66244 loss)
I0628 19:47:32.970324 17458 sgd_solver.cpp:138] Iteration 10110, lr = 6.25e-05
I0628 19:47:42.110199 17458 solver.cpp:243] Iteration 10120, loss = 3.34829
I0628 19:47:42.110363 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.17608 (* 1 = 3.17608 loss)
I0628 19:47:42.110373 17458 sgd_solver.cpp:138] Iteration 10120, lr = 6.25e-05
I0628 19:47:51.273607 17458 solver.cpp:243] Iteration 10130, loss = 3.21429
I0628 19:47:51.273631 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.02091 (* 1 = 2.02091 loss)
I0628 19:47:51.273658 17458 sgd_solver.cpp:138] Iteration 10130, lr = 6.25e-05
I0628 19:48:00.411579 17458 solver.cpp:243] Iteration 10140, loss = 3.08506
I0628 19:48:00.411603 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.31301 (* 1 = 5.31301 loss)
I0628 19:48:00.411629 17458 sgd_solver.cpp:138] Iteration 10140, lr = 6.25e-05
I0628 19:48:09.578528 17458 solver.cpp:243] Iteration 10150, loss = 4.07651
I0628 19:48:09.578553 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.43496 (* 1 = 1.43496 loss)
I0628 19:48:09.578578 17458 sgd_solver.cpp:138] Iteration 10150, lr = 6.25e-05
I0628 19:48:18.717785 17458 solver.cpp:243] Iteration 10160, loss = 3.09395
I0628 19:48:18.717947 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.33795 (* 1 = 5.33795 loss)
I0628 19:48:18.717957 17458 sgd_solver.cpp:138] Iteration 10160, lr = 6.25e-05
I0628 19:48:27.875038 17458 solver.cpp:243] Iteration 10170, loss = 3.2955
I0628 19:48:27.875063 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.03209 (* 1 = 3.03209 loss)
I0628 19:48:27.875090 17458 sgd_solver.cpp:138] Iteration 10170, lr = 6.25e-05
I0628 19:48:37.012279 17458 solver.cpp:243] Iteration 10180, loss = 3.21491
I0628 19:48:37.012302 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.79303 (* 1 = 3.79303 loss)
I0628 19:48:37.012328 17458 sgd_solver.cpp:138] Iteration 10180, lr = 6.25e-05
I0628 19:48:46.172914 17458 solver.cpp:243] Iteration 10190, loss = 3.38042
I0628 19:48:46.172940 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.52754 (* 1 = 4.52754 loss)
I0628 19:48:46.172967 17458 sgd_solver.cpp:138] Iteration 10190, lr = 6.25e-05
I0628 19:48:55.303153 17458 solver.cpp:243] Iteration 10200, loss = 3.23052
I0628 19:48:55.303294 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.85792 (* 1 = 2.85792 loss)
I0628 19:48:55.303303 17458 sgd_solver.cpp:138] Iteration 10200, lr = 6.25e-05
I0628 19:49:04.469323 17458 solver.cpp:243] Iteration 10210, loss = 3.88705
I0628 19:49:04.469349 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.64933 (* 1 = 6.64933 loss)
I0628 19:49:04.469375 17458 sgd_solver.cpp:138] Iteration 10210, lr = 6.25e-05
I0628 19:49:13.609474 17458 solver.cpp:243] Iteration 10220, loss = 2.77511
I0628 19:49:13.609521 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.29849 (* 1 = 1.29849 loss)
I0628 19:49:13.609529 17458 sgd_solver.cpp:138] Iteration 10220, lr = 6.25e-05
I0628 19:49:22.776509 17458 solver.cpp:243] Iteration 10230, loss = 2.72684
I0628 19:49:22.776532 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.58611 (* 1 = 2.58611 loss)
I0628 19:49:22.776558 17458 sgd_solver.cpp:138] Iteration 10230, lr = 6.25e-05
I0628 19:49:31.903120 17458 solver.cpp:243] Iteration 10240, loss = 3.83223
I0628 19:49:31.903261 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.37519 (* 1 = 3.37519 loss)
I0628 19:49:31.903270 17458 sgd_solver.cpp:138] Iteration 10240, lr = 6.25e-05
I0628 19:49:41.061647 17458 solver.cpp:243] Iteration 10250, loss = 3.21092
I0628 19:49:41.061671 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.61428 (* 1 = 3.61428 loss)
I0628 19:49:41.061697 17458 sgd_solver.cpp:138] Iteration 10250, lr = 6.25e-05
I0628 19:49:50.195399 17458 solver.cpp:243] Iteration 10260, loss = 3.67216
I0628 19:49:50.195425 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.50504 (* 1 = 1.50504 loss)
I0628 19:49:50.195451 17458 sgd_solver.cpp:138] Iteration 10260, lr = 6.25e-05
I0628 19:49:59.358585 17458 solver.cpp:243] Iteration 10270, loss = 3.54675
I0628 19:49:59.358610 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.60407 (* 1 = 2.60407 loss)
I0628 19:49:59.358618 17458 sgd_solver.cpp:138] Iteration 10270, lr = 6.25e-05
I0628 19:50:08.500674 17458 solver.cpp:243] Iteration 10280, loss = 3.38904
I0628 19:50:08.500867 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.08627 (* 1 = 2.08627 loss)
I0628 19:50:08.500880 17458 sgd_solver.cpp:138] Iteration 10280, lr = 6.25e-05
I0628 19:50:17.657500 17458 solver.cpp:243] Iteration 10290, loss = 3.59299
I0628 19:50:17.657524 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.91144 (* 1 = 1.91144 loss)
I0628 19:50:17.657550 17458 sgd_solver.cpp:138] Iteration 10290, lr = 6.25e-05
I0628 19:50:26.790367 17458 solver.cpp:243] Iteration 10300, loss = 3.85341
I0628 19:50:26.790390 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.94022 (* 1 = 2.94022 loss)
I0628 19:50:26.790416 17458 sgd_solver.cpp:138] Iteration 10300, lr = 6.25e-05
I0628 19:50:35.939584 17458 solver.cpp:243] Iteration 10310, loss = 3.67795
I0628 19:50:35.939608 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.31658 (* 1 = 2.31658 loss)
I0628 19:50:35.939635 17458 sgd_solver.cpp:138] Iteration 10310, lr = 6.25e-05
I0628 19:50:45.076848 17458 solver.cpp:243] Iteration 10320, loss = 3.42023
I0628 19:50:45.076997 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.7984 (* 1 = 3.7984 loss)
I0628 19:50:45.077023 17458 sgd_solver.cpp:138] Iteration 10320, lr = 6.25e-05
I0628 19:50:54.241034 17458 solver.cpp:243] Iteration 10330, loss = 3.35877
I0628 19:50:54.241060 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.77775 (* 1 = 6.77775 loss)
I0628 19:50:54.241086 17458 sgd_solver.cpp:138] Iteration 10330, lr = 6.25e-05
I0628 19:51:03.389400 17458 solver.cpp:243] Iteration 10340, loss = 3.80068
I0628 19:51:03.389425 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.73238 (* 1 = 1.73238 loss)
I0628 19:51:03.389451 17458 sgd_solver.cpp:138] Iteration 10340, lr = 6.25e-05
I0628 19:51:12.559764 17458 solver.cpp:243] Iteration 10350, loss = 2.67019
I0628 19:51:12.559789 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.61327 (* 1 = 1.61327 loss)
I0628 19:51:12.559815 17458 sgd_solver.cpp:138] Iteration 10350, lr = 6.25e-05
I0628 19:51:21.698902 17458 solver.cpp:243] Iteration 10360, loss = 3.15531
I0628 19:51:21.699075 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.07982 (* 1 = 3.07982 loss)
I0628 19:51:21.699084 17458 sgd_solver.cpp:138] Iteration 10360, lr = 6.25e-05
I0628 19:51:30.860718 17458 solver.cpp:243] Iteration 10370, loss = 2.86995
I0628 19:51:30.860741 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.18063 (* 1 = 3.18063 loss)
I0628 19:51:30.860767 17458 sgd_solver.cpp:138] Iteration 10370, lr = 6.25e-05
I0628 19:51:39.999068 17458 solver.cpp:243] Iteration 10380, loss = 3.76447
I0628 19:51:39.999090 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.79155 (* 1 = 3.79155 loss)
I0628 19:51:39.999116 17458 sgd_solver.cpp:138] Iteration 10380, lr = 6.25e-05
I0628 19:51:49.161401 17458 solver.cpp:243] Iteration 10390, loss = 2.96859
I0628 19:51:49.161425 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.14858 (* 1 = 4.14858 loss)
I0628 19:51:49.161451 17458 sgd_solver.cpp:138] Iteration 10390, lr = 6.25e-05
I0628 19:51:58.298763 17458 solver.cpp:243] Iteration 10400, loss = 3.99217
I0628 19:51:58.298928 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.52839 (* 1 = 2.52839 loss)
I0628 19:51:58.298959 17458 sgd_solver.cpp:138] Iteration 10400, lr = 6.25e-05
I0628 19:52:07.454119 17458 solver.cpp:243] Iteration 10410, loss = 3.31971
I0628 19:52:07.454145 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.21299 (* 1 = 3.21299 loss)
I0628 19:52:07.454171 17458 sgd_solver.cpp:138] Iteration 10410, lr = 6.25e-05
I0628 19:52:16.585871 17458 solver.cpp:243] Iteration 10420, loss = 3.16626
I0628 19:52:16.585896 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.01426 (* 1 = 3.01426 loss)
I0628 19:52:16.585922 17458 sgd_solver.cpp:138] Iteration 10420, lr = 6.25e-05
I0628 19:52:25.745409 17458 solver.cpp:243] Iteration 10430, loss = 3.34691
I0628 19:52:25.745434 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.73689 (* 1 = 2.73689 loss)
I0628 19:52:25.745460 17458 sgd_solver.cpp:138] Iteration 10430, lr = 6.25e-05
I0628 19:52:34.878711 17458 solver.cpp:243] Iteration 10440, loss = 3.6817
I0628 19:52:34.878840 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.67601 (* 1 = 1.67601 loss)
I0628 19:52:34.878849 17458 sgd_solver.cpp:138] Iteration 10440, lr = 6.25e-05
I0628 19:52:44.008787 17458 solver.cpp:243] Iteration 10450, loss = 3.46869
I0628 19:52:44.008811 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.98337 (* 1 = 2.98337 loss)
I0628 19:52:44.008837 17458 sgd_solver.cpp:138] Iteration 10450, lr = 6.25e-05
I0628 19:52:53.116063 17458 solver.cpp:243] Iteration 10460, loss = 3.1439
I0628 19:52:53.116087 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.35811 (* 1 = 4.35811 loss)
I0628 19:52:53.116096 17458 sgd_solver.cpp:138] Iteration 10460, lr = 6.25e-05
I0628 19:53:02.253496 17458 solver.cpp:243] Iteration 10470, loss = 3.23919
I0628 19:53:02.253521 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.68641 (* 1 = 1.68641 loss)
I0628 19:53:02.253547 17458 sgd_solver.cpp:138] Iteration 10470, lr = 6.25e-05
I0628 19:53:11.368961 17458 solver.cpp:243] Iteration 10480, loss = 2.8994
I0628 19:53:11.369108 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.55093 (* 1 = 2.55093 loss)
I0628 19:53:11.369117 17458 sgd_solver.cpp:138] Iteration 10480, lr = 6.25e-05
I0628 19:53:20.504230 17458 solver.cpp:243] Iteration 10490, loss = 3.18143
I0628 19:53:20.504254 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.85093 (* 1 = 3.85093 loss)
I0628 19:53:20.504281 17458 sgd_solver.cpp:138] Iteration 10490, lr = 6.25e-05
I0628 19:53:29.638810 17458 solver.cpp:243] Iteration 10500, loss = 3.8272
I0628 19:53:29.638834 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.68099 (* 1 = 3.68099 loss)
I0628 19:53:29.638860 17458 sgd_solver.cpp:138] Iteration 10500, lr = 6.25e-05
I0628 19:53:38.795073 17458 solver.cpp:243] Iteration 10510, loss = 3.39032
I0628 19:53:38.795099 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.47142 (* 1 = 4.47142 loss)
I0628 19:53:38.795125 17458 sgd_solver.cpp:138] Iteration 10510, lr = 6.25e-05
I0628 19:53:47.924010 17458 solver.cpp:243] Iteration 10520, loss = 2.25408
I0628 19:53:47.924155 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.09566 (* 1 = 3.09566 loss)
I0628 19:53:47.924178 17458 sgd_solver.cpp:138] Iteration 10520, lr = 6.25e-05
I0628 19:53:57.081619 17458 solver.cpp:243] Iteration 10530, loss = 4.0805
I0628 19:53:57.081643 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.10853 (* 1 = 7.10853 loss)
I0628 19:53:57.081687 17458 sgd_solver.cpp:138] Iteration 10530, lr = 6.25e-05
I0628 19:54:06.213505 17458 solver.cpp:243] Iteration 10540, loss = 3.33434
I0628 19:54:06.213527 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.89599 (* 1 = 2.89599 loss)
I0628 19:54:06.213553 17458 sgd_solver.cpp:138] Iteration 10540, lr = 6.25e-05
I0628 19:54:15.371264 17458 solver.cpp:243] Iteration 10550, loss = 3.22449
I0628 19:54:15.371290 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.70597 (* 1 = 3.70597 loss)
I0628 19:54:15.371317 17458 sgd_solver.cpp:138] Iteration 10550, lr = 6.25e-05
I0628 19:54:24.501466 17458 solver.cpp:243] Iteration 10560, loss = 3.52234
I0628 19:54:24.501700 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.57531 (* 1 = 2.57531 loss)
I0628 19:54:24.501710 17458 sgd_solver.cpp:138] Iteration 10560, lr = 6.25e-05
I0628 19:54:33.659023 17458 solver.cpp:243] Iteration 10570, loss = 3.23395
I0628 19:54:33.659047 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.35555 (* 1 = 5.35555 loss)
I0628 19:54:33.659072 17458 sgd_solver.cpp:138] Iteration 10570, lr = 6.25e-05
I0628 19:54:42.784317 17458 solver.cpp:243] Iteration 10580, loss = 2.82651
I0628 19:54:42.784340 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.19 (* 1 = 1.19 loss)
I0628 19:54:42.784366 17458 sgd_solver.cpp:138] Iteration 10580, lr = 6.25e-05
I0628 19:54:51.939802 17458 solver.cpp:243] Iteration 10590, loss = 3.36465
I0628 19:54:51.939827 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.49019 (* 1 = 2.49019 loss)
I0628 19:54:51.939852 17458 sgd_solver.cpp:138] Iteration 10590, lr = 6.25e-05
I0628 19:55:01.081156 17458 solver.cpp:243] Iteration 10600, loss = 4.06644
I0628 19:55:01.081336 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.9935 (* 1 = 3.9935 loss)
I0628 19:55:01.081364 17458 sgd_solver.cpp:138] Iteration 10600, lr = 6.25e-05
I0628 19:55:10.237758 17458 solver.cpp:243] Iteration 10610, loss = 2.49
I0628 19:55:10.237782 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.45616 (* 1 = 1.45616 loss)
I0628 19:55:10.237808 17458 sgd_solver.cpp:138] Iteration 10610, lr = 6.25e-05
I0628 19:55:19.372057 17458 solver.cpp:243] Iteration 10620, loss = 2.88617
I0628 19:55:19.372081 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.15099 (* 1 = 2.15099 loss)
I0628 19:55:19.372107 17458 sgd_solver.cpp:138] Iteration 10620, lr = 6.25e-05
I0628 19:55:28.510115 17458 solver.cpp:243] Iteration 10630, loss = 2.74979
I0628 19:55:28.510139 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.4269 (* 1 = 3.4269 loss)
I0628 19:55:28.510146 17458 sgd_solver.cpp:138] Iteration 10630, lr = 6.25e-05
I0628 19:55:37.621352 17458 solver.cpp:243] Iteration 10640, loss = 3.39935
I0628 19:55:37.621493 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.41486 (* 1 = 4.41486 loss)
I0628 19:55:37.621502 17458 sgd_solver.cpp:138] Iteration 10640, lr = 6.25e-05
I0628 19:55:46.754565 17458 solver.cpp:243] Iteration 10650, loss = 2.93772
I0628 19:55:46.754588 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25757 (* 1 = 3.25757 loss)
I0628 19:55:46.754614 17458 sgd_solver.cpp:138] Iteration 10650, lr = 6.25e-05
I0628 19:55:55.864253 17458 solver.cpp:243] Iteration 10660, loss = 3.9878
I0628 19:55:55.864279 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.45602 (* 1 = 2.45602 loss)
I0628 19:55:55.864286 17458 sgd_solver.cpp:138] Iteration 10660, lr = 6.25e-05
I0628 19:56:05.006294 17458 solver.cpp:243] Iteration 10670, loss = 2.98257
I0628 19:56:05.006317 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.06391 (* 1 = 2.06391 loss)
I0628 19:56:05.006343 17458 sgd_solver.cpp:138] Iteration 10670, lr = 6.25e-05
I0628 19:56:14.134918 17458 solver.cpp:243] Iteration 10680, loss = 2.86528
I0628 19:56:14.135062 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.6036 (* 1 = 4.6036 loss)
I0628 19:56:14.135087 17458 sgd_solver.cpp:138] Iteration 10680, lr = 6.25e-05
I0628 19:56:23.290045 17458 solver.cpp:243] Iteration 10690, loss = 3.80263
I0628 19:56:23.290069 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.2191 (* 1 = 4.2191 loss)
I0628 19:56:23.290096 17458 sgd_solver.cpp:138] Iteration 10690, lr = 6.25e-05
I0628 19:56:32.411150 17458 solver.cpp:243] Iteration 10700, loss = 3.87313
I0628 19:56:32.411173 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.68735 (* 1 = 4.68735 loss)
I0628 19:56:32.411200 17458 sgd_solver.cpp:138] Iteration 10700, lr = 6.25e-05
I0628 19:56:41.557286 17458 solver.cpp:243] Iteration 10710, loss = 3.15489
I0628 19:56:41.557312 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.88412 (* 1 = 3.88412 loss)
I0628 19:56:41.557339 17458 sgd_solver.cpp:138] Iteration 10710, lr = 6.25e-05
I0628 19:56:50.692826 17458 solver.cpp:243] Iteration 10720, loss = 3.42073
I0628 19:56:50.693045 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.74053 (* 1 = 3.74053 loss)
I0628 19:56:50.693086 17458 sgd_solver.cpp:138] Iteration 10720, lr = 6.25e-05
I0628 19:56:59.855517 17458 solver.cpp:243] Iteration 10730, loss = 2.68973
I0628 19:56:59.855542 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.88829 (* 1 = 1.88829 loss)
I0628 19:56:59.855567 17458 sgd_solver.cpp:138] Iteration 10730, lr = 6.25e-05
I0628 19:57:08.991066 17458 solver.cpp:243] Iteration 10740, loss = 3.78584
I0628 19:57:08.991091 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.80331 (* 1 = 3.80331 loss)
I0628 19:57:08.991117 17458 sgd_solver.cpp:138] Iteration 10740, lr = 6.25e-05
I0628 19:57:18.153944 17458 solver.cpp:243] Iteration 10750, loss = 3.30039
I0628 19:57:18.153970 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.21233 (* 1 = 4.21233 loss)
I0628 19:57:18.153995 17458 sgd_solver.cpp:138] Iteration 10750, lr = 6.25e-05
I0628 19:57:27.291258 17458 solver.cpp:243] Iteration 10760, loss = 3.56563
I0628 19:57:27.291388 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.64555 (* 1 = 2.64555 loss)
I0628 19:57:27.291396 17458 sgd_solver.cpp:138] Iteration 10760, lr = 6.25e-05
I0628 19:57:36.447999 17458 solver.cpp:243] Iteration 10770, loss = 3.05453
I0628 19:57:36.448024 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.69636 (* 1 = 1.69636 loss)
I0628 19:57:36.448050 17458 sgd_solver.cpp:138] Iteration 10770, lr = 6.25e-05
I0628 19:57:45.559629 17458 solver.cpp:243] Iteration 10780, loss = 2.83805
I0628 19:57:45.559669 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.75415 (* 1 = 3.75415 loss)
I0628 19:57:45.559695 17458 sgd_solver.cpp:138] Iteration 10780, lr = 6.25e-05
I0628 19:57:54.706193 17458 solver.cpp:243] Iteration 10790, loss = 3.57975
I0628 19:57:54.706218 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.9798 (* 1 = 1.9798 loss)
I0628 19:57:54.706244 17458 sgd_solver.cpp:138] Iteration 10790, lr = 6.25e-05
I0628 19:58:03.847676 17458 solver.cpp:243] Iteration 10800, loss = 2.95205
I0628 19:58:03.847847 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.39216 (* 1 = 1.39216 loss)
I0628 19:58:03.847856 17458 sgd_solver.cpp:138] Iteration 10800, lr = 6.25e-05
I0628 19:58:13.006551 17458 solver.cpp:243] Iteration 10810, loss = 3.25258
I0628 19:58:13.006575 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.73727 (* 1 = 4.73727 loss)
I0628 19:58:13.006583 17458 sgd_solver.cpp:138] Iteration 10810, lr = 6.25e-05
I0628 19:58:22.139479 17458 solver.cpp:243] Iteration 10820, loss = 3.29473
I0628 19:58:22.139503 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.40612 (* 1 = 2.40612 loss)
I0628 19:58:22.139529 17458 sgd_solver.cpp:138] Iteration 10820, lr = 6.25e-05
I0628 19:58:31.296476 17458 solver.cpp:243] Iteration 10830, loss = 3.26735
I0628 19:58:31.296501 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.35463 (* 1 = 3.35463 loss)
I0628 19:58:31.296526 17458 sgd_solver.cpp:138] Iteration 10830, lr = 6.25e-05
I0628 19:58:40.431051 17458 solver.cpp:243] Iteration 10840, loss = 2.95328
I0628 19:58:40.431179 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.13106 (* 1 = 3.13106 loss)
I0628 19:58:40.431203 17458 sgd_solver.cpp:138] Iteration 10840, lr = 6.25e-05
I0628 19:58:49.593412 17458 solver.cpp:243] Iteration 10850, loss = 4.52863
I0628 19:58:49.593437 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.60007 (* 1 = 4.60007 loss)
I0628 19:58:49.593444 17458 sgd_solver.cpp:138] Iteration 10850, lr = 6.25e-05
I0628 19:58:58.727349 17458 solver.cpp:243] Iteration 10860, loss = 2.63035
I0628 19:58:58.727371 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.16365 (* 1 = 2.16365 loss)
I0628 19:58:58.727397 17458 sgd_solver.cpp:138] Iteration 10860, lr = 6.25e-05
I0628 19:59:07.873430 17458 solver.cpp:243] Iteration 10870, loss = 2.77656
I0628 19:59:07.873454 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.76181 (* 1 = 2.76181 loss)
I0628 19:59:07.873462 17458 sgd_solver.cpp:138] Iteration 10870, lr = 6.25e-05
I0628 19:59:16.985510 17458 solver.cpp:243] Iteration 10880, loss = 2.79515
I0628 19:59:16.985656 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.84674 (* 1 = 2.84674 loss)
I0628 19:59:16.985666 17458 sgd_solver.cpp:138] Iteration 10880, lr = 6.25e-05
I0628 19:59:26.122836 17458 solver.cpp:243] Iteration 10890, loss = 3.48266
I0628 19:59:26.122859 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.41513 (* 1 = 3.41513 loss)
I0628 19:59:26.122885 17458 sgd_solver.cpp:138] Iteration 10890, lr = 6.25e-05
I0628 19:59:35.235373 17458 solver.cpp:243] Iteration 10900, loss = 3.50906
I0628 19:59:35.235397 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.95053 (* 1 = 3.95053 loss)
I0628 19:59:35.235404 17458 sgd_solver.cpp:138] Iteration 10900, lr = 6.25e-05
I0628 19:59:44.371260 17458 solver.cpp:243] Iteration 10910, loss = 3.24634
I0628 19:59:44.371300 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.85712 (* 1 = 3.85712 loss)
I0628 19:59:44.371332 17458 sgd_solver.cpp:138] Iteration 10910, lr = 6.25e-05
I0628 19:59:53.502328 17458 solver.cpp:243] Iteration 10920, loss = 3.20185
I0628 19:59:53.502490 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.05386 (* 1 = 2.05386 loss)
I0628 19:59:53.502498 17458 sgd_solver.cpp:138] Iteration 10920, lr = 6.25e-05
I0628 20:00:02.658640 17458 solver.cpp:243] Iteration 10930, loss = 2.81876
I0628 20:00:02.658665 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.74582 (* 1 = 1.74582 loss)
I0628 20:00:02.658690 17458 sgd_solver.cpp:138] Iteration 10930, lr = 6.25e-05
I0628 20:00:11.786578 17458 solver.cpp:243] Iteration 10940, loss = 3.36325
I0628 20:00:11.786602 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.51909 (* 1 = 2.51909 loss)
I0628 20:00:11.786628 17458 sgd_solver.cpp:138] Iteration 10940, lr = 6.25e-05
I0628 20:00:20.937683 17458 solver.cpp:243] Iteration 10950, loss = 3.61883
I0628 20:00:20.937707 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.89297 (* 1 = 2.89297 loss)
I0628 20:00:20.937716 17458 sgd_solver.cpp:138] Iteration 10950, lr = 6.25e-05
I0628 20:00:30.066081 17458 solver.cpp:243] Iteration 10960, loss = 3.40765
I0628 20:00:30.066215 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.79683 (* 1 = 2.79683 loss)
I0628 20:00:30.066241 17458 sgd_solver.cpp:138] Iteration 10960, lr = 6.25e-05
I0628 20:00:39.218503 17458 solver.cpp:243] Iteration 10970, loss = 3.32507
I0628 20:00:39.218528 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.98065 (* 1 = 4.98065 loss)
I0628 20:00:39.218554 17458 sgd_solver.cpp:138] Iteration 10970, lr = 6.25e-05
I0628 20:00:48.347942 17458 solver.cpp:243] Iteration 10980, loss = 3.94059
I0628 20:00:48.347966 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.76263 (* 1 = 3.76263 loss)
I0628 20:00:48.347992 17458 sgd_solver.cpp:138] Iteration 10980, lr = 6.25e-05
I0628 20:00:57.504177 17458 solver.cpp:243] Iteration 10990, loss = 3.1479
I0628 20:00:57.504201 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53838 (* 1 = 3.53838 loss)
I0628 20:00:57.504227 17458 sgd_solver.cpp:138] Iteration 10990, lr = 6.25e-05
I0628 20:01:05.886405 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_11000.caffemodel
I0628 20:01:05.968504 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_11000.solverstate
I0628 20:01:06.001372 17458 solver.cpp:433] Iteration 11000, Testing net (#0)
I0628 20:01:06.001475 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 20:04:10.851620 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.317129
I0628 20:04:11.635861 17458 solver.cpp:243] Iteration 11000, loss = 3.52261
I0628 20:04:11.635886 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.9962 (* 1 = 1.9962 loss)
I0628 20:04:11.635895 17458 sgd_solver.cpp:138] Iteration 11000, lr = 6.25e-05
I0628 20:04:20.792210 17458 solver.cpp:243] Iteration 11010, loss = 2.76426
I0628 20:04:20.792234 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.33643 (* 1 = 3.33643 loss)
I0628 20:04:20.792259 17458 sgd_solver.cpp:138] Iteration 11010, lr = 6.25e-05
I0628 20:04:29.922435 17458 solver.cpp:243] Iteration 11020, loss = 3.23188
I0628 20:04:29.922457 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.66688 (* 1 = 3.66688 loss)
I0628 20:04:29.922483 17458 sgd_solver.cpp:138] Iteration 11020, lr = 6.25e-05
I0628 20:04:39.077481 17458 solver.cpp:243] Iteration 11030, loss = 3.2155
I0628 20:04:39.077503 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.56491 (* 1 = 3.56491 loss)
I0628 20:04:39.077529 17458 sgd_solver.cpp:138] Iteration 11030, lr = 6.25e-05
I0628 20:04:48.204752 17458 solver.cpp:243] Iteration 11040, loss = 3.25261
I0628 20:04:48.204926 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.75882 (* 1 = 1.75882 loss)
I0628 20:04:48.204933 17458 sgd_solver.cpp:138] Iteration 11040, lr = 6.25e-05
I0628 20:04:57.353432 17458 solver.cpp:243] Iteration 11050, loss = 3.08475
I0628 20:04:57.353458 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.25871 (* 1 = 5.25871 loss)
I0628 20:04:57.353483 17458 sgd_solver.cpp:138] Iteration 11050, lr = 6.25e-05
I0628 20:05:06.482842 17458 solver.cpp:243] Iteration 11060, loss = 2.74511
I0628 20:05:06.482867 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.477 (* 1 = 3.477 loss)
I0628 20:05:06.482892 17458 sgd_solver.cpp:138] Iteration 11060, lr = 6.25e-05
I0628 20:05:15.623064 17458 solver.cpp:243] Iteration 11070, loss = 3.32852
I0628 20:05:15.623090 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.29071 (* 1 = 5.29071 loss)
I0628 20:05:15.623097 17458 sgd_solver.cpp:138] Iteration 11070, lr = 6.25e-05
I0628 20:05:24.733424 17458 solver.cpp:243] Iteration 11080, loss = 3.86724
I0628 20:05:24.733587 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.54911 (* 1 = 3.54911 loss)
I0628 20:05:24.733614 17458 sgd_solver.cpp:138] Iteration 11080, lr = 6.25e-05
I0628 20:05:33.887084 17458 solver.cpp:243] Iteration 11090, loss = 3.48198
I0628 20:05:33.887107 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.94939 (* 1 = 1.94939 loss)
I0628 20:05:33.887133 17458 sgd_solver.cpp:138] Iteration 11090, lr = 6.25e-05
I0628 20:05:43.020921 17458 solver.cpp:243] Iteration 11100, loss = 2.76113
I0628 20:05:43.020944 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.61989 (* 1 = 4.61989 loss)
I0628 20:05:43.020970 17458 sgd_solver.cpp:138] Iteration 11100, lr = 6.25e-05
I0628 20:05:52.173604 17458 solver.cpp:243] Iteration 11110, loss = 4.22382
I0628 20:05:52.173627 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.92832 (* 1 = 1.92832 loss)
I0628 20:05:52.173653 17458 sgd_solver.cpp:138] Iteration 11110, lr = 6.25e-05
I0628 20:06:01.311276 17458 solver.cpp:243] Iteration 11120, loss = 3.11429
I0628 20:06:01.311442 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.6756 (* 1 = 2.6756 loss)
I0628 20:06:01.311470 17458 sgd_solver.cpp:138] Iteration 11120, lr = 6.25e-05
I0628 20:06:10.470211 17458 solver.cpp:243] Iteration 11130, loss = 3.07157
I0628 20:06:10.470235 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.28413 (* 1 = 3.28413 loss)
I0628 20:06:10.470242 17458 sgd_solver.cpp:138] Iteration 11130, lr = 6.25e-05
I0628 20:06:19.593705 17458 solver.cpp:243] Iteration 11140, loss = 3.40818
I0628 20:06:19.593729 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.98295 (* 1 = 3.98295 loss)
I0628 20:06:19.593755 17458 sgd_solver.cpp:138] Iteration 11140, lr = 6.25e-05
I0628 20:06:28.724984 17458 solver.cpp:243] Iteration 11150, loss = 3.32637
I0628 20:06:28.725009 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.97936 (* 1 = 3.97936 loss)
I0628 20:06:28.725018 17458 sgd_solver.cpp:138] Iteration 11150, lr = 6.25e-05
I0628 20:06:37.837458 17458 solver.cpp:243] Iteration 11160, loss = 3.28768
I0628 20:06:37.837664 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.44987 (* 1 = 3.44987 loss)
I0628 20:06:37.837673 17458 sgd_solver.cpp:138] Iteration 11160, lr = 6.25e-05
I0628 20:06:46.968997 17458 solver.cpp:243] Iteration 11170, loss = 3.65206
I0628 20:06:46.969018 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.54377 (* 1 = 4.54377 loss)
I0628 20:06:46.969043 17458 sgd_solver.cpp:138] Iteration 11170, lr = 6.25e-05
I0628 20:06:56.102231 17458 solver.cpp:243] Iteration 11180, loss = 3.38
I0628 20:06:56.102253 17458 solver.cpp:259]     Train net output #0: mbox_loss = 0.921726 (* 1 = 0.921726 loss)
I0628 20:06:56.102279 17458 sgd_solver.cpp:138] Iteration 11180, lr = 6.25e-05
I0628 20:07:05.266767 17458 solver.cpp:243] Iteration 11190, loss = 3.2538
I0628 20:07:05.266791 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.19255 (* 1 = 4.19255 loss)
I0628 20:07:05.266798 17458 sgd_solver.cpp:138] Iteration 11190, lr = 6.25e-05
I0628 20:07:14.409003 17458 solver.cpp:243] Iteration 11200, loss = 3.24186
I0628 20:07:14.409166 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.18262 (* 1 = 3.18262 loss)
I0628 20:07:14.409175 17458 sgd_solver.cpp:138] Iteration 11200, lr = 6.25e-05
I0628 20:07:23.570935 17458 solver.cpp:243] Iteration 11210, loss = 3.89235
I0628 20:07:23.570960 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.15139 (* 1 = 3.15139 loss)
I0628 20:07:23.570986 17458 sgd_solver.cpp:138] Iteration 11210, lr = 6.25e-05
I0628 20:07:32.696028 17458 solver.cpp:243] Iteration 11220, loss = 3.40265
I0628 20:07:32.696053 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.37996 (* 1 = 1.37996 loss)
I0628 20:07:32.696079 17458 sgd_solver.cpp:138] Iteration 11220, lr = 6.25e-05
I0628 20:07:41.826319 17458 solver.cpp:243] Iteration 11230, loss = 3.36423
I0628 20:07:41.826345 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.13809 (* 1 = 3.13809 loss)
I0628 20:07:41.826354 17458 sgd_solver.cpp:138] Iteration 11230, lr = 6.25e-05
I0628 20:07:50.943487 17458 solver.cpp:243] Iteration 11240, loss = 3.22529
I0628 20:07:50.943646 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.97324 (* 1 = 1.97324 loss)
I0628 20:07:50.943655 17458 sgd_solver.cpp:138] Iteration 11240, lr = 6.25e-05
I0628 20:08:00.096824 17458 solver.cpp:243] Iteration 11250, loss = 3.40174
I0628 20:08:00.096849 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.9188 (* 1 = 2.9188 loss)
I0628 20:08:00.096875 17458 sgd_solver.cpp:138] Iteration 11250, lr = 6.25e-05
I0628 20:08:09.227389 17458 solver.cpp:243] Iteration 11260, loss = 2.60844
I0628 20:08:09.227412 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.96297 (* 1 = 1.96297 loss)
I0628 20:08:09.227438 17458 sgd_solver.cpp:138] Iteration 11260, lr = 6.25e-05
I0628 20:08:18.383368 17458 solver.cpp:243] Iteration 11270, loss = 3.33217
I0628 20:08:18.383394 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.68343 (* 1 = 3.68343 loss)
I0628 20:08:18.383419 17458 sgd_solver.cpp:138] Iteration 11270, lr = 6.25e-05
I0628 20:08:27.517040 17458 solver.cpp:243] Iteration 11280, loss = 3.29112
I0628 20:08:27.517185 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.88549 (* 1 = 2.88549 loss)
I0628 20:08:27.517194 17458 sgd_solver.cpp:138] Iteration 11280, lr = 6.25e-05
I0628 20:08:36.670766 17458 solver.cpp:243] Iteration 11290, loss = 3.27771
I0628 20:08:36.670791 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.14102 (* 1 = 4.14102 loss)
I0628 20:08:36.670816 17458 sgd_solver.cpp:138] Iteration 11290, lr = 6.25e-05
I0628 20:08:45.804239 17458 solver.cpp:243] Iteration 11300, loss = 3.7114
I0628 20:08:45.804263 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.68024 (* 1 = 1.68024 loss)
I0628 20:08:45.804288 17458 sgd_solver.cpp:138] Iteration 11300, lr = 6.25e-05
I0628 20:08:54.962608 17458 solver.cpp:243] Iteration 11310, loss = 3.27632
I0628 20:08:54.962633 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.85239 (* 1 = 3.85239 loss)
I0628 20:08:54.962659 17458 sgd_solver.cpp:138] Iteration 11310, lr = 6.25e-05
I0628 20:09:04.097364 17458 solver.cpp:243] Iteration 11320, loss = 2.78145
I0628 20:09:04.097529 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.23452 (* 1 = 3.23452 loss)
I0628 20:09:04.097538 17458 sgd_solver.cpp:138] Iteration 11320, lr = 6.25e-05
I0628 20:09:13.232507 17458 solver.cpp:243] Iteration 11330, loss = 3.00397
I0628 20:09:13.232532 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.48929 (* 1 = 3.48929 loss)
I0628 20:09:13.232539 17458 sgd_solver.cpp:138] Iteration 11330, lr = 6.25e-05
I0628 20:09:22.336490 17458 solver.cpp:243] Iteration 11340, loss = 3.20447
I0628 20:09:22.336514 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.48387 (* 1 = 3.48387 loss)
I0628 20:09:22.336540 17458 sgd_solver.cpp:138] Iteration 11340, lr = 6.25e-05
I0628 20:09:31.480782 17458 solver.cpp:243] Iteration 11350, loss = 2.67815
I0628 20:09:31.480808 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.41713 (* 1 = 3.41713 loss)
I0628 20:09:31.480834 17458 sgd_solver.cpp:138] Iteration 11350, lr = 6.25e-05
I0628 20:09:40.607221 17458 solver.cpp:243] Iteration 11360, loss = 3.41658
I0628 20:09:40.607391 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.36758 (* 1 = 3.36758 loss)
I0628 20:09:40.607400 17458 sgd_solver.cpp:138] Iteration 11360, lr = 6.25e-05
I0628 20:09:49.758123 17458 solver.cpp:243] Iteration 11370, loss = 2.64634
I0628 20:09:49.758148 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.6711 (* 1 = 3.6711 loss)
I0628 20:09:49.758157 17458 sgd_solver.cpp:138] Iteration 11370, lr = 6.25e-05
I0628 20:09:58.872298 17458 solver.cpp:243] Iteration 11380, loss = 2.94615
I0628 20:09:58.872323 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.90939 (* 1 = 2.90939 loss)
I0628 20:09:58.872330 17458 sgd_solver.cpp:138] Iteration 11380, lr = 6.25e-05
I0628 20:10:07.998205 17458 solver.cpp:243] Iteration 11390, loss = 3.46121
I0628 20:10:07.998230 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.86226 (* 1 = 1.86226 loss)
I0628 20:10:07.998239 17458 sgd_solver.cpp:138] Iteration 11390, lr = 6.25e-05
I0628 20:10:17.118281 17458 solver.cpp:243] Iteration 11400, loss = 3.62778
I0628 20:10:17.118435 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.68945 (* 1 = 3.68945 loss)
I0628 20:10:17.118444 17458 sgd_solver.cpp:138] Iteration 11400, lr = 6.25e-05
I0628 20:10:26.253931 17458 solver.cpp:243] Iteration 11410, loss = 3.4152
I0628 20:10:26.253955 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.79278 (* 1 = 1.79278 loss)
I0628 20:10:26.253963 17458 sgd_solver.cpp:138] Iteration 11410, lr = 6.25e-05
I0628 20:10:35.347252 17458 solver.cpp:243] Iteration 11420, loss = 2.85856
I0628 20:10:35.347276 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.82759 (* 1 = 3.82759 loss)
I0628 20:10:35.347283 17458 sgd_solver.cpp:138] Iteration 11420, lr = 6.25e-05
I0628 20:10:44.489264 17458 solver.cpp:243] Iteration 11430, loss = 4.1541
I0628 20:10:44.489290 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.54553 (* 1 = 1.54553 loss)
I0628 20:10:44.489298 17458 sgd_solver.cpp:138] Iteration 11430, lr = 6.25e-05
I0628 20:10:53.609844 17458 solver.cpp:243] Iteration 11440, loss = 3.3609
I0628 20:10:53.609994 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.38662 (* 1 = 4.38662 loss)
I0628 20:10:53.610003 17458 sgd_solver.cpp:138] Iteration 11440, lr = 6.25e-05
I0628 20:11:02.734179 17458 solver.cpp:243] Iteration 11450, loss = 2.8653
I0628 20:11:02.734205 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.10299 (* 1 = 4.10299 loss)
I0628 20:11:02.734212 17458 sgd_solver.cpp:138] Iteration 11450, lr = 6.25e-05
I0628 20:11:11.842146 17458 solver.cpp:243] Iteration 11460, loss = 3.04474
I0628 20:11:11.842171 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.15884 (* 1 = 5.15884 loss)
I0628 20:11:11.842180 17458 sgd_solver.cpp:138] Iteration 11460, lr = 6.25e-05
I0628 20:11:20.982679 17458 solver.cpp:243] Iteration 11470, loss = 3.6692
I0628 20:11:20.982705 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.91179 (* 1 = 2.91179 loss)
I0628 20:11:20.982713 17458 sgd_solver.cpp:138] Iteration 11470, lr = 6.25e-05
I0628 20:11:30.092543 17458 solver.cpp:243] Iteration 11480, loss = 3.10869
I0628 20:11:30.092715 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.77847 (* 1 = 2.77847 loss)
I0628 20:11:30.092725 17458 sgd_solver.cpp:138] Iteration 11480, lr = 6.25e-05
I0628 20:11:39.210613 17458 solver.cpp:243] Iteration 11490, loss = 4.51708
I0628 20:11:39.210639 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.40751 (* 1 = 4.40751 loss)
I0628 20:11:39.210646 17458 sgd_solver.cpp:138] Iteration 11490, lr = 6.25e-05
I0628 20:11:48.333266 17458 solver.cpp:243] Iteration 11500, loss = 3.39516
I0628 20:11:48.333288 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.20185 (* 1 = 1.20185 loss)
I0628 20:11:48.333297 17458 sgd_solver.cpp:138] Iteration 11500, lr = 6.25e-05
I0628 20:11:57.479473 17458 solver.cpp:243] Iteration 11510, loss = 3.21192
I0628 20:11:57.479502 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.73065 (* 1 = 3.73065 loss)
I0628 20:11:57.479511 17458 sgd_solver.cpp:138] Iteration 11510, lr = 6.25e-05
I0628 20:12:06.584534 17458 solver.cpp:243] Iteration 11520, loss = 2.77792
I0628 20:12:06.584645 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.53697 (* 1 = 1.53697 loss)
I0628 20:12:06.584655 17458 sgd_solver.cpp:138] Iteration 11520, lr = 6.25e-05
I0628 20:12:15.722810 17458 solver.cpp:243] Iteration 11530, loss = 3.18994
I0628 20:12:15.722836 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.26294 (* 1 = 3.26294 loss)
I0628 20:12:15.722843 17458 sgd_solver.cpp:138] Iteration 11530, lr = 6.25e-05
I0628 20:12:24.842551 17458 solver.cpp:243] Iteration 11540, loss = 3.06467
I0628 20:12:24.842576 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.47494 (* 1 = 3.47494 loss)
I0628 20:12:24.842583 17458 sgd_solver.cpp:138] Iteration 11540, lr = 6.25e-05
I0628 20:12:33.970572 17458 solver.cpp:243] Iteration 11550, loss = 3.22524
I0628 20:12:33.970598 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.76075 (* 1 = 2.76075 loss)
I0628 20:12:33.970607 17458 sgd_solver.cpp:138] Iteration 11550, lr = 6.25e-05
I0628 20:12:43.076625 17458 solver.cpp:243] Iteration 11560, loss = 3.63327
I0628 20:12:43.076761 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.40267 (* 1 = 2.40267 loss)
I0628 20:12:43.076771 17458 sgd_solver.cpp:138] Iteration 11560, lr = 6.25e-05
I0628 20:12:52.197537 17458 solver.cpp:243] Iteration 11570, loss = 2.61216
I0628 20:12:52.197561 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.67442 (* 1 = 1.67442 loss)
I0628 20:12:52.197569 17458 sgd_solver.cpp:138] Iteration 11570, lr = 6.25e-05
I0628 20:13:01.300127 17458 solver.cpp:243] Iteration 11580, loss = 2.99012
I0628 20:13:01.300153 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.96244 (* 1 = 2.96244 loss)
I0628 20:13:01.300159 17458 sgd_solver.cpp:138] Iteration 11580, lr = 6.25e-05
I0628 20:13:10.420791 17458 solver.cpp:243] Iteration 11590, loss = 4.28119
I0628 20:13:10.420816 17458 solver.cpp:259]     Train net output #0: mbox_loss = 7.57648 (* 1 = 7.57648 loss)
I0628 20:13:10.420825 17458 sgd_solver.cpp:138] Iteration 11590, lr = 6.25e-05
I0628 20:13:19.526098 17458 solver.cpp:243] Iteration 11600, loss = 3.37544
I0628 20:13:19.526229 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.51152 (* 1 = 2.51152 loss)
I0628 20:13:19.526239 17458 sgd_solver.cpp:138] Iteration 11600, lr = 6.25e-05
I0628 20:13:28.647363 17458 solver.cpp:243] Iteration 11610, loss = 2.7523
I0628 20:13:28.647387 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.78753 (* 1 = 3.78753 loss)
I0628 20:13:28.647395 17458 sgd_solver.cpp:138] Iteration 11610, lr = 6.25e-05
I0628 20:13:37.756417 17458 solver.cpp:243] Iteration 11620, loss = 4.06594
I0628 20:13:37.756441 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.98791 (* 1 = 3.98791 loss)
I0628 20:13:37.756448 17458 sgd_solver.cpp:138] Iteration 11620, lr = 6.25e-05
I0628 20:13:46.888625 17458 solver.cpp:243] Iteration 11630, loss = 2.45281
I0628 20:13:46.888653 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.0674 (* 1 = 3.0674 loss)
I0628 20:13:46.888659 17458 sgd_solver.cpp:138] Iteration 11630, lr = 6.25e-05
I0628 20:13:55.993202 17458 solver.cpp:243] Iteration 11640, loss = 2.47852
I0628 20:13:55.993348 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.0242 (* 1 = 2.0242 loss)
I0628 20:13:55.993372 17458 sgd_solver.cpp:138] Iteration 11640, lr = 6.25e-05
I0628 20:14:05.120095 17458 solver.cpp:243] Iteration 11650, loss = 2.92149
I0628 20:14:05.120121 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.96339 (* 1 = 2.96339 loss)
I0628 20:14:05.120129 17458 sgd_solver.cpp:138] Iteration 11650, lr = 6.25e-05
I0628 20:14:14.219220 17458 solver.cpp:243] Iteration 11660, loss = 3.79178
I0628 20:14:14.219245 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.52855 (* 1 = 4.52855 loss)
I0628 20:14:14.219254 17458 sgd_solver.cpp:138] Iteration 11660, lr = 6.25e-05
I0628 20:14:23.367507 17458 solver.cpp:243] Iteration 11670, loss = 2.63854
I0628 20:14:23.367537 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.53623 (* 1 = 3.53623 loss)
I0628 20:14:23.367568 17458 sgd_solver.cpp:138] Iteration 11670, lr = 6.25e-05
I0628 20:14:32.499042 17458 solver.cpp:243] Iteration 11680, loss = 3.00768
I0628 20:14:32.499249 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.82142 (* 1 = 2.82142 loss)
I0628 20:14:32.499262 17458 sgd_solver.cpp:138] Iteration 11680, lr = 6.25e-05
I0628 20:14:41.645656 17458 solver.cpp:243] Iteration 11690, loss = 2.97595
I0628 20:14:41.645685 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.67375 (* 1 = 1.67375 loss)
I0628 20:14:41.645699 17458 sgd_solver.cpp:138] Iteration 11690, lr = 6.25e-05
I0628 20:14:50.776327 17458 solver.cpp:243] Iteration 11700, loss = 2.82661
I0628 20:14:50.776356 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.24881 (* 1 = 4.24881 loss)
I0628 20:14:50.776369 17458 sgd_solver.cpp:138] Iteration 11700, lr = 6.25e-05
I0628 20:14:59.930310 17458 solver.cpp:243] Iteration 11710, loss = 2.82555
I0628 20:14:59.930341 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.70496 (* 1 = 2.70496 loss)
I0628 20:14:59.930352 17458 sgd_solver.cpp:138] Iteration 11710, lr = 6.25e-05
I0628 20:15:09.066321 17458 solver.cpp:243] Iteration 11720, loss = 3.80086
I0628 20:15:09.066491 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.777 (* 1 = 3.777 loss)
I0628 20:15:09.066504 17458 sgd_solver.cpp:138] Iteration 11720, lr = 6.25e-05
I0628 20:15:18.223270 17458 solver.cpp:243] Iteration 11730, loss = 3.5311
I0628 20:15:18.223300 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.26815 (* 1 = 2.26815 loss)
I0628 20:15:18.223312 17458 sgd_solver.cpp:138] Iteration 11730, lr = 6.25e-05
I0628 20:15:27.357386 17458 solver.cpp:243] Iteration 11740, loss = 3.1338
I0628 20:15:27.357420 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.13497 (* 1 = 3.13497 loss)
I0628 20:15:27.357432 17458 sgd_solver.cpp:138] Iteration 11740, lr = 6.25e-05
I0628 20:15:36.510403 17458 solver.cpp:243] Iteration 11750, loss = 3.47242
I0628 20:15:36.510432 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.25411 (* 1 = 1.25411 loss)
I0628 20:15:36.510445 17458 sgd_solver.cpp:138] Iteration 11750, lr = 6.25e-05
I0628 20:15:45.635499 17458 solver.cpp:243] Iteration 11760, loss = 2.90174
I0628 20:15:45.635651 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.11628 (* 1 = 3.11628 loss)
I0628 20:15:45.635674 17458 sgd_solver.cpp:138] Iteration 11760, lr = 6.25e-05
I0628 20:15:54.787811 17458 solver.cpp:243] Iteration 11770, loss = 2.89024
I0628 20:15:54.787838 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.98892 (* 1 = 2.98892 loss)
I0628 20:15:54.787848 17458 sgd_solver.cpp:138] Iteration 11770, lr = 6.25e-05
I0628 20:16:03.923108 17458 solver.cpp:243] Iteration 11780, loss = 3.4932
I0628 20:16:03.923138 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.82692 (* 1 = 2.82692 loss)
I0628 20:16:03.923151 17458 sgd_solver.cpp:138] Iteration 11780, lr = 6.25e-05
I0628 20:16:13.077338 17458 solver.cpp:243] Iteration 11790, loss = 3.59452
I0628 20:16:13.077368 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.35711 (* 1 = 4.35711 loss)
I0628 20:16:13.077379 17458 sgd_solver.cpp:138] Iteration 11790, lr = 6.25e-05
I0628 20:16:22.188071 17458 solver.cpp:243] Iteration 11800, loss = 3.21175
I0628 20:16:22.188246 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.28715 (* 1 = 2.28715 loss)
I0628 20:16:22.188258 17458 sgd_solver.cpp:138] Iteration 11800, lr = 6.25e-05
I0628 20:16:31.315495 17458 solver.cpp:243] Iteration 11810, loss = 3.17984
I0628 20:16:31.315527 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.88493 (* 1 = 3.88493 loss)
I0628 20:16:31.315541 17458 sgd_solver.cpp:138] Iteration 11810, lr = 6.25e-05
I0628 20:16:40.419701 17458 solver.cpp:243] Iteration 11820, loss = 2.97558
I0628 20:16:40.419730 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.09467 (* 1 = 1.09467 loss)
I0628 20:16:40.419742 17458 sgd_solver.cpp:138] Iteration 11820, lr = 6.25e-05
I0628 20:16:49.544103 17458 solver.cpp:243] Iteration 11830, loss = 2.89157
I0628 20:16:49.544131 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.71637 (* 1 = 2.71637 loss)
I0628 20:16:49.544140 17458 sgd_solver.cpp:138] Iteration 11830, lr = 6.25e-05
I0628 20:16:58.675806 17458 solver.cpp:243] Iteration 11840, loss = 3.38718
I0628 20:16:58.675964 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.31231 (* 1 = 4.31231 loss)
I0628 20:16:58.675994 17458 sgd_solver.cpp:138] Iteration 11840, lr = 6.25e-05
I0628 20:17:07.839485 17458 solver.cpp:243] Iteration 11850, loss = 3.33129
I0628 20:17:07.839511 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.14844 (* 1 = 3.14844 loss)
I0628 20:17:07.839521 17458 sgd_solver.cpp:138] Iteration 11850, lr = 6.25e-05
I0628 20:17:16.981555 17458 solver.cpp:243] Iteration 11860, loss = 2.86209
I0628 20:17:16.981585 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.54582 (* 1 = 1.54582 loss)
I0628 20:17:16.981596 17458 sgd_solver.cpp:138] Iteration 11860, lr = 6.25e-05
I0628 20:17:26.117790 17458 solver.cpp:243] Iteration 11870, loss = 3.44477
I0628 20:17:26.117816 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.17511 (* 1 = 3.17511 loss)
I0628 20:17:26.117826 17458 sgd_solver.cpp:138] Iteration 11870, lr = 6.25e-05
I0628 20:17:35.233759 17458 solver.cpp:243] Iteration 11880, loss = 3.58091
I0628 20:17:35.233892 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.36048 (* 1 = 1.36048 loss)
I0628 20:17:35.233904 17458 sgd_solver.cpp:138] Iteration 11880, lr = 6.25e-05
I0628 20:17:44.365612 17458 solver.cpp:243] Iteration 11890, loss = 2.47003
I0628 20:17:44.365638 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.53125 (* 1 = 1.53125 loss)
I0628 20:17:44.365648 17458 sgd_solver.cpp:138] Iteration 11890, lr = 6.25e-05
I0628 20:17:53.476382 17458 solver.cpp:243] Iteration 11900, loss = 3.26165
I0628 20:17:53.476410 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.03718 (* 1 = 2.03718 loss)
I0628 20:17:53.476423 17458 sgd_solver.cpp:138] Iteration 11900, lr = 6.25e-05
I0628 20:18:02.630220 17458 solver.cpp:243] Iteration 11910, loss = 3.19512
I0628 20:18:02.630249 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.50362 (* 1 = 5.50362 loss)
I0628 20:18:02.630262 17458 sgd_solver.cpp:138] Iteration 11910, lr = 6.25e-05
I0628 20:18:11.757225 17458 solver.cpp:243] Iteration 11920, loss = 3.10732
I0628 20:18:11.757426 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.05629 (* 1 = 4.05629 loss)
I0628 20:18:11.757457 17458 sgd_solver.cpp:138] Iteration 11920, lr = 6.25e-05
I0628 20:18:20.914863 17458 solver.cpp:243] Iteration 11930, loss = 2.50095
I0628 20:18:20.914891 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.7323 (* 1 = 2.7323 loss)
I0628 20:18:20.914904 17458 sgd_solver.cpp:138] Iteration 11930, lr = 6.25e-05
I0628 20:18:30.182049 17458 solver.cpp:243] Iteration 11940, loss = 3.19988
I0628 20:18:30.182108 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.02144 (* 1 = 2.02144 loss)
I0628 20:18:30.182118 17458 sgd_solver.cpp:138] Iteration 11940, lr = 6.25e-05
I0628 20:18:39.531898 17458 solver.cpp:243] Iteration 11950, loss = 3.29383
I0628 20:18:39.531926 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.16343 (* 1 = 3.16343 loss)
I0628 20:18:39.531937 17458 sgd_solver.cpp:138] Iteration 11950, lr = 6.25e-05
I0628 20:18:48.767901 17458 solver.cpp:243] Iteration 11960, loss = 2.83841
I0628 20:18:48.768085 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.68241 (* 1 = 3.68241 loss)
I0628 20:18:48.768097 17458 sgd_solver.cpp:138] Iteration 11960, lr = 6.25e-05
I0628 20:18:57.972999 17458 solver.cpp:243] Iteration 11970, loss = 2.87509
I0628 20:18:57.973026 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.26861 (* 1 = 3.26861 loss)
I0628 20:18:57.973037 17458 sgd_solver.cpp:138] Iteration 11970, lr = 6.25e-05
I0628 20:19:07.188236 17458 solver.cpp:243] Iteration 11980, loss = 3.15107
I0628 20:19:07.188264 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.77289 (* 1 = 4.77289 loss)
I0628 20:19:07.188274 17458 sgd_solver.cpp:138] Iteration 11980, lr = 6.25e-05
I0628 20:19:16.448523 17458 solver.cpp:243] Iteration 11990, loss = 2.47409
I0628 20:19:16.448566 17458 solver.cpp:259]     Train net output #0: mbox_loss = 0.862585 (* 1 = 0.862585 loss)
I0628 20:19:16.448583 17458 sgd_solver.cpp:138] Iteration 11990, lr = 6.25e-05
I0628 20:19:24.867519 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_12000.caffemodel
I0628 20:19:24.951056 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_12000.solverstate
I0628 20:19:24.984556 17458 solver.cpp:433] Iteration 12000, Testing net (#0)
I0628 20:19:24.984663 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 20:22:29.882287 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.325756
I0628 20:22:30.670915 17458 solver.cpp:243] Iteration 12000, loss = 3.0424
I0628 20:22:30.670940 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.73945 (* 1 = 3.73945 loss)
I0628 20:22:30.670946 17458 sgd_solver.cpp:47] MultiStep Status: Iteration 12000, step = 4
I0628 20:22:30.670951 17458 sgd_solver.cpp:138] Iteration 12000, lr = 3.125e-05
I0628 20:22:39.803752 17458 solver.cpp:243] Iteration 12010, loss = 3.05265
I0628 20:22:39.803794 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.83285 (* 1 = 4.83285 loss)
I0628 20:22:39.803802 17458 sgd_solver.cpp:138] Iteration 12010, lr = 3.125e-05
I0628 20:22:48.916826 17458 solver.cpp:243] Iteration 12020, loss = 3.1538
I0628 20:22:48.916849 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.63158 (* 1 = 4.63158 loss)
I0628 20:22:48.916857 17458 sgd_solver.cpp:138] Iteration 12020, lr = 3.125e-05
I0628 20:22:58.046802 17458 solver.cpp:243] Iteration 12030, loss = 2.38426
I0628 20:22:58.046825 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.1056 (* 1 = 2.1056 loss)
I0628 20:22:58.046833 17458 sgd_solver.cpp:138] Iteration 12030, lr = 3.125e-05
I0628 20:23:07.157619 17458 solver.cpp:243] Iteration 12040, loss = 3.43956
I0628 20:23:07.157809 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.8265 (* 1 = 3.8265 loss)
I0628 20:23:07.157819 17458 sgd_solver.cpp:138] Iteration 12040, lr = 3.125e-05
I0628 20:23:16.297731 17458 solver.cpp:243] Iteration 12050, loss = 3.97472
I0628 20:23:16.297756 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.65832 (* 1 = 2.65832 loss)
I0628 20:23:16.297765 17458 sgd_solver.cpp:138] Iteration 12050, lr = 3.125e-05
I0628 20:23:25.429159 17458 solver.cpp:243] Iteration 12060, loss = 3.20871
I0628 20:23:25.429183 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.55258 (* 1 = 4.55258 loss)
I0628 20:23:25.429209 17458 sgd_solver.cpp:138] Iteration 12060, lr = 3.125e-05
I0628 20:23:34.584372 17458 solver.cpp:243] Iteration 12070, loss = 3.59038
I0628 20:23:34.584396 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.43056 (* 1 = 3.43056 loss)
I0628 20:23:34.584403 17458 sgd_solver.cpp:138] Iteration 12070, lr = 3.125e-05
I0628 20:23:43.698662 17458 solver.cpp:243] Iteration 12080, loss = 2.81658
I0628 20:23:43.698848 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.16805 (* 1 = 2.16805 loss)
I0628 20:23:43.698858 17458 sgd_solver.cpp:138] Iteration 12080, lr = 3.125e-05
I0628 20:23:52.852668 17458 solver.cpp:243] Iteration 12090, loss = 3.23154
I0628 20:23:52.852690 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.43294 (* 1 = 3.43294 loss)
I0628 20:23:52.852716 17458 sgd_solver.cpp:138] Iteration 12090, lr = 3.125e-05
I0628 20:24:01.988411 17458 solver.cpp:243] Iteration 12100, loss = 3.4478
I0628 20:24:01.988436 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.14145 (* 1 = 4.14145 loss)
I0628 20:24:01.988462 17458 sgd_solver.cpp:138] Iteration 12100, lr = 3.125e-05
I0628 20:24:11.145242 17458 solver.cpp:243] Iteration 12110, loss = 2.90239
I0628 20:24:11.145267 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.70468 (* 1 = 4.70468 loss)
I0628 20:24:11.145293 17458 sgd_solver.cpp:138] Iteration 12110, lr = 3.125e-05
I0628 20:24:20.262801 17458 solver.cpp:243] Iteration 12120, loss = 2.67439
I0628 20:24:20.262951 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.30249 (* 1 = 3.30249 loss)
I0628 20:24:20.262961 17458 sgd_solver.cpp:138] Iteration 12120, lr = 3.125e-05
I0628 20:24:29.402987 17458 solver.cpp:243] Iteration 12130, loss = 3.93135
I0628 20:24:29.403012 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.45462 (* 1 = 4.45462 loss)
I0628 20:24:29.403019 17458 sgd_solver.cpp:138] Iteration 12130, lr = 3.125e-05
I0628 20:24:38.538409 17458 solver.cpp:243] Iteration 12140, loss = 2.72402
I0628 20:24:38.538434 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.48882 (* 1 = 2.48882 loss)
I0628 20:24:38.538441 17458 sgd_solver.cpp:138] Iteration 12140, lr = 3.125e-05
I0628 20:24:47.698215 17458 solver.cpp:243] Iteration 12150, loss = 3.25077
I0628 20:24:47.698240 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.29563 (* 1 = 3.29563 loss)
I0628 20:24:47.698247 17458 sgd_solver.cpp:138] Iteration 12150, lr = 3.125e-05
I0628 20:24:56.805289 17458 solver.cpp:243] Iteration 12160, loss = 3.48377
I0628 20:24:56.805426 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.25187 (* 1 = 4.25187 loss)
I0628 20:24:56.805436 17458 sgd_solver.cpp:138] Iteration 12160, lr = 3.125e-05
I0628 20:25:05.940941 17458 solver.cpp:243] Iteration 12170, loss = 3.53807
I0628 20:25:05.940965 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.30486 (* 1 = 3.30486 loss)
I0628 20:25:05.940991 17458 sgd_solver.cpp:138] Iteration 12170, lr = 3.125e-05
I0628 20:25:15.068387 17458 solver.cpp:243] Iteration 12180, loss = 3.82795
I0628 20:25:15.068424 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.80455 (* 1 = 2.80455 loss)
I0628 20:25:15.068431 17458 sgd_solver.cpp:138] Iteration 12180, lr = 3.125e-05
I0628 20:25:24.224247 17458 solver.cpp:243] Iteration 12190, loss = 3.00815
I0628 20:25:24.224273 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.12745 (* 1 = 3.12745 loss)
I0628 20:25:24.224282 17458 sgd_solver.cpp:138] Iteration 12190, lr = 3.125e-05
I0628 20:25:33.357224 17458 solver.cpp:243] Iteration 12200, loss = 2.77944
I0628 20:25:33.357352 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.89122 (* 1 = 2.89122 loss)
I0628 20:25:33.357375 17458 sgd_solver.cpp:138] Iteration 12200, lr = 3.125e-05
I0628 20:25:42.516191 17458 solver.cpp:243] Iteration 12210, loss = 2.76019
I0628 20:25:42.516217 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.76721 (* 1 = 1.76721 loss)
I0628 20:25:42.516243 17458 sgd_solver.cpp:138] Iteration 12210, lr = 3.125e-05
I0628 20:25:51.639899 17458 solver.cpp:243] Iteration 12220, loss = 2.8176
I0628 20:25:51.639923 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.05877 (* 1 = 4.05877 loss)
I0628 20:25:51.639931 17458 sgd_solver.cpp:138] Iteration 12220, lr = 3.125e-05
I0628 20:26:00.783172 17458 solver.cpp:243] Iteration 12230, loss = 3.36916
I0628 20:26:00.783198 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.32559 (* 1 = 3.32559 loss)
I0628 20:26:00.783224 17458 sgd_solver.cpp:138] Iteration 12230, lr = 3.125e-05
I0628 20:26:09.919030 17458 solver.cpp:243] Iteration 12240, loss = 3.63786
I0628 20:26:09.919294 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.93954 (* 1 = 3.93954 loss)
I0628 20:26:09.919304 17458 sgd_solver.cpp:138] Iteration 12240, lr = 3.125e-05
I0628 20:26:19.075923 17458 solver.cpp:243] Iteration 12250, loss = 2.47912
I0628 20:26:19.075947 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.35472 (* 1 = 1.35472 loss)
I0628 20:26:19.075955 17458 sgd_solver.cpp:138] Iteration 12250, lr = 3.125e-05
I0628 20:26:28.204481 17458 solver.cpp:243] Iteration 12260, loss = 3.98209
I0628 20:26:28.204504 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.59599 (* 1 = 3.59599 loss)
I0628 20:26:28.204530 17458 sgd_solver.cpp:138] Iteration 12260, lr = 3.125e-05
I0628 20:26:37.361876 17458 solver.cpp:243] Iteration 12270, loss = 3.10886
I0628 20:26:37.361901 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.40717 (* 1 = 3.40717 loss)
I0628 20:26:37.361909 17458 sgd_solver.cpp:138] Iteration 12270, lr = 3.125e-05
I0628 20:26:46.486658 17458 solver.cpp:243] Iteration 12280, loss = 2.94381
I0628 20:26:46.486810 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.97139 (* 1 = 1.97139 loss)
I0628 20:26:46.486819 17458 sgd_solver.cpp:138] Iteration 12280, lr = 3.125e-05
I0628 20:26:55.619151 17458 solver.cpp:243] Iteration 12290, loss = 3.29625
I0628 20:26:55.619176 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.52049 (* 1 = 3.52049 loss)
I0628 20:26:55.619184 17458 sgd_solver.cpp:138] Iteration 12290, lr = 3.125e-05
I0628 20:27:04.736904 17458 solver.cpp:243] Iteration 12300, loss = 3.10407
I0628 20:27:04.736929 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.78591 (* 1 = 3.78591 loss)
I0628 20:27:04.736937 17458 sgd_solver.cpp:138] Iteration 12300, lr = 3.125e-05
I0628 20:27:13.893748 17458 solver.cpp:243] Iteration 12310, loss = 3.00551
I0628 20:27:13.893774 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.12638 (* 1 = 2.12638 loss)
I0628 20:27:13.893780 17458 sgd_solver.cpp:138] Iteration 12310, lr = 3.125e-05
I0628 20:27:23.027886 17458 solver.cpp:243] Iteration 12320, loss = 3.30526
I0628 20:27:23.028048 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.29098 (* 1 = 2.29098 loss)
I0628 20:27:23.028074 17458 sgd_solver.cpp:138] Iteration 12320, lr = 3.125e-05
I0628 20:27:32.163985 17458 solver.cpp:243] Iteration 12330, loss = 3.05908
I0628 20:27:32.164008 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.53031 (* 1 = 2.53031 loss)
I0628 20:27:32.164016 17458 sgd_solver.cpp:138] Iteration 12330, lr = 3.125e-05
I0628 20:27:41.291384 17458 solver.cpp:243] Iteration 12340, loss = 2.5017
I0628 20:27:41.291409 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.318 (* 1 = 3.318 loss)
I0628 20:27:41.291415 17458 sgd_solver.cpp:138] Iteration 12340, lr = 3.125e-05
I0628 20:27:50.452491 17458 solver.cpp:243] Iteration 12350, loss = 3.06533
I0628 20:27:50.452515 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.02055 (* 1 = 2.02055 loss)
I0628 20:27:50.452523 17458 sgd_solver.cpp:138] Iteration 12350, lr = 3.125e-05
I0628 20:27:59.575446 17458 solver.cpp:243] Iteration 12360, loss = 3.0306
I0628 20:27:59.575609 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.27147 (* 1 = 2.27147 loss)
I0628 20:27:59.575618 17458 sgd_solver.cpp:138] Iteration 12360, lr = 3.125e-05
I0628 20:28:08.710024 17458 solver.cpp:243] Iteration 12370, loss = 3.56115
I0628 20:28:08.710049 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.53231 (* 1 = 2.53231 loss)
I0628 20:28:08.710075 17458 sgd_solver.cpp:138] Iteration 12370, lr = 3.125e-05
I0628 20:28:17.823423 17458 solver.cpp:243] Iteration 12380, loss = 3.24939
I0628 20:28:17.823448 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.56269 (* 1 = 5.56269 loss)
I0628 20:28:17.823457 17458 sgd_solver.cpp:138] Iteration 12380, lr = 3.125e-05
I0628 20:28:26.983775 17458 solver.cpp:243] Iteration 12390, loss = 3.40701
I0628 20:28:26.983800 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.86671 (* 1 = 1.86671 loss)
I0628 20:28:26.983808 17458 sgd_solver.cpp:138] Iteration 12390, lr = 3.125e-05
I0628 20:28:36.119410 17458 solver.cpp:243] Iteration 12400, loss = 3.22336
I0628 20:28:36.119588 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.28321 (* 1 = 5.28321 loss)
I0628 20:28:36.119598 17458 sgd_solver.cpp:138] Iteration 12400, lr = 3.125e-05
I0628 20:28:45.251543 17458 solver.cpp:243] Iteration 12410, loss = 3.02325
I0628 20:28:45.251565 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.64501 (* 1 = 3.64501 loss)
I0628 20:28:45.251592 17458 sgd_solver.cpp:138] Iteration 12410, lr = 3.125e-05
I0628 20:28:54.363649 17458 solver.cpp:243] Iteration 12420, loss = 3.1458
I0628 20:28:54.363673 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.33561 (* 1 = 3.33561 loss)
I0628 20:28:54.363680 17458 sgd_solver.cpp:138] Iteration 12420, lr = 3.125e-05
I0628 20:29:03.498721 17458 solver.cpp:243] Iteration 12430, loss = 3.62527
I0628 20:29:03.498746 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.37229 (* 1 = 4.37229 loss)
I0628 20:29:03.498754 17458 sgd_solver.cpp:138] Iteration 12430, lr = 3.125e-05
I0628 20:29:12.604328 17458 solver.cpp:243] Iteration 12440, loss = 2.76683
I0628 20:29:12.604490 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.26998 (* 1 = 3.26998 loss)
I0628 20:29:12.604498 17458 sgd_solver.cpp:138] Iteration 12440, lr = 3.125e-05
I0628 20:29:21.746362 17458 solver.cpp:243] Iteration 12450, loss = 3.21601
I0628 20:29:21.746387 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.7457 (* 1 = 2.7457 loss)
I0628 20:29:21.746395 17458 sgd_solver.cpp:138] Iteration 12450, lr = 3.125e-05
I0628 20:29:30.884116 17458 solver.cpp:243] Iteration 12460, loss = 2.66965
I0628 20:29:30.884140 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.67681 (* 1 = 3.67681 loss)
I0628 20:29:30.884148 17458 sgd_solver.cpp:138] Iteration 12460, lr = 3.125e-05
I0628 20:29:40.040367 17458 solver.cpp:243] Iteration 12470, loss = 2.99562
I0628 20:29:40.040393 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.96136 (* 1 = 1.96136 loss)
I0628 20:29:40.040400 17458 sgd_solver.cpp:138] Iteration 12470, lr = 3.125e-05
I0628 20:29:49.151235 17458 solver.cpp:243] Iteration 12480, loss = 3.46206
I0628 20:29:49.151393 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.25009 (* 1 = 5.25009 loss)
I0628 20:29:49.151401 17458 sgd_solver.cpp:138] Iteration 12480, lr = 3.125e-05
I0628 20:29:58.302547 17458 solver.cpp:243] Iteration 12490, loss = 3.91032
I0628 20:29:58.302570 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.49769 (* 1 = 3.49769 loss)
I0628 20:29:58.302597 17458 sgd_solver.cpp:138] Iteration 12490, lr = 3.125e-05
I0628 20:30:07.436529 17458 solver.cpp:243] Iteration 12500, loss = 2.99365
I0628 20:30:07.436553 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.00193 (* 1 = 1.00193 loss)
I0628 20:30:07.436579 17458 sgd_solver.cpp:138] Iteration 12500, lr = 3.125e-05
I0628 20:30:16.572903 17458 solver.cpp:243] Iteration 12510, loss = 3.04512
I0628 20:30:16.572928 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.46777 (* 1 = 2.46777 loss)
I0628 20:30:16.572935 17458 sgd_solver.cpp:138] Iteration 12510, lr = 3.125e-05
I0628 20:30:25.699375 17458 solver.cpp:243] Iteration 12520, loss = 3.10101
I0628 20:30:25.699564 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.93057 (* 1 = 1.93057 loss)
I0628 20:30:25.699573 17458 sgd_solver.cpp:138] Iteration 12520, lr = 3.125e-05
I0628 20:30:34.856256 17458 solver.cpp:243] Iteration 12530, loss = 3.63803
I0628 20:30:34.856281 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.96171 (* 1 = 1.96171 loss)
I0628 20:30:34.856288 17458 sgd_solver.cpp:138] Iteration 12530, lr = 3.125e-05
I0628 20:30:43.980202 17458 solver.cpp:243] Iteration 12540, loss = 3.22659
I0628 20:30:43.980227 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.70911 (* 1 = 2.70911 loss)
I0628 20:30:43.980235 17458 sgd_solver.cpp:138] Iteration 12540, lr = 3.125e-05
I0628 20:30:53.117575 17458 solver.cpp:243] Iteration 12550, loss = 3.82961
I0628 20:30:53.117600 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.14348 (* 1 = 5.14348 loss)
I0628 20:30:53.117609 17458 sgd_solver.cpp:138] Iteration 12550, lr = 3.125e-05
I0628 20:31:02.228844 17458 solver.cpp:243] Iteration 12560, loss = 3.63673
I0628 20:31:02.228972 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.13325 (* 1 = 5.13325 loss)
I0628 20:31:02.228981 17458 sgd_solver.cpp:138] Iteration 12560, lr = 3.125e-05
I0628 20:31:11.387362 17458 solver.cpp:243] Iteration 12570, loss = 2.81086
I0628 20:31:11.387387 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.47142 (* 1 = 1.47142 loss)
I0628 20:31:11.387394 17458 sgd_solver.cpp:138] Iteration 12570, lr = 3.125e-05
I0628 20:31:20.525491 17458 solver.cpp:243] Iteration 12580, loss = 3.84036
I0628 20:31:20.525514 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.92969 (* 1 = 2.92969 loss)
I0628 20:31:20.525539 17458 sgd_solver.cpp:138] Iteration 12580, lr = 3.125e-05
I0628 20:31:29.666481 17458 solver.cpp:243] Iteration 12590, loss = 3.19703
I0628 20:31:29.666507 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.76357 (* 1 = 3.76357 loss)
I0628 20:31:29.666515 17458 sgd_solver.cpp:138] Iteration 12590, lr = 3.125e-05
I0628 20:31:38.785960 17458 solver.cpp:243] Iteration 12600, loss = 3.49803
I0628 20:31:38.786121 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.78713 (* 1 = 3.78713 loss)
I0628 20:31:38.786149 17458 sgd_solver.cpp:138] Iteration 12600, lr = 3.125e-05
I0628 20:31:47.944311 17458 solver.cpp:243] Iteration 12610, loss = 3.21521
I0628 20:31:47.944336 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.26349 (* 1 = 4.26349 loss)
I0628 20:31:47.944362 17458 sgd_solver.cpp:138] Iteration 12610, lr = 3.125e-05
I0628 20:31:57.073334 17458 solver.cpp:243] Iteration 12620, loss = 3.71234
I0628 20:31:57.073359 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.83262 (* 1 = 3.83262 loss)
I0628 20:31:57.073366 17458 sgd_solver.cpp:138] Iteration 12620, lr = 3.125e-05
I0628 20:32:06.205689 17458 solver.cpp:243] Iteration 12630, loss = 2.70642
I0628 20:32:06.205714 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.81168 (* 1 = 1.81168 loss)
I0628 20:32:06.205722 17458 sgd_solver.cpp:138] Iteration 12630, lr = 3.125e-05
I0628 20:32:15.317167 17458 solver.cpp:243] Iteration 12640, loss = 3.338
I0628 20:32:15.317334 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.00625 (* 1 = 4.00625 loss)
I0628 20:32:15.317360 17458 sgd_solver.cpp:138] Iteration 12640, lr = 3.125e-05
I0628 20:32:24.475256 17458 solver.cpp:243] Iteration 12650, loss = 3.10305
I0628 20:32:24.475281 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.98861 (* 1 = 4.98861 loss)
I0628 20:32:24.475289 17458 sgd_solver.cpp:138] Iteration 12650, lr = 3.125e-05
I0628 20:32:33.611199 17458 solver.cpp:243] Iteration 12660, loss = 2.621
I0628 20:32:33.611223 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.58405 (* 1 = 2.58405 loss)
I0628 20:32:33.611249 17458 sgd_solver.cpp:138] Iteration 12660, lr = 3.125e-05
I0628 20:32:42.747113 17458 solver.cpp:243] Iteration 12670, loss = 2.9979
I0628 20:32:42.747138 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.59186 (* 1 = 2.59186 loss)
I0628 20:32:42.747146 17458 sgd_solver.cpp:138] Iteration 12670, lr = 3.125e-05
I0628 20:32:51.875735 17458 solver.cpp:243] Iteration 12680, loss = 3.31231
I0628 20:32:51.875924 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.42635 (* 1 = 3.42635 loss)
I0628 20:32:51.875933 17458 sgd_solver.cpp:138] Iteration 12680, lr = 3.125e-05
I0628 20:33:01.035974 17458 solver.cpp:243] Iteration 12690, loss = 3.46573
I0628 20:33:01.036000 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.305 (* 1 = 2.305 loss)
I0628 20:33:01.036006 17458 sgd_solver.cpp:138] Iteration 12690, lr = 3.125e-05
I0628 20:33:10.171272 17458 solver.cpp:243] Iteration 12700, loss = 2.97385
I0628 20:33:10.171298 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.00593 (* 1 = 3.00593 loss)
I0628 20:33:10.171304 17458 sgd_solver.cpp:138] Iteration 12700, lr = 3.125e-05
I0628 20:33:19.326485 17458 solver.cpp:243] Iteration 12710, loss = 3.57663
I0628 20:33:19.326510 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.40791 (* 1 = 2.40791 loss)
I0628 20:33:19.326517 17458 sgd_solver.cpp:138] Iteration 12710, lr = 3.125e-05
I0628 20:33:28.437465 17458 solver.cpp:243] Iteration 12720, loss = 3.62554
I0628 20:33:28.437610 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.87761 (* 1 = 3.87761 loss)
I0628 20:33:28.437619 17458 sgd_solver.cpp:138] Iteration 12720, lr = 3.125e-05
I0628 20:33:37.588532 17458 solver.cpp:243] Iteration 12730, loss = 2.85608
I0628 20:33:37.588557 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.72756 (* 1 = 3.72756 loss)
I0628 20:33:37.588563 17458 sgd_solver.cpp:138] Iteration 12730, lr = 3.125e-05
I0628 20:33:46.722237 17458 solver.cpp:243] Iteration 12740, loss = 3.20005
I0628 20:33:46.722260 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.76955 (* 1 = 2.76955 loss)
I0628 20:33:46.722267 17458 sgd_solver.cpp:138] Iteration 12740, lr = 3.125e-05
I0628 20:33:55.859215 17458 solver.cpp:243] Iteration 12750, loss = 3.52776
I0628 20:33:55.859241 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.9924 (* 1 = 3.9924 loss)
I0628 20:33:55.859248 17458 sgd_solver.cpp:138] Iteration 12750, lr = 3.125e-05
I0628 20:34:04.967737 17458 solver.cpp:243] Iteration 12760, loss = 2.39383
I0628 20:34:04.967900 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.73089 (* 1 = 2.73089 loss)
I0628 20:34:04.967927 17458 sgd_solver.cpp:138] Iteration 12760, lr = 3.125e-05
I0628 20:34:14.108227 17458 solver.cpp:243] Iteration 12770, loss = 3.34887
I0628 20:34:14.108251 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.638 (* 1 = 3.638 loss)
I0628 20:34:14.108276 17458 sgd_solver.cpp:138] Iteration 12770, lr = 3.125e-05
I0628 20:34:23.239179 17458 solver.cpp:243] Iteration 12780, loss = 3.18961
I0628 20:34:23.239204 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.46711 (* 1 = 2.46711 loss)
I0628 20:34:23.239212 17458 sgd_solver.cpp:138] Iteration 12780, lr = 3.125e-05
I0628 20:34:32.391656 17458 solver.cpp:243] Iteration 12790, loss = 3.04853
I0628 20:34:32.391682 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.0928 (* 1 = 3.0928 loss)
I0628 20:34:32.391690 17458 sgd_solver.cpp:138] Iteration 12790, lr = 3.125e-05
I0628 20:34:41.504230 17458 solver.cpp:243] Iteration 12800, loss = 2.70599
I0628 20:34:41.504392 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.51601 (* 1 = 2.51601 loss)
I0628 20:34:41.504420 17458 sgd_solver.cpp:138] Iteration 12800, lr = 3.125e-05
I0628 20:34:50.653762 17458 solver.cpp:243] Iteration 12810, loss = 2.98598
I0628 20:34:50.653787 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.10818 (* 1 = 4.10818 loss)
I0628 20:34:50.653795 17458 sgd_solver.cpp:138] Iteration 12810, lr = 3.125e-05
I0628 20:34:59.787315 17458 solver.cpp:243] Iteration 12820, loss = 3.22974
I0628 20:34:59.787340 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.45348 (* 1 = 1.45348 loss)
I0628 20:34:59.787348 17458 sgd_solver.cpp:138] Iteration 12820, lr = 3.125e-05
I0628 20:35:08.940789 17458 solver.cpp:243] Iteration 12830, loss = 2.84243
I0628 20:35:08.940814 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.46218 (* 1 = 3.46218 loss)
I0628 20:35:08.940840 17458 sgd_solver.cpp:138] Iteration 12830, lr = 3.125e-05
I0628 20:35:18.077023 17458 solver.cpp:243] Iteration 12840, loss = 3.31095
I0628 20:35:18.077211 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.48808 (* 1 = 2.48808 loss)
I0628 20:35:18.077220 17458 sgd_solver.cpp:138] Iteration 12840, lr = 3.125e-05
I0628 20:35:27.226575 17458 solver.cpp:243] Iteration 12850, loss = 2.95974
I0628 20:35:27.226600 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.53908 (* 1 = 1.53908 loss)
I0628 20:35:27.226608 17458 sgd_solver.cpp:138] Iteration 12850, lr = 3.125e-05
I0628 20:35:36.335507 17458 solver.cpp:243] Iteration 12860, loss = 3.2238
I0628 20:35:36.335531 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.34428 (* 1 = 3.34428 loss)
I0628 20:35:36.335539 17458 sgd_solver.cpp:138] Iteration 12860, lr = 3.125e-05
I0628 20:35:45.471331 17458 solver.cpp:243] Iteration 12870, loss = 3.71067
I0628 20:35:45.471355 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.29069 (* 1 = 4.29069 loss)
I0628 20:35:45.471364 17458 sgd_solver.cpp:138] Iteration 12870, lr = 3.125e-05
I0628 20:35:54.606318 17458 solver.cpp:243] Iteration 12880, loss = 3.40554
I0628 20:35:54.606493 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.83315 (* 1 = 3.83315 loss)
I0628 20:35:54.606501 17458 sgd_solver.cpp:138] Iteration 12880, lr = 3.125e-05
I0628 20:36:03.763715 17458 solver.cpp:243] Iteration 12890, loss = 3.28048
I0628 20:36:03.763758 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.54776 (* 1 = 5.54776 loss)
I0628 20:36:03.763767 17458 sgd_solver.cpp:138] Iteration 12890, lr = 3.125e-05
I0628 20:36:12.872880 17458 solver.cpp:243] Iteration 12900, loss = 3.38668
I0628 20:36:12.872905 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.24547 (* 1 = 2.24547 loss)
I0628 20:36:12.872929 17458 sgd_solver.cpp:138] Iteration 12900, lr = 3.125e-05
I0628 20:36:22.010124 17458 solver.cpp:243] Iteration 12910, loss = 2.36449
I0628 20:36:22.010149 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.79211 (* 1 = 1.79211 loss)
I0628 20:36:22.010157 17458 sgd_solver.cpp:138] Iteration 12910, lr = 3.125e-05
I0628 20:36:31.119442 17458 solver.cpp:243] Iteration 12920, loss = 2.5187
I0628 20:36:31.119637 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.24439 (* 1 = 2.24439 loss)
I0628 20:36:31.119666 17458 sgd_solver.cpp:138] Iteration 12920, lr = 3.125e-05
I0628 20:36:40.260361 17458 solver.cpp:243] Iteration 12930, loss = 3.18704
I0628 20:36:40.260386 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.16278 (* 1 = 4.16278 loss)
I0628 20:36:40.260412 17458 sgd_solver.cpp:138] Iteration 12930, lr = 3.125e-05
I0628 20:36:49.394381 17458 solver.cpp:243] Iteration 12940, loss = 3.58713
I0628 20:36:49.394404 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.65523 (* 1 = 3.65523 loss)
I0628 20:36:49.394430 17458 sgd_solver.cpp:138] Iteration 12940, lr = 3.125e-05
I0628 20:36:58.545601 17458 solver.cpp:243] Iteration 12950, loss = 3.34181
I0628 20:36:58.545627 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.23004 (* 1 = 3.23004 loss)
I0628 20:36:58.545634 17458 sgd_solver.cpp:138] Iteration 12950, lr = 3.125e-05
I0628 20:37:07.674190 17458 solver.cpp:243] Iteration 12960, loss = 3.52455
I0628 20:37:07.674332 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.69141 (* 1 = 3.69141 loss)
I0628 20:37:07.674358 17458 sgd_solver.cpp:138] Iteration 12960, lr = 3.125e-05
I0628 20:37:16.835216 17458 solver.cpp:243] Iteration 12970, loss = 3.07117
I0628 20:37:16.835242 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.56315 (* 1 = 2.56315 loss)
I0628 20:37:16.835249 17458 sgd_solver.cpp:138] Iteration 12970, lr = 3.125e-05
I0628 20:37:25.963063 17458 solver.cpp:243] Iteration 12980, loss = 2.89153
I0628 20:37:25.963097 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.82 (* 1 = 4.82 loss)
I0628 20:37:25.963124 17458 sgd_solver.cpp:138] Iteration 12980, lr = 3.125e-05
I0628 20:37:35.111865 17458 solver.cpp:243] Iteration 12990, loss = 3.08697
I0628 20:37:35.111887 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.09045 (* 1 = 3.09045 loss)
I0628 20:37:35.111913 17458 sgd_solver.cpp:138] Iteration 12990, lr = 3.125e-05
I0628 20:37:43.493808 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_13000.caffemodel
I0628 20:37:43.577136 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_13000.solverstate
I0628 20:37:43.610213 17458 solver.cpp:433] Iteration 13000, Testing net (#0)
I0628 20:37:43.610417 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 20:40:48.426028 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.330411
I0628 20:40:49.211257 17458 solver.cpp:243] Iteration 13000, loss = 3.79074
I0628 20:40:49.211282 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.02311 (* 1 = 3.02311 loss)
I0628 20:40:49.211308 17458 sgd_solver.cpp:138] Iteration 13000, lr = 3.125e-05
I0628 20:40:58.361344 17458 solver.cpp:243] Iteration 13010, loss = 3.98564
I0628 20:40:58.361368 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.27976 (* 1 = 5.27976 loss)
I0628 20:40:58.361393 17458 sgd_solver.cpp:138] Iteration 13010, lr = 3.125e-05
I0628 20:41:07.492893 17458 solver.cpp:243] Iteration 13020, loss = 2.75304
I0628 20:41:07.492918 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.54386 (* 1 = 2.54386 loss)
I0628 20:41:07.492925 17458 sgd_solver.cpp:138] Iteration 13020, lr = 3.125e-05
I0628 20:41:16.650928 17458 solver.cpp:243] Iteration 13030, loss = 3.66554
I0628 20:41:16.650951 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.08373 (* 1 = 3.08373 loss)
I0628 20:41:16.650959 17458 sgd_solver.cpp:138] Iteration 13030, lr = 3.125e-05
I0628 20:41:25.786556 17458 solver.cpp:243] Iteration 13040, loss = 3.21569
I0628 20:41:25.786681 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.0228 (* 1 = 4.0228 loss)
I0628 20:41:25.786690 17458 sgd_solver.cpp:138] Iteration 13040, lr = 3.125e-05
I0628 20:41:34.944218 17458 solver.cpp:243] Iteration 13050, loss = 2.77713
I0628 20:41:34.944243 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.3104 (* 1 = 2.3104 loss)
I0628 20:41:34.944250 17458 sgd_solver.cpp:138] Iteration 13050, lr = 3.125e-05
I0628 20:41:44.068397 17458 solver.cpp:243] Iteration 13060, loss = 3.2666
I0628 20:41:44.068439 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.31657 (* 1 = 4.31657 loss)
I0628 20:41:44.068447 17458 sgd_solver.cpp:138] Iteration 13060, lr = 3.125e-05
I0628 20:41:53.200385 17458 solver.cpp:243] Iteration 13070, loss = 3.6153
I0628 20:41:53.200410 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.19141 (* 1 = 5.19141 loss)
I0628 20:41:53.200418 17458 sgd_solver.cpp:138] Iteration 13070, lr = 3.125e-05
I0628 20:42:02.311795 17458 solver.cpp:243] Iteration 13080, loss = 3.19088
I0628 20:42:02.311928 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.68089 (* 1 = 2.68089 loss)
I0628 20:42:02.311936 17458 sgd_solver.cpp:138] Iteration 13080, lr = 3.125e-05
I0628 20:42:11.443078 17458 solver.cpp:243] Iteration 13090, loss = 3.72411
I0628 20:42:11.443102 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.04856 (* 1 = 3.04856 loss)
I0628 20:42:11.443110 17458 sgd_solver.cpp:138] Iteration 13090, lr = 3.125e-05
I0628 20:42:20.560575 17458 solver.cpp:243] Iteration 13100, loss = 2.86454
I0628 20:42:20.560597 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.96725 (* 1 = 2.96725 loss)
I0628 20:42:20.560622 17458 sgd_solver.cpp:138] Iteration 13100, lr = 3.125e-05
I0628 20:42:29.699522 17458 solver.cpp:243] Iteration 13110, loss = 2.75283
I0628 20:42:29.699546 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.86205 (* 1 = 2.86205 loss)
I0628 20:42:29.699573 17458 sgd_solver.cpp:138] Iteration 13110, lr = 3.125e-05
I0628 20:42:38.814139 17458 solver.cpp:243] Iteration 13120, loss = 2.75945
I0628 20:42:38.814354 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.43692 (* 1 = 2.43692 loss)
I0628 20:42:38.814378 17458 sgd_solver.cpp:138] Iteration 13120, lr = 3.125e-05
I0628 20:42:47.953231 17458 solver.cpp:243] Iteration 13130, loss = 3.66133
I0628 20:42:47.953255 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.80862 (* 1 = 2.80862 loss)
I0628 20:42:47.953281 17458 sgd_solver.cpp:138] Iteration 13130, lr = 3.125e-05
I0628 20:42:57.069353 17458 solver.cpp:243] Iteration 13140, loss = 2.96789
I0628 20:42:57.069376 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.99916 (* 1 = 1.99916 loss)
I0628 20:42:57.069401 17458 sgd_solver.cpp:138] Iteration 13140, lr = 3.125e-05
I0628 20:43:06.212924 17458 solver.cpp:243] Iteration 13150, loss = 2.99052
I0628 20:43:06.212946 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.08541 (* 1 = 4.08541 loss)
I0628 20:43:06.212972 17458 sgd_solver.cpp:138] Iteration 13150, lr = 3.125e-05
I0628 20:43:15.340680 17458 solver.cpp:243] Iteration 13160, loss = 3.61533
I0628 20:43:15.340847 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.65461 (* 1 = 2.65461 loss)
I0628 20:43:15.340857 17458 sgd_solver.cpp:138] Iteration 13160, lr = 3.125e-05
I0628 20:43:24.489285 17458 solver.cpp:243] Iteration 13170, loss = 3.32687
I0628 20:43:24.489313 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.59388 (* 1 = 1.59388 loss)
I0628 20:43:24.489333 17458 sgd_solver.cpp:138] Iteration 13170, lr = 3.125e-05
I0628 20:43:33.615540 17458 solver.cpp:243] Iteration 13180, loss = 2.82255
I0628 20:43:33.615562 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.36006 (* 1 = 2.36006 loss)
I0628 20:43:33.615587 17458 sgd_solver.cpp:138] Iteration 13180, lr = 3.125e-05
I0628 20:43:42.767004 17458 solver.cpp:243] Iteration 13190, loss = 3.0685
I0628 20:43:42.767029 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.91247 (* 1 = 2.91247 loss)
I0628 20:43:42.767053 17458 sgd_solver.cpp:138] Iteration 13190, lr = 3.125e-05
I0628 20:43:51.892549 17458 solver.cpp:243] Iteration 13200, loss = 3.45672
I0628 20:43:51.892679 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.72806 (* 1 = 2.72806 loss)
I0628 20:43:51.892688 17458 sgd_solver.cpp:138] Iteration 13200, lr = 3.125e-05
I0628 20:44:01.044553 17458 solver.cpp:243] Iteration 13210, loss = 2.9476
I0628 20:44:01.044576 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.17488 (* 1 = 3.17488 loss)
I0628 20:44:01.044603 17458 sgd_solver.cpp:138] Iteration 13210, lr = 3.125e-05
I0628 20:44:10.177826 17458 solver.cpp:243] Iteration 13220, loss = 3.62218
I0628 20:44:10.177850 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.36609 (* 1 = 4.36609 loss)
I0628 20:44:10.177875 17458 sgd_solver.cpp:138] Iteration 13220, lr = 3.125e-05
I0628 20:44:19.342295 17458 solver.cpp:243] Iteration 13230, loss = 2.54638
I0628 20:44:19.342319 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.65862 (* 1 = 2.65862 loss)
I0628 20:44:19.342345 17458 sgd_solver.cpp:138] Iteration 13230, lr = 3.125e-05
I0628 20:44:28.476920 17458 solver.cpp:243] Iteration 13240, loss = 3.37849
I0628 20:44:28.477057 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.98933 (* 1 = 2.98933 loss)
I0628 20:44:28.477066 17458 sgd_solver.cpp:138] Iteration 13240, lr = 3.125e-05
I0628 20:44:37.635035 17458 solver.cpp:243] Iteration 13250, loss = 3.73805
I0628 20:44:37.635059 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.73529 (* 1 = 4.73529 loss)
I0628 20:44:37.635066 17458 sgd_solver.cpp:138] Iteration 13250, lr = 3.125e-05
I0628 20:44:46.769853 17458 solver.cpp:243] Iteration 13260, loss = 3.03443
I0628 20:44:46.769874 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.40809 (* 1 = 4.40809 loss)
I0628 20:44:46.769882 17458 sgd_solver.cpp:138] Iteration 13260, lr = 3.125e-05
I0628 20:44:55.924805 17458 solver.cpp:243] Iteration 13270, loss = 3.41242
I0628 20:44:55.924829 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.31793 (* 1 = 3.31793 loss)
I0628 20:44:55.924855 17458 sgd_solver.cpp:138] Iteration 13270, lr = 3.125e-05
I0628 20:45:05.058709 17458 solver.cpp:243] Iteration 13280, loss = 3.46634
I0628 20:45:05.058938 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.25077 (* 1 = 2.25077 loss)
I0628 20:45:05.058966 17458 sgd_solver.cpp:138] Iteration 13280, lr = 3.125e-05
I0628 20:45:14.217550 17458 solver.cpp:243] Iteration 13290, loss = 3.53749
I0628 20:45:14.217573 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.06355 (* 1 = 3.06355 loss)
I0628 20:45:14.217581 17458 sgd_solver.cpp:138] Iteration 13290, lr = 3.125e-05
I0628 20:45:23.350270 17458 solver.cpp:243] Iteration 13300, loss = 3.39339
I0628 20:45:23.350296 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.86816 (* 1 = 2.86816 loss)
I0628 20:45:23.350302 17458 sgd_solver.cpp:138] Iteration 13300, lr = 3.125e-05
I0628 20:45:32.509418 17458 solver.cpp:243] Iteration 13310, loss = 2.95602
I0628 20:45:32.509443 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.60769 (* 1 = 4.60769 loss)
I0628 20:45:32.509467 17458 sgd_solver.cpp:138] Iteration 13310, lr = 3.125e-05
I0628 20:45:41.642735 17458 solver.cpp:243] Iteration 13320, loss = 3.65594
I0628 20:45:41.642902 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.54229 (* 1 = 3.54229 loss)
I0628 20:45:41.642930 17458 sgd_solver.cpp:138] Iteration 13320, lr = 3.125e-05
I0628 20:45:50.800237 17458 solver.cpp:243] Iteration 13330, loss = 3.1153
I0628 20:45:50.800262 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.3334 (* 1 = 1.3334 loss)
I0628 20:45:50.800288 17458 sgd_solver.cpp:138] Iteration 13330, lr = 3.125e-05
I0628 20:45:59.934065 17458 solver.cpp:243] Iteration 13340, loss = 3.17121
I0628 20:45:59.934088 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.64846 (* 1 = 2.64846 loss)
I0628 20:45:59.934095 17458 sgd_solver.cpp:138] Iteration 13340, lr = 3.125e-05
I0628 20:46:09.091827 17458 solver.cpp:243] Iteration 13350, loss = 3.16851
I0628 20:46:09.091851 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.71131 (* 1 = 1.71131 loss)
I0628 20:46:09.091877 17458 sgd_solver.cpp:138] Iteration 13350, lr = 3.125e-05
I0628 20:46:18.220763 17458 solver.cpp:243] Iteration 13360, loss = 3.68736
I0628 20:46:18.220875 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.81973 (* 1 = 5.81973 loss)
I0628 20:46:18.220899 17458 sgd_solver.cpp:138] Iteration 13360, lr = 3.125e-05
I0628 20:46:27.383172 17458 solver.cpp:243] Iteration 13370, loss = 3.21826
I0628 20:46:27.383196 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.04172 (* 1 = 2.04172 loss)
I0628 20:46:27.383222 17458 sgd_solver.cpp:138] Iteration 13370, lr = 3.125e-05
I0628 20:46:36.524924 17458 solver.cpp:243] Iteration 13380, loss = 2.94093
I0628 20:46:36.524947 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.41535 (* 1 = 2.41535 loss)
I0628 20:46:36.524973 17458 sgd_solver.cpp:138] Iteration 13380, lr = 3.125e-05
I0628 20:46:45.678166 17458 solver.cpp:243] Iteration 13390, loss = 3.39848
I0628 20:46:45.678190 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.38221 (* 1 = 4.38221 loss)
I0628 20:46:45.678216 17458 sgd_solver.cpp:138] Iteration 13390, lr = 3.125e-05
I0628 20:46:54.814688 17458 solver.cpp:243] Iteration 13400, loss = 2.92669
I0628 20:46:54.814815 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.70745 (* 1 = 2.70745 loss)
I0628 20:46:54.814843 17458 sgd_solver.cpp:138] Iteration 13400, lr = 3.125e-05
I0628 20:47:03.983671 17458 solver.cpp:243] Iteration 13410, loss = 3.21821
I0628 20:47:03.983696 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.02605 (* 1 = 4.02605 loss)
I0628 20:47:03.983723 17458 sgd_solver.cpp:138] Iteration 13410, lr = 3.125e-05
I0628 20:47:13.131800 17458 solver.cpp:243] Iteration 13420, loss = 2.94279
I0628 20:47:13.131824 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.48061 (* 1 = 1.48061 loss)
I0628 20:47:13.131832 17458 sgd_solver.cpp:138] Iteration 13420, lr = 3.125e-05
I0628 20:47:22.292001 17458 solver.cpp:243] Iteration 13430, loss = 3.03842
I0628 20:47:22.292026 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.96509 (* 1 = 3.96509 loss)
I0628 20:47:22.292052 17458 sgd_solver.cpp:138] Iteration 13430, lr = 3.125e-05
I0628 20:47:31.430655 17458 solver.cpp:243] Iteration 13440, loss = 2.84515
I0628 20:47:31.430871 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.9985 (* 1 = 3.9985 loss)
I0628 20:47:31.430881 17458 sgd_solver.cpp:138] Iteration 13440, lr = 3.125e-05
I0628 20:47:40.598361 17458 solver.cpp:243] Iteration 13450, loss = 3.43879
I0628 20:47:40.598384 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.54437 (* 1 = 3.54437 loss)
I0628 20:47:40.598392 17458 sgd_solver.cpp:138] Iteration 13450, lr = 3.125e-05
I0628 20:47:49.741905 17458 solver.cpp:243] Iteration 13460, loss = 3.55667
I0628 20:47:49.741928 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.22305 (* 1 = 1.22305 loss)
I0628 20:47:49.741936 17458 sgd_solver.cpp:138] Iteration 13460, lr = 3.125e-05
I0628 20:47:58.903831 17458 solver.cpp:243] Iteration 13470, loss = 3.89325
I0628 20:47:58.903854 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.95186 (* 1 = 4.95186 loss)
I0628 20:47:58.903880 17458 sgd_solver.cpp:138] Iteration 13470, lr = 3.125e-05
I0628 20:48:08.051934 17458 solver.cpp:243] Iteration 13480, loss = 3.49466
I0628 20:48:08.052099 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.03539 (* 1 = 2.03539 loss)
I0628 20:48:08.052109 17458 sgd_solver.cpp:138] Iteration 13480, lr = 3.125e-05
I0628 20:48:17.218924 17458 solver.cpp:243] Iteration 13490, loss = 2.63059
I0628 20:48:17.218948 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.07411 (* 1 = 2.07411 loss)
I0628 20:48:17.218974 17458 sgd_solver.cpp:138] Iteration 13490, lr = 3.125e-05
I0628 20:48:26.360057 17458 solver.cpp:243] Iteration 13500, loss = 3.23557
I0628 20:48:26.360080 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.7236 (* 1 = 4.7236 loss)
I0628 20:48:26.360106 17458 sgd_solver.cpp:138] Iteration 13500, lr = 3.125e-05
I0628 20:48:35.513550 17458 solver.cpp:243] Iteration 13510, loss = 3.86642
I0628 20:48:35.513574 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.32255 (* 1 = 4.32255 loss)
I0628 20:48:35.513600 17458 sgd_solver.cpp:138] Iteration 13510, lr = 3.125e-05
I0628 20:48:44.652693 17458 solver.cpp:243] Iteration 13520, loss = 3.43235
I0628 20:48:44.652820 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.69088 (* 1 = 6.69088 loss)
I0628 20:48:44.652829 17458 sgd_solver.cpp:138] Iteration 13520, lr = 3.125e-05
I0628 20:48:53.812343 17458 solver.cpp:243] Iteration 13530, loss = 2.9183
I0628 20:48:53.812368 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.916 (* 1 = 4.916 loss)
I0628 20:48:53.812394 17458 sgd_solver.cpp:138] Iteration 13530, lr = 3.125e-05
I0628 20:49:02.952926 17458 solver.cpp:243] Iteration 13540, loss = 3.94429
I0628 20:49:02.952950 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.80394 (* 1 = 2.80394 loss)
I0628 20:49:02.952975 17458 sgd_solver.cpp:138] Iteration 13540, lr = 3.125e-05
I0628 20:49:12.118232 17458 solver.cpp:243] Iteration 13550, loss = 2.66459
I0628 20:49:12.118257 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25487 (* 1 = 3.25487 loss)
I0628 20:49:12.118283 17458 sgd_solver.cpp:138] Iteration 13550, lr = 3.125e-05
I0628 20:49:21.259147 17458 solver.cpp:243] Iteration 13560, loss = 3.14282
I0628 20:49:21.259274 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.01988 (* 1 = 3.01988 loss)
I0628 20:49:21.259297 17458 sgd_solver.cpp:138] Iteration 13560, lr = 3.125e-05
I0628 20:49:30.418895 17458 solver.cpp:243] Iteration 13570, loss = 3.53904
I0628 20:49:30.418941 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.96097 (* 1 = 2.96097 loss)
I0628 20:49:30.418967 17458 sgd_solver.cpp:138] Iteration 13570, lr = 3.125e-05
I0628 20:49:39.553337 17458 solver.cpp:243] Iteration 13580, loss = 3.29401
I0628 20:49:39.553362 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.46355 (* 1 = 3.46355 loss)
I0628 20:49:39.553370 17458 sgd_solver.cpp:138] Iteration 13580, lr = 3.125e-05
I0628 20:49:48.722606 17458 solver.cpp:243] Iteration 13590, loss = 3.13054
I0628 20:49:48.722630 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.45213 (* 1 = 3.45213 loss)
I0628 20:49:48.722656 17458 sgd_solver.cpp:138] Iteration 13590, lr = 3.125e-05
I0628 20:49:57.862144 17458 solver.cpp:243] Iteration 13600, loss = 2.4286
I0628 20:49:57.862334 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.40728 (* 1 = 2.40728 loss)
I0628 20:49:57.862344 17458 sgd_solver.cpp:138] Iteration 13600, lr = 3.125e-05
I0628 20:50:07.035607 17458 solver.cpp:243] Iteration 13610, loss = 2.42121
I0628 20:50:07.035650 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.75085 (* 1 = 2.75085 loss)
I0628 20:50:07.035676 17458 sgd_solver.cpp:138] Iteration 13610, lr = 3.125e-05
I0628 20:50:16.176966 17458 solver.cpp:243] Iteration 13620, loss = 2.93363
I0628 20:50:16.176990 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.99721 (* 1 = 3.99721 loss)
I0628 20:50:16.177016 17458 sgd_solver.cpp:138] Iteration 13620, lr = 3.125e-05
I0628 20:50:25.343510 17458 solver.cpp:243] Iteration 13630, loss = 3.08898
I0628 20:50:25.343534 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.28345 (* 1 = 3.28345 loss)
I0628 20:50:25.343560 17458 sgd_solver.cpp:138] Iteration 13630, lr = 3.125e-05
I0628 20:50:34.480306 17458 solver.cpp:243] Iteration 13640, loss = 3.57737
I0628 20:50:34.480451 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.39857 (* 1 = 4.39857 loss)
I0628 20:50:34.480477 17458 sgd_solver.cpp:138] Iteration 13640, lr = 3.125e-05
I0628 20:50:43.644412 17458 solver.cpp:243] Iteration 13650, loss = 3.2953
I0628 20:50:43.644436 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.16424 (* 1 = 2.16424 loss)
I0628 20:50:43.644462 17458 sgd_solver.cpp:138] Iteration 13650, lr = 3.125e-05
I0628 20:50:52.784444 17458 solver.cpp:243] Iteration 13660, loss = 2.99759
I0628 20:50:52.784485 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.13172 (* 1 = 5.13172 loss)
I0628 20:50:52.784492 17458 sgd_solver.cpp:138] Iteration 13660, lr = 3.125e-05
I0628 20:51:01.952749 17458 solver.cpp:243] Iteration 13670, loss = 3.92822
I0628 20:51:01.952772 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.07309 (* 1 = 2.07309 loss)
I0628 20:51:01.952798 17458 sgd_solver.cpp:138] Iteration 13670, lr = 3.125e-05
I0628 20:51:11.094883 17458 solver.cpp:243] Iteration 13680, loss = 3.10601
I0628 20:51:11.094995 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.65579 (* 1 = 2.65579 loss)
I0628 20:51:11.095021 17458 sgd_solver.cpp:138] Iteration 13680, lr = 3.125e-05
I0628 20:51:20.260800 17458 solver.cpp:243] Iteration 13690, loss = 2.89528
I0628 20:51:20.260824 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.23801 (* 1 = 4.23801 loss)
I0628 20:51:20.260850 17458 sgd_solver.cpp:138] Iteration 13690, lr = 3.125e-05
I0628 20:51:29.402333 17458 solver.cpp:243] Iteration 13700, loss = 3.75182
I0628 20:51:29.402356 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.34398 (* 1 = 6.34398 loss)
I0628 20:51:29.402364 17458 sgd_solver.cpp:138] Iteration 13700, lr = 3.125e-05
I0628 20:51:38.565443 17458 solver.cpp:243] Iteration 13710, loss = 4.20536
I0628 20:51:38.565466 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.52382 (* 1 = 4.52382 loss)
I0628 20:51:38.565501 17458 sgd_solver.cpp:138] Iteration 13710, lr = 3.125e-05
I0628 20:51:47.701614 17458 solver.cpp:243] Iteration 13720, loss = 3.0382
I0628 20:51:47.701790 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.19125 (* 1 = 3.19125 loss)
I0628 20:51:47.701818 17458 sgd_solver.cpp:138] Iteration 13720, lr = 3.125e-05
I0628 20:51:56.862224 17458 solver.cpp:243] Iteration 13730, loss = 3.92692
I0628 20:51:56.862248 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.41371 (* 1 = 4.41371 loss)
I0628 20:51:56.862274 17458 sgd_solver.cpp:138] Iteration 13730, lr = 3.125e-05
I0628 20:52:06.006752 17458 solver.cpp:243] Iteration 13740, loss = 2.48872
I0628 20:52:06.006775 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.55425 (* 1 = 2.55425 loss)
I0628 20:52:06.006801 17458 sgd_solver.cpp:138] Iteration 13740, lr = 3.125e-05
I0628 20:52:15.176363 17458 solver.cpp:243] Iteration 13750, loss = 3.09536
I0628 20:52:15.176388 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.56287 (* 1 = 2.56287 loss)
I0628 20:52:15.176414 17458 sgd_solver.cpp:138] Iteration 13750, lr = 3.125e-05
I0628 20:52:24.311691 17458 solver.cpp:243] Iteration 13760, loss = 3.31849
I0628 20:52:24.311897 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.09276 (* 1 = 3.09276 loss)
I0628 20:52:24.311908 17458 sgd_solver.cpp:138] Iteration 13760, lr = 3.125e-05
I0628 20:52:33.473248 17458 solver.cpp:243] Iteration 13770, loss = 3.61822
I0628 20:52:33.473273 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.06077 (* 1 = 6.06077 loss)
I0628 20:52:33.473299 17458 sgd_solver.cpp:138] Iteration 13770, lr = 3.125e-05
I0628 20:52:42.606500 17458 solver.cpp:243] Iteration 13780, loss = 3.55165
I0628 20:52:42.606525 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.20893 (* 1 = 1.20893 loss)
I0628 20:52:42.606551 17458 sgd_solver.cpp:138] Iteration 13780, lr = 3.125e-05
I0628 20:52:51.759272 17458 solver.cpp:243] Iteration 13790, loss = 3.45478
I0628 20:52:51.759296 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.80524 (* 1 = 4.80524 loss)
I0628 20:52:51.759322 17458 sgd_solver.cpp:138] Iteration 13790, lr = 3.125e-05
I0628 20:53:00.895900 17458 solver.cpp:243] Iteration 13800, loss = 3.44754
I0628 20:53:00.896039 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.06389 (* 1 = 2.06389 loss)
I0628 20:53:00.896046 17458 sgd_solver.cpp:138] Iteration 13800, lr = 3.125e-05
I0628 20:53:10.054070 17458 solver.cpp:243] Iteration 13810, loss = 2.65524
I0628 20:53:10.054096 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.57331 (* 1 = 1.57331 loss)
I0628 20:53:10.054105 17458 sgd_solver.cpp:138] Iteration 13810, lr = 3.125e-05
I0628 20:53:19.167963 17458 solver.cpp:243] Iteration 13820, loss = 3.56475
I0628 20:53:19.167987 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.96755 (* 1 = 2.96755 loss)
I0628 20:53:19.167994 17458 sgd_solver.cpp:138] Iteration 13820, lr = 3.125e-05
I0628 20:53:28.283782 17458 solver.cpp:243] Iteration 13830, loss = 3.56792
I0628 20:53:28.283812 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.07234 (* 1 = 3.07234 loss)
I0628 20:53:28.283821 17458 sgd_solver.cpp:138] Iteration 13830, lr = 3.125e-05
I0628 20:53:37.395771 17458 solver.cpp:243] Iteration 13840, loss = 3.44692
I0628 20:53:37.395939 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.45928 (* 1 = 2.45928 loss)
I0628 20:53:37.395948 17458 sgd_solver.cpp:138] Iteration 13840, lr = 3.125e-05
I0628 20:53:46.532990 17458 solver.cpp:243] Iteration 13850, loss = 3.33494
I0628 20:53:46.533016 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.56264 (* 1 = 5.56264 loss)
I0628 20:53:46.533041 17458 sgd_solver.cpp:138] Iteration 13850, lr = 3.125e-05
I0628 20:53:55.644578 17458 solver.cpp:243] Iteration 13860, loss = 3.93298
I0628 20:53:55.644604 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3343 (* 1 = 3.3343 loss)
I0628 20:53:55.644613 17458 sgd_solver.cpp:138] Iteration 13860, lr = 3.125e-05
I0628 20:54:04.776438 17458 solver.cpp:243] Iteration 13870, loss = 2.61984
I0628 20:54:04.776463 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.26562 (* 1 = 4.26562 loss)
I0628 20:54:04.776489 17458 sgd_solver.cpp:138] Iteration 13870, lr = 3.125e-05
I0628 20:54:13.898677 17458 solver.cpp:243] Iteration 13880, loss = 2.61369
I0628 20:54:13.898826 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.2622 (* 1 = 2.2622 loss)
I0628 20:54:13.898834 17458 sgd_solver.cpp:138] Iteration 13880, lr = 3.125e-05
I0628 20:54:23.035676 17458 solver.cpp:243] Iteration 13890, loss = 3.01781
I0628 20:54:23.035702 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3538 (* 1 = 3.3538 loss)
I0628 20:54:23.035709 17458 sgd_solver.cpp:138] Iteration 13890, lr = 3.125e-05
I0628 20:54:32.134660 17458 solver.cpp:243] Iteration 13900, loss = 3.23766
I0628 20:54:32.134685 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.18273 (* 1 = 3.18273 loss)
I0628 20:54:32.134692 17458 sgd_solver.cpp:138] Iteration 13900, lr = 3.125e-05
I0628 20:54:41.277958 17458 solver.cpp:243] Iteration 13910, loss = 3.50543
I0628 20:54:41.277983 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.61908 (* 1 = 3.61908 loss)
I0628 20:54:41.277990 17458 sgd_solver.cpp:138] Iteration 13910, lr = 3.125e-05
I0628 20:54:50.398717 17458 solver.cpp:243] Iteration 13920, loss = 3.1101
I0628 20:54:50.398877 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.59593 (* 1 = 3.59593 loss)
I0628 20:54:50.398890 17458 sgd_solver.cpp:138] Iteration 13920, lr = 3.125e-05
I0628 20:54:59.519424 17458 solver.cpp:243] Iteration 13930, loss = 3.06707
I0628 20:54:59.519450 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.30368 (* 1 = 4.30368 loss)
I0628 20:54:59.519457 17458 sgd_solver.cpp:138] Iteration 13930, lr = 3.125e-05
I0628 20:55:08.634363 17458 solver.cpp:243] Iteration 13940, loss = 2.73238
I0628 20:55:08.634387 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.20113 (* 1 = 3.20113 loss)
I0628 20:55:08.634395 17458 sgd_solver.cpp:138] Iteration 13940, lr = 3.125e-05
I0628 20:55:17.774220 17458 solver.cpp:243] Iteration 13950, loss = 3.32838
I0628 20:55:17.774245 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.17798 (* 1 = 2.17798 loss)
I0628 20:55:17.774253 17458 sgd_solver.cpp:138] Iteration 13950, lr = 3.125e-05
I0628 20:55:26.884730 17458 solver.cpp:243] Iteration 13960, loss = 3.50644
I0628 20:55:26.884891 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.07352 (* 1 = 3.07352 loss)
I0628 20:55:26.884901 17458 sgd_solver.cpp:138] Iteration 13960, lr = 3.125e-05
I0628 20:55:36.005728 17458 solver.cpp:243] Iteration 13970, loss = 3.01416
I0628 20:55:36.005753 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.99668 (* 1 = 1.99668 loss)
I0628 20:55:36.005760 17458 sgd_solver.cpp:138] Iteration 13970, lr = 3.125e-05
I0628 20:55:45.105155 17458 solver.cpp:243] Iteration 13980, loss = 3.23492
I0628 20:55:45.105180 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.32952 (* 1 = 3.32952 loss)
I0628 20:55:45.105201 17458 sgd_solver.cpp:138] Iteration 13980, lr = 3.125e-05
I0628 20:55:54.229259 17458 solver.cpp:243] Iteration 13990, loss = 3.09921
I0628 20:55:54.229283 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.54151 (* 1 = 2.54151 loss)
I0628 20:55:54.229290 17458 sgd_solver.cpp:138] Iteration 13990, lr = 3.125e-05
I0628 20:56:02.582953 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_14000.caffemodel
I0628 20:56:02.664732 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_14000.solverstate
I0628 20:56:02.697366 17458 solver.cpp:433] Iteration 14000, Testing net (#0)
I0628 20:56:02.697477 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 20:59:07.617040 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.331443
I0628 20:59:08.403698 17458 solver.cpp:243] Iteration 14000, loss = 3.12149
I0628 20:59:08.403723 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.84669 (* 1 = 1.84669 loss)
I0628 20:59:08.403729 17458 sgd_solver.cpp:138] Iteration 14000, lr = 3.125e-05
I0628 20:59:17.541313 17458 solver.cpp:243] Iteration 14010, loss = 3.26279
I0628 20:59:17.541337 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.71921 (* 1 = 2.71921 loss)
I0628 20:59:17.541345 17458 sgd_solver.cpp:138] Iteration 14010, lr = 3.125e-05
I0628 20:59:26.639727 17458 solver.cpp:243] Iteration 14020, loss = 3.5616
I0628 20:59:26.639750 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.98085 (* 1 = 3.98085 loss)
I0628 20:59:26.639757 17458 sgd_solver.cpp:138] Iteration 14020, lr = 3.125e-05
I0628 20:59:35.769534 17458 solver.cpp:243] Iteration 14030, loss = 3.59914
I0628 20:59:35.769559 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.25793 (* 1 = 2.25793 loss)
I0628 20:59:35.769567 17458 sgd_solver.cpp:138] Iteration 14030, lr = 3.125e-05
I0628 20:59:44.867600 17458 solver.cpp:243] Iteration 14040, loss = 2.55136
I0628 20:59:44.867797 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.60208 (* 1 = 2.60208 loss)
I0628 20:59:44.867807 17458 sgd_solver.cpp:138] Iteration 14040, lr = 3.125e-05
I0628 20:59:53.988765 17458 solver.cpp:243] Iteration 14050, loss = 3.52829
I0628 20:59:53.988791 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.7341 (* 1 = 2.7341 loss)
I0628 20:59:53.988798 17458 sgd_solver.cpp:138] Iteration 14050, lr = 3.125e-05
I0628 21:00:03.094903 17458 solver.cpp:243] Iteration 14060, loss = 3.17243
I0628 21:00:03.094928 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.41914 (* 1 = 2.41914 loss)
I0628 21:00:03.094935 17458 sgd_solver.cpp:138] Iteration 14060, lr = 3.125e-05
I0628 21:00:12.237799 17458 solver.cpp:243] Iteration 14070, loss = 2.69801
I0628 21:00:12.237824 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.49755 (* 1 = 2.49755 loss)
I0628 21:00:12.237831 17458 sgd_solver.cpp:138] Iteration 14070, lr = 3.125e-05
I0628 21:00:21.353601 17458 solver.cpp:243] Iteration 14080, loss = 3.15332
I0628 21:00:21.353729 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.09536 (* 1 = 6.09536 loss)
I0628 21:00:21.353754 17458 sgd_solver.cpp:138] Iteration 14080, lr = 3.125e-05
I0628 21:00:30.478889 17458 solver.cpp:243] Iteration 14090, loss = 3.6228
I0628 21:00:30.478914 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.07133 (* 1 = 4.07133 loss)
I0628 21:00:30.478921 17458 sgd_solver.cpp:138] Iteration 14090, lr = 3.125e-05
I0628 21:00:39.578333 17458 solver.cpp:243] Iteration 14100, loss = 3.81116
I0628 21:00:39.578358 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.1921 (* 1 = 3.1921 loss)
I0628 21:00:39.578367 17458 sgd_solver.cpp:138] Iteration 14100, lr = 3.125e-05
I0628 21:00:48.703605 17458 solver.cpp:243] Iteration 14110, loss = 3.15392
I0628 21:00:48.703630 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.92438 (* 1 = 5.92438 loss)
I0628 21:00:48.703637 17458 sgd_solver.cpp:138] Iteration 14110, lr = 3.125e-05
I0628 21:00:57.810905 17458 solver.cpp:243] Iteration 14120, loss = 2.90452
I0628 21:00:57.811050 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.06655 (* 1 = 4.06655 loss)
I0628 21:00:57.811059 17458 sgd_solver.cpp:138] Iteration 14120, lr = 3.125e-05
I0628 21:01:06.936252 17458 solver.cpp:243] Iteration 14130, loss = 2.83278
I0628 21:01:06.936277 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.99986 (* 1 = 3.99986 loss)
I0628 21:01:06.936285 17458 sgd_solver.cpp:138] Iteration 14130, lr = 3.125e-05
I0628 21:01:16.040746 17458 solver.cpp:243] Iteration 14140, loss = 3.67865
I0628 21:01:16.040771 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.41451 (* 1 = 6.41451 loss)
I0628 21:01:16.040778 17458 sgd_solver.cpp:138] Iteration 14140, lr = 3.125e-05
I0628 21:01:25.163700 17458 solver.cpp:243] Iteration 14150, loss = 3.62402
I0628 21:01:25.163725 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.91377 (* 1 = 4.91377 loss)
I0628 21:01:25.163733 17458 sgd_solver.cpp:138] Iteration 14150, lr = 3.125e-05
I0628 21:01:34.271301 17458 solver.cpp:243] Iteration 14160, loss = 3.1727
I0628 21:01:34.271459 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.04116 (* 1 = 4.04116 loss)
I0628 21:01:34.271486 17458 sgd_solver.cpp:138] Iteration 14160, lr = 3.125e-05
I0628 21:01:43.392729 17458 solver.cpp:243] Iteration 14170, loss = 3.097
I0628 21:01:43.392755 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.93414 (* 1 = 5.93414 loss)
I0628 21:01:43.392762 17458 sgd_solver.cpp:138] Iteration 14170, lr = 3.125e-05
I0628 21:01:52.501116 17458 solver.cpp:243] Iteration 14180, loss = 3.93277
I0628 21:01:52.501142 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.42277 (* 1 = 3.42277 loss)
I0628 21:01:52.501148 17458 sgd_solver.cpp:138] Iteration 14180, lr = 3.125e-05
I0628 21:02:01.631084 17458 solver.cpp:243] Iteration 14190, loss = 3.53147
I0628 21:02:01.631111 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.67342 (* 1 = 3.67342 loss)
I0628 21:02:01.631119 17458 sgd_solver.cpp:138] Iteration 14190, lr = 3.125e-05
I0628 21:02:10.742336 17458 solver.cpp:243] Iteration 14200, loss = 2.94429
I0628 21:02:10.742493 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.32784 (* 1 = 2.32784 loss)
I0628 21:02:10.742503 17458 sgd_solver.cpp:138] Iteration 14200, lr = 3.125e-05
I0628 21:02:19.872054 17458 solver.cpp:243] Iteration 14210, loss = 3.72639
I0628 21:02:19.872079 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.70537 (* 1 = 4.70537 loss)
I0628 21:02:19.872087 17458 sgd_solver.cpp:138] Iteration 14210, lr = 3.125e-05
I0628 21:02:28.979106 17458 solver.cpp:243] Iteration 14220, loss = 3.4496
I0628 21:02:28.979130 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.26045 (* 1 = 3.26045 loss)
I0628 21:02:28.979138 17458 sgd_solver.cpp:138] Iteration 14220, lr = 3.125e-05
I0628 21:02:38.096734 17458 solver.cpp:243] Iteration 14230, loss = 3.77327
I0628 21:02:38.096758 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.26681 (* 1 = 4.26681 loss)
I0628 21:02:38.096765 17458 sgd_solver.cpp:138] Iteration 14230, lr = 3.125e-05
I0628 21:02:47.201341 17458 solver.cpp:243] Iteration 14240, loss = 3.7166
I0628 21:02:47.201455 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.27711 (* 1 = 1.27711 loss)
I0628 21:02:47.201480 17458 sgd_solver.cpp:138] Iteration 14240, lr = 3.125e-05
I0628 21:02:56.324970 17458 solver.cpp:243] Iteration 14250, loss = 2.88291
I0628 21:02:56.324996 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.6686 (* 1 = 1.6686 loss)
I0628 21:02:56.325003 17458 sgd_solver.cpp:138] Iteration 14250, lr = 3.125e-05
I0628 21:03:05.431210 17458 solver.cpp:243] Iteration 14260, loss = 2.96277
I0628 21:03:05.431233 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.58772 (* 1 = 2.58772 loss)
I0628 21:03:05.431241 17458 sgd_solver.cpp:138] Iteration 14260, lr = 3.125e-05
I0628 21:03:14.552232 17458 solver.cpp:243] Iteration 14270, loss = 3.16536
I0628 21:03:14.552258 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.01223 (* 1 = 3.01223 loss)
I0628 21:03:14.552265 17458 sgd_solver.cpp:138] Iteration 14270, lr = 3.125e-05
I0628 21:03:23.656539 17458 solver.cpp:243] Iteration 14280, loss = 3.61296
I0628 21:03:23.656700 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.68073 (* 1 = 1.68073 loss)
I0628 21:03:23.656744 17458 sgd_solver.cpp:138] Iteration 14280, lr = 3.125e-05
I0628 21:03:32.782327 17458 solver.cpp:243] Iteration 14290, loss = 3.02441
I0628 21:03:32.782351 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.16952 (* 1 = 3.16952 loss)
I0628 21:03:32.782359 17458 sgd_solver.cpp:138] Iteration 14290, lr = 3.125e-05
I0628 21:03:41.890365 17458 solver.cpp:243] Iteration 14300, loss = 2.97145
I0628 21:03:41.890389 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.18963 (* 1 = 5.18963 loss)
I0628 21:03:41.890396 17458 sgd_solver.cpp:138] Iteration 14300, lr = 3.125e-05
I0628 21:03:51.019991 17458 solver.cpp:243] Iteration 14310, loss = 4.08207
I0628 21:03:51.020016 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.89182 (* 1 = 1.89182 loss)
I0628 21:03:51.020023 17458 sgd_solver.cpp:138] Iteration 14310, lr = 3.125e-05
I0628 21:04:00.129595 17458 solver.cpp:243] Iteration 14320, loss = 3.42074
I0628 21:04:00.129748 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.3034 (* 1 = 2.3034 loss)
I0628 21:04:00.129758 17458 sgd_solver.cpp:138] Iteration 14320, lr = 3.125e-05
I0628 21:04:09.255666 17458 solver.cpp:243] Iteration 14330, loss = 3.43822
I0628 21:04:09.255690 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.86106 (* 1 = 2.86106 loss)
I0628 21:04:09.255698 17458 sgd_solver.cpp:138] Iteration 14330, lr = 3.125e-05
I0628 21:04:18.360852 17458 solver.cpp:243] Iteration 14340, loss = 3.79307
I0628 21:04:18.360877 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.21124 (* 1 = 3.21124 loss)
I0628 21:04:18.360884 17458 sgd_solver.cpp:138] Iteration 14340, lr = 3.125e-05
I0628 21:04:27.487718 17458 solver.cpp:243] Iteration 14350, loss = 3.07165
I0628 21:04:27.487743 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.86131 (* 1 = 3.86131 loss)
I0628 21:04:27.487751 17458 sgd_solver.cpp:138] Iteration 14350, lr = 3.125e-05
I0628 21:04:36.592737 17458 solver.cpp:243] Iteration 14360, loss = 3.32065
I0628 21:04:36.592877 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25014 (* 1 = 3.25014 loss)
I0628 21:04:36.592902 17458 sgd_solver.cpp:138] Iteration 14360, lr = 3.125e-05
I0628 21:04:45.719286 17458 solver.cpp:243] Iteration 14370, loss = 3.40544
I0628 21:04:45.719319 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25641 (* 1 = 3.25641 loss)
I0628 21:04:45.719333 17458 sgd_solver.cpp:138] Iteration 14370, lr = 3.125e-05
I0628 21:04:54.825093 17458 solver.cpp:243] Iteration 14380, loss = 2.6683
I0628 21:04:54.825117 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.54861 (* 1 = 2.54861 loss)
I0628 21:04:54.825125 17458 sgd_solver.cpp:138] Iteration 14380, lr = 3.125e-05
I0628 21:05:03.957093 17458 solver.cpp:243] Iteration 14390, loss = 2.94235
I0628 21:05:03.957116 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.03811 (* 1 = 3.03811 loss)
I0628 21:05:03.957124 17458 sgd_solver.cpp:138] Iteration 14390, lr = 3.125e-05
I0628 21:05:13.061460 17458 solver.cpp:243] Iteration 14400, loss = 3.51963
I0628 21:05:13.061591 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.81591 (* 1 = 3.81591 loss)
I0628 21:05:13.061600 17458 sgd_solver.cpp:138] Iteration 14400, lr = 3.125e-05
I0628 21:05:22.189571 17458 solver.cpp:243] Iteration 14410, loss = 3.3552
I0628 21:05:22.189597 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.4476 (* 1 = 4.4476 loss)
I0628 21:05:22.189604 17458 sgd_solver.cpp:138] Iteration 14410, lr = 3.125e-05
I0628 21:05:31.290457 17458 solver.cpp:243] Iteration 14420, loss = 3.00748
I0628 21:05:31.290480 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.87554 (* 1 = 2.87554 loss)
I0628 21:05:31.290488 17458 sgd_solver.cpp:138] Iteration 14420, lr = 3.125e-05
I0628 21:05:40.413815 17458 solver.cpp:243] Iteration 14430, loss = 3.05969
I0628 21:05:40.413841 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.95058 (* 1 = 3.95058 loss)
I0628 21:05:40.413849 17458 sgd_solver.cpp:138] Iteration 14430, lr = 3.125e-05
I0628 21:05:49.519441 17458 solver.cpp:243] Iteration 14440, loss = 3.58128
I0628 21:05:49.519603 17458 solver.cpp:259]     Train net output #0: mbox_loss = 6.89897 (* 1 = 6.89897 loss)
I0628 21:05:49.519630 17458 sgd_solver.cpp:138] Iteration 14440, lr = 3.125e-05
I0628 21:05:58.643927 17458 solver.cpp:243] Iteration 14450, loss = 3.18125
I0628 21:05:58.643952 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.31807 (* 1 = 1.31807 loss)
I0628 21:05:58.643959 17458 sgd_solver.cpp:138] Iteration 14450, lr = 3.125e-05
I0628 21:06:07.753021 17458 solver.cpp:243] Iteration 14460, loss = 2.83479
I0628 21:06:07.753046 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.99968 (* 1 = 1.99968 loss)
I0628 21:06:07.753054 17458 sgd_solver.cpp:138] Iteration 14460, lr = 3.125e-05
I0628 21:06:16.881856 17458 solver.cpp:243] Iteration 14470, loss = 3.09702
I0628 21:06:16.881881 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.21433 (* 1 = 3.21433 loss)
I0628 21:06:16.881889 17458 sgd_solver.cpp:138] Iteration 14470, lr = 3.125e-05
I0628 21:06:25.988672 17458 solver.cpp:243] Iteration 14480, loss = 3.58971
I0628 21:06:25.988798 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.51909 (* 1 = 2.51909 loss)
I0628 21:06:25.988807 17458 sgd_solver.cpp:138] Iteration 14480, lr = 3.125e-05
I0628 21:06:35.117985 17458 solver.cpp:243] Iteration 14490, loss = 2.73935
I0628 21:06:35.118010 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25626 (* 1 = 3.25626 loss)
I0628 21:06:35.118017 17458 sgd_solver.cpp:138] Iteration 14490, lr = 3.125e-05
I0628 21:06:44.223961 17458 solver.cpp:243] Iteration 14500, loss = 3.72242
I0628 21:06:44.223984 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.02575 (* 1 = 4.02575 loss)
I0628 21:06:44.224010 17458 sgd_solver.cpp:138] Iteration 14500, lr = 3.125e-05
I0628 21:06:53.353621 17458 solver.cpp:243] Iteration 14510, loss = 3.15412
I0628 21:06:53.353647 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.40119 (* 1 = 2.40119 loss)
I0628 21:06:53.353654 17458 sgd_solver.cpp:138] Iteration 14510, lr = 3.125e-05
I0628 21:07:02.461171 17458 solver.cpp:243] Iteration 14520, loss = 3.76539
I0628 21:07:02.461361 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.3209 (* 1 = 3.3209 loss)
I0628 21:07:02.461390 17458 sgd_solver.cpp:138] Iteration 14520, lr = 3.125e-05
I0628 21:07:11.592509 17458 solver.cpp:243] Iteration 14530, loss = 3.40351
I0628 21:07:11.592535 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.53566 (* 1 = 4.53566 loss)
I0628 21:07:11.592541 17458 sgd_solver.cpp:138] Iteration 14530, lr = 3.125e-05
I0628 21:07:20.696491 17458 solver.cpp:243] Iteration 14540, loss = 3.38208
I0628 21:07:20.696516 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.19324 (* 1 = 4.19324 loss)
I0628 21:07:20.696522 17458 sgd_solver.cpp:138] Iteration 14540, lr = 3.125e-05
I0628 21:07:29.824717 17458 solver.cpp:243] Iteration 14550, loss = 2.9332
I0628 21:07:29.824743 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25264 (* 1 = 3.25264 loss)
I0628 21:07:29.824751 17458 sgd_solver.cpp:138] Iteration 14550, lr = 3.125e-05
I0628 21:07:38.933629 17458 solver.cpp:243] Iteration 14560, loss = 3.23186
I0628 21:07:38.933756 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.64967 (* 1 = 4.64967 loss)
I0628 21:07:38.933766 17458 sgd_solver.cpp:138] Iteration 14560, lr = 3.125e-05
I0628 21:07:48.068018 17458 solver.cpp:243] Iteration 14570, loss = 3.2526
I0628 21:07:48.068044 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.37369 (* 1 = 3.37369 loss)
I0628 21:07:48.068053 17458 sgd_solver.cpp:138] Iteration 14570, lr = 3.125e-05
I0628 21:07:57.171586 17458 solver.cpp:243] Iteration 14580, loss = 2.83851
I0628 21:07:57.171609 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.45069 (* 1 = 2.45069 loss)
I0628 21:07:57.171617 17458 sgd_solver.cpp:138] Iteration 14580, lr = 3.125e-05
I0628 21:08:06.303668 17458 solver.cpp:243] Iteration 14590, loss = 2.76759
I0628 21:08:06.303694 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.77582 (* 1 = 1.77582 loss)
I0628 21:08:06.303701 17458 sgd_solver.cpp:138] Iteration 14590, lr = 3.125e-05
I0628 21:08:15.410434 17458 solver.cpp:243] Iteration 14600, loss = 2.72523
I0628 21:08:15.410533 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.42552 (* 1 = 1.42552 loss)
I0628 21:08:15.410542 17458 sgd_solver.cpp:138] Iteration 14600, lr = 3.125e-05
I0628 21:08:24.533952 17458 solver.cpp:243] Iteration 14610, loss = 2.98876
I0628 21:08:24.533978 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.86829 (* 1 = 2.86829 loss)
I0628 21:08:24.533985 17458 sgd_solver.cpp:138] Iteration 14610, lr = 3.125e-05
I0628 21:08:33.648732 17458 solver.cpp:243] Iteration 14620, loss = 3.29063
I0628 21:08:33.648756 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.1184 (* 1 = 5.1184 loss)
I0628 21:08:33.648780 17458 sgd_solver.cpp:138] Iteration 14620, lr = 3.125e-05
I0628 21:08:42.809878 17458 solver.cpp:243] Iteration 14630, loss = 3.27776
I0628 21:08:42.809903 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.97612 (* 1 = 1.97612 loss)
I0628 21:08:42.809929 17458 sgd_solver.cpp:138] Iteration 14630, lr = 3.125e-05
I0628 21:08:51.944413 17458 solver.cpp:243] Iteration 14640, loss = 3.07287
I0628 21:08:51.944564 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.41495 (* 1 = 2.41495 loss)
I0628 21:08:51.944589 17458 sgd_solver.cpp:138] Iteration 14640, lr = 3.125e-05
I0628 21:09:01.103425 17458 solver.cpp:243] Iteration 14650, loss = 3.69954
I0628 21:09:01.103451 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.11926 (* 1 = 3.11926 loss)
I0628 21:09:01.103475 17458 sgd_solver.cpp:138] Iteration 14650, lr = 3.125e-05
I0628 21:09:10.229607 17458 solver.cpp:243] Iteration 14660, loss = 3.40589
I0628 21:09:10.229631 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.50918 (* 1 = 3.50918 loss)
I0628 21:09:10.229657 17458 sgd_solver.cpp:138] Iteration 14660, lr = 3.125e-05
I0628 21:09:19.378388 17458 solver.cpp:243] Iteration 14670, loss = 4.09693
I0628 21:09:19.378412 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.99863 (* 1 = 3.99863 loss)
I0628 21:09:19.378437 17458 sgd_solver.cpp:138] Iteration 14670, lr = 3.125e-05
I0628 21:09:28.500871 17458 solver.cpp:243] Iteration 14680, loss = 3.13754
I0628 21:09:28.501051 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.02794 (* 1 = 3.02794 loss)
I0628 21:09:28.501061 17458 sgd_solver.cpp:138] Iteration 14680, lr = 3.125e-05
I0628 21:09:37.652990 17458 solver.cpp:243] Iteration 14690, loss = 3.7659
I0628 21:09:37.653015 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.77621 (* 1 = 4.77621 loss)
I0628 21:09:37.653041 17458 sgd_solver.cpp:138] Iteration 14690, lr = 3.125e-05
I0628 21:09:46.783828 17458 solver.cpp:243] Iteration 14700, loss = 2.52524
I0628 21:09:46.783852 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.74293 (* 1 = 2.74293 loss)
I0628 21:09:46.783879 17458 sgd_solver.cpp:138] Iteration 14700, lr = 3.125e-05
I0628 21:09:55.942517 17458 solver.cpp:243] Iteration 14710, loss = 2.95423
I0628 21:09:55.942540 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.85874 (* 1 = 2.85874 loss)
I0628 21:09:55.942566 17458 sgd_solver.cpp:138] Iteration 14710, lr = 3.125e-05
I0628 21:10:05.076987 17458 solver.cpp:243] Iteration 14720, loss = 3.53842
I0628 21:10:05.077157 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.62069 (* 1 = 4.62069 loss)
I0628 21:10:05.077183 17458 sgd_solver.cpp:138] Iteration 14720, lr = 3.125e-05
I0628 21:10:14.232897 17458 solver.cpp:243] Iteration 14730, loss = 3.74171
I0628 21:10:14.232921 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.86758 (* 1 = 3.86758 loss)
I0628 21:10:14.232947 17458 sgd_solver.cpp:138] Iteration 14730, lr = 3.125e-05
I0628 21:10:23.366134 17458 solver.cpp:243] Iteration 14740, loss = 3.08754
I0628 21:10:23.366158 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.83854 (* 1 = 1.83854 loss)
I0628 21:10:23.366184 17458 sgd_solver.cpp:138] Iteration 14740, lr = 3.125e-05
I0628 21:10:32.517550 17458 solver.cpp:243] Iteration 14750, loss = 3.45708
I0628 21:10:32.517573 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.11032 (* 1 = 5.11032 loss)
I0628 21:10:32.517599 17458 sgd_solver.cpp:138] Iteration 14750, lr = 3.125e-05
I0628 21:10:41.643995 17458 solver.cpp:243] Iteration 14760, loss = 3.35488
I0628 21:10:41.644140 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.2174 (* 1 = 2.2174 loss)
I0628 21:10:41.644148 17458 sgd_solver.cpp:138] Iteration 14760, lr = 3.125e-05
I0628 21:10:50.800573 17458 solver.cpp:243] Iteration 14770, loss = 3.36459
I0628 21:10:50.800598 17458 solver.cpp:259]     Train net output #0: mbox_loss = 1.97825 (* 1 = 1.97825 loss)
I0628 21:10:50.800623 17458 sgd_solver.cpp:138] Iteration 14770, lr = 3.125e-05
I0628 21:10:59.934222 17458 solver.cpp:243] Iteration 14780, loss = 3.54084
I0628 21:10:59.934247 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.63727 (* 1 = 3.63727 loss)
I0628 21:10:59.934273 17458 sgd_solver.cpp:138] Iteration 14780, lr = 3.125e-05
I0628 21:11:09.078544 17458 solver.cpp:243] Iteration 14790, loss = 3.27471
I0628 21:11:09.078570 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.83483 (* 1 = 2.83483 loss)
I0628 21:11:09.078577 17458 sgd_solver.cpp:138] Iteration 14790, lr = 3.125e-05
I0628 21:11:18.189648 17458 solver.cpp:243] Iteration 14800, loss = 3.25641
I0628 21:11:18.189771 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.64683 (* 1 = 2.64683 loss)
I0628 21:11:18.189780 17458 sgd_solver.cpp:138] Iteration 14800, lr = 3.125e-05
I0628 21:11:27.317548 17458 solver.cpp:243] Iteration 14810, loss = 2.57226
I0628 21:11:27.317574 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.8603 (* 1 = 2.8603 loss)
I0628 21:11:27.317580 17458 sgd_solver.cpp:138] Iteration 14810, lr = 3.125e-05
I0628 21:11:36.432237 17458 solver.cpp:243] Iteration 14820, loss = 3.77553
I0628 21:11:36.432261 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.25418 (* 1 = 3.25418 loss)
I0628 21:11:36.432287 17458 sgd_solver.cpp:138] Iteration 14820, lr = 3.125e-05
I0628 21:11:45.591708 17458 solver.cpp:243] Iteration 14830, loss = 2.73436
I0628 21:11:45.591732 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.81508 (* 1 = 2.81508 loss)
I0628 21:11:45.591758 17458 sgd_solver.cpp:138] Iteration 14830, lr = 3.125e-05
I0628 21:11:54.724253 17458 solver.cpp:243] Iteration 14840, loss = 3.20851
I0628 21:11:54.724411 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.5529 (* 1 = 2.5529 loss)
I0628 21:11:54.724428 17458 sgd_solver.cpp:138] Iteration 14840, lr = 3.125e-05
I0628 21:12:03.863109 17458 solver.cpp:243] Iteration 14850, loss = 3.00599
I0628 21:12:03.863134 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.36125 (* 1 = 4.36125 loss)
I0628 21:12:03.863160 17458 sgd_solver.cpp:138] Iteration 14850, lr = 3.125e-05
I0628 21:12:12.976927 17458 solver.cpp:243] Iteration 14860, loss = 3.29242
I0628 21:12:12.976949 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.78572 (* 1 = 2.78572 loss)
I0628 21:12:12.976958 17458 sgd_solver.cpp:138] Iteration 14860, lr = 3.125e-05
I0628 21:12:22.114634 17458 solver.cpp:243] Iteration 14870, loss = 3.08891
I0628 21:12:22.114658 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.80713 (* 1 = 2.80713 loss)
I0628 21:12:22.114684 17458 sgd_solver.cpp:138] Iteration 14870, lr = 3.125e-05
I0628 21:12:31.250636 17458 solver.cpp:243] Iteration 14880, loss = 3.92016
I0628 21:12:31.250790 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.23103 (* 1 = 3.23103 loss)
I0628 21:12:31.250799 17458 sgd_solver.cpp:138] Iteration 14880, lr = 3.125e-05
I0628 21:12:40.407253 17458 solver.cpp:243] Iteration 14890, loss = 2.49021
I0628 21:12:40.407279 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.54832 (* 1 = 3.54832 loss)
I0628 21:12:40.407303 17458 sgd_solver.cpp:138] Iteration 14890, lr = 3.125e-05
I0628 21:12:49.533522 17458 solver.cpp:243] Iteration 14900, loss = 2.92683
I0628 21:12:49.533547 17458 solver.cpp:259]     Train net output #0: mbox_loss = 5.27777 (* 1 = 5.27777 loss)
I0628 21:12:49.533555 17458 sgd_solver.cpp:138] Iteration 14900, lr = 3.125e-05
I0628 21:12:58.687469 17458 solver.cpp:243] Iteration 14910, loss = 3.39278
I0628 21:12:58.687492 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.03354 (* 1 = 2.03354 loss)
I0628 21:12:58.687518 17458 sgd_solver.cpp:138] Iteration 14910, lr = 3.125e-05
I0628 21:13:07.820627 17458 solver.cpp:243] Iteration 14920, loss = 3.20532
I0628 21:13:07.820760 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.47228 (* 1 = 2.47228 loss)
I0628 21:13:07.820770 17458 sgd_solver.cpp:138] Iteration 14920, lr = 3.125e-05
I0628 21:13:16.957353 17458 solver.cpp:243] Iteration 14930, loss = 3.84976
I0628 21:13:16.957377 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.47726 (* 1 = 2.47726 loss)
I0628 21:13:16.957403 17458 sgd_solver.cpp:138] Iteration 14930, lr = 3.125e-05
I0628 21:13:26.068563 17458 solver.cpp:243] Iteration 14940, loss = 2.84323
I0628 21:13:26.068588 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.53704 (* 1 = 2.53704 loss)
I0628 21:13:26.068595 17458 sgd_solver.cpp:138] Iteration 14940, lr = 3.125e-05
I0628 21:13:35.205092 17458 solver.cpp:243] Iteration 14950, loss = 2.97804
I0628 21:13:35.205117 17458 solver.cpp:259]     Train net output #0: mbox_loss = 2.78915 (* 1 = 2.78915 loss)
I0628 21:13:35.205143 17458 sgd_solver.cpp:138] Iteration 14950, lr = 3.125e-05
I0628 21:13:44.337127 17458 solver.cpp:243] Iteration 14960, loss = 3.31396
I0628 21:13:44.337306 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.43684 (* 1 = 3.43684 loss)
I0628 21:13:44.337321 17458 sgd_solver.cpp:138] Iteration 14960, lr = 3.125e-05
I0628 21:13:53.490553 17458 solver.cpp:243] Iteration 14970, loss = 2.85119
I0628 21:13:53.490578 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.87103 (* 1 = 3.87103 loss)
I0628 21:13:53.490604 17458 sgd_solver.cpp:138] Iteration 14970, lr = 3.125e-05
I0628 21:14:02.626685 17458 solver.cpp:243] Iteration 14980, loss = 3.23021
I0628 21:14:02.626709 17458 solver.cpp:259]     Train net output #0: mbox_loss = 3.59211 (* 1 = 3.59211 loss)
I0628 21:14:02.626734 17458 sgd_solver.cpp:138] Iteration 14980, lr = 3.125e-05
I0628 21:14:11.781163 17458 solver.cpp:243] Iteration 14990, loss = 3.5013
I0628 21:14:11.781188 17458 solver.cpp:259]     Train net output #0: mbox_loss = 4.27104 (* 1 = 4.27104 loss)
I0628 21:14:11.781195 17458 sgd_solver.cpp:138] Iteration 14990, lr = 3.125e-05
I0628 21:14:20.138279 17458 solver.cpp:596] Snapshotting to binary proto file snapshot/mobilenet_iter_15000.caffemodel
I0628 21:14:20.218698 17458 sgd_solver.cpp:307] Snapshotting solver state to binary proto file snapshot/mobilenet_iter_15000.solverstate
I0628 21:14:20.547590 17458 solver.cpp:332] Iteration 15000, loss = 3.06732
I0628 21:14:20.547612 17458 solver.cpp:433] Iteration 15000, Testing net (#0)
I0628 21:14:20.547762 17458 net.cpp:693] Ignoring source layer mbox_loss
I0628 21:17:25.347295 17458 solver.cpp:546]     Test net output #0: detection_eval = 0.328787
I0628 21:17:25.348186 17458 solver.cpp:337] Optimization Done.
I0628 21:17:25.348196 17458 caffe.cpp:254] Optimization Done.
